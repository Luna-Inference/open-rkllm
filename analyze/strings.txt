__gmon_start__
_ITM_deregisterTMCloneTable
_ITM_registerTMCloneTable
__cxa_finalize
strcoll
strchr
_ZdlPv
_Znwm
_ZNSt18condition_variableC1Ev
_Unwind_Resume
__cxa_begin_catch
__cxa_rethrow
__cxa_end_catch
_ZNSt18condition_variableD1Ev
__gxx_personality_v0
rkllm_init
memset
rkllm_load_lora
rkllm_load_prompt_cache
rkllm_release_prompt_cache
rkllm_destroy
rkllm_run
rkllm_run_async
rkllm_abort
rkllm_is_running
rkllm_clear_kv_cache
rkllm_set_chat_template
rkllm_createDefaultParam
sysconf
opendir
readdir
remove
closedir
rmdir
scandir
perror
memmove
_ZSt20__throw_length_errorPKc
fopen
fread
rkllm_accuracy_analysis
access
calloc
strlen
strcpy
sprintf
putchar
mkdir
_ZNSt8ios_base4InitC1Ev
_ZNSt8ios_base4InitD1Ev
__cxa_atexit
strcmp
_ZNSt6thread6_StateD2Ev
_ZNSt9basic_iosIcSt11char_traitsIcEE5clearESt12_Ios_Iostate
_ZSt17__throw_bad_allocv
stdout
fputc
fflush
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE9_M_appendEPKcm
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE9_M_mutateEmmPKcm
stderr
fwrite
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE10_M_replaceEmmPKcm
_ZTVNSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEEE
_ZTVSt15basic_streambufIcSt11char_traitsIcEE
_ZNSt6localeD1Ev
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE9_M_createERmm
_ZNSt8ios_baseC2Ev
_ZTTNSt7__cxx1119basic_istringstreamIcSt11char_traitsIcESaIcEEE
_ZTVSt9basic_iosIcSt11char_traitsIcEE
_ZNSt9basic_iosIcSt11char_traitsIcEE4initEPSt15basic_streambufIcS1_E
_ZTVNSt7__cxx1119basic_istringstreamIcSt11char_traitsIcESaIcEEE
_ZNSt6localeC1Ev
_ZNSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEE7_M_syncEPcmm
_ZSt7getlineIcSt11char_traitsIcESaIcEERSt13basic_istreamIT_T0_ES7_RNSt7__cxx1112basic_stringIS4_S5_T1_EES4_
__errno_location
strtol
_ZNSt8ios_baseD2Ev
pthread_create
_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7compareEPKc
getenv
_ZSt20__throw_out_of_rangePKc
_ZSt24__throw_invalid_argumentPKc
_ZSt19__throw_logic_errorPKc
_ZNSt7__cxx1119basic_istringstreamIcSt11char_traitsIcESaIcEED1Ev
_ZTTNSt7__cxx1118basic_stringstreamIcSt11char_traitsIcESaIcEEE
_ZTVNSt7__cxx1118basic_stringstreamIcSt11char_traitsIcESaIcEEE
_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l
isprint
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_M_constructEmc
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE9_M_assignERKS4_
_ZNSt7__cxx1118basic_stringstreamIcSt11char_traitsIcESaIcEED1Ev
_ZTTSt14basic_ifstreamIcSt11char_traitsIcEE
_ZTVSt14basic_ifstreamIcSt11char_traitsIcEE
_ZNSt13basic_filebufIcSt11char_traitsIcEEC1Ev
_ZNSt13basic_filebufIcSt11char_traitsIcEE4openEPKcSt13_Ios_Openmode
_ZTVSt13basic_filebufIcSt11char_traitsIcEE
_ZNSt13basic_filebufIcSt11char_traitsIcEE5closeEv
_ZNSt12__basic_fileIcED1Ev
_ZNSt13basic_filebufIcSt11char_traitsIcEED1Ev
_ZNSi5tellgEv
_ZNSt14basic_ifstreamIcSt11char_traitsIcEED1Ev
_ZSt18_Rb_tree_decrementPSt18_Rb_tree_node_base
_ZSt29_Rb_tree_insert_and_rebalancebPSt18_Rb_tree_node_baseS0_RS_
__xstat
_ZSt4cerr
_ZNSo3putEc
_ZNSo5flushEv
_ZNKSt5ctypeIcE13_M_widen_initEv
_ZSt16__throw_bad_castv
malloc
strdup
_ZNSt18condition_variable10notify_allEv
_ZSt20__throw_system_errori
_ZNSt6thread4joinEv
_ZSt9terminatev
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE4findEPKcmm
_ZTTNSt7__cxx1119basic_ostringstreamIcSt11char_traitsIcESaIcEEE
_ZTVNSt7__cxx1119basic_ostringstreamIcSt11char_traitsIcESaIcEEE
rkllm_print_timings
rkllm_print_memorys
_ZSt24__throw_out_of_range_fmtPKcz
_ZNSt7__cxx1119basic_ostringstreamIcSt11char_traitsIcESaIcEED1Ev
sched_getaffinity
_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE
_ZTVN10__cxxabiv117__class_type_infoE
_ZTVN10__cxxabiv120__si_class_type_infoE
_ZTINSt6thread6_StateE
__pthread_key_create
pthread_mutex_unlock
pthread_mutex_lock
_ZNKSt13runtime_error4whatEv
_ZNSt13runtime_errorD1Ev
_ZNSt9exceptionD2Ev
_ZNSt19__codecvt_utf8_baseIDiED2Ev
__cxa_allocate_exception
_ZNSt13runtime_errorC1ERKS_
__cxa_throw
__cxa_guard_acquire
__cxa_guard_release
_ZSt9use_facetISt5ctypeIcEERKT_RKSt6locale
__cxa_guard_abort
_ZSt18_Rb_tree_incrementPSt18_Rb_tree_node_base
vsnprintf
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7reserveEm
_ZNSt13runtime_errorC2EPKc
_ZTVSt11regex_error
_ZNSt11regex_errorD1Ev
_ZTISt11regex_error
__cxa_free_exception
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE14_M_replace_auxEmmmc
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE8_M_eraseEmm
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE4findEcm
isspace
_ZNSt6chrono3_V212system_clock3nowEv
localtime
strftime
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE6resizeEmc
_ZNSt13runtime_errorC1ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
_ZTISt13runtime_error
_ZNSolsEi
_ZNSt6thread20hardware_concurrencyEv
_ZNSo9_M_insertImEERSoT_
_ZNSi10_M_extractIlEERSiRT_
_ZNSt16invalid_argumentC1EPKc
_ZNSt16invalid_argumentD1Ev
_ZTISt16invalid_argument
strncpy
strncmp
strtod
_ZNSirsERi
_ZNSt13runtime_errorC1EPKc
_ZNSt6localeC1ERKS_
_ZdaPv
_ZNKSt8__detail20_Prime_rehash_policy14_M_need_rehashEmmm
_ZNKSt12__basic_fileIcE7is_openEv
_ZSt11_Hash_bytesPKvmm
_ZSt25__throw_bad_function_callv
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE9push_backEc
strtoull
strtoll
_ZNSt5ctypeIcE2idE
_ZNKSt6locale2id5_M_idEv
_ZTISt5ctypeIcE
_ZTINSt6locale5facetE
__dynamic_cast
__cxa_bad_cast
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE6appendEPKc
localeconv
_ZNKSt19__codecvt_utf8_baseIDiE13do_max_lengthEv
_ZSt19__throw_range_errorPKc
_ZSt9use_facetINSt7__cxx117collateIcEEERKT_RKSt6locale
_Znam
_ZNSt6localeaSERKS_
_ZSt19__throw_regex_errorNSt15regex_constants10error_typeE
strtoul
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE6assignEPKc
_ZNSt14basic_ifstreamIcSt11char_traitsIcEEC1EPKcSt13_Ios_Openmode
_ZNSt7__cxx1119basic_ostringstreamIcSt11char_traitsIcESaIcEEC1Ev
_ZNSolsEPSt15basic_streambufIcSt11char_traitsIcEE
_ZNKSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEE3strEv
strtof
_ZNSt7__cxx1118basic_stringstreamIcSt11char_traitsIcESaIcEEC1ERKNS_12basic_stringIcS2_S3_EESt13_Ios_Openmode
_ZStrsIcSt11char_traitsIcEERSt13basic_istreamIT_T0_ES6_RS3_
_ZSt7getlineIcSt11char_traitsIcESaIcEERSt13basic_istreamIT_T0_ES7_RNSt7__cxx1112basic_stringIS4_S5_T1_EE
_ZNSt14basic_ifstreamIcSt11char_traitsIcEE5closeEv
_ZTVSt9exception
_ZNSt9exceptionD1Ev
_ZTISt9exception
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7compareEmmRKS4_
_ZNSt16invalid_argumentC1ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
_ZTISt19__codecvt_utf8_baseIDiE
_ZNKSt19__codecvt_utf8_baseIDiE6do_outER11__mbstate_tPKDiS4_RS4_PcS6_RS6_
_ZNKSt19__codecvt_utf8_baseIDiE10do_unshiftER11__mbstate_tPcS3_RS3_
_ZNKSt19__codecvt_utf8_baseIDiE5do_inER11__mbstate_tPKcS4_RS4_PDiS6_RS6_
_ZNKSt19__codecvt_utf8_baseIDiE11do_encodingEv
_ZNKSt19__codecvt_utf8_baseIDiE16do_always_noconvEv
_ZNKSt19__codecvt_utf8_baseIDiE9do_lengthER11__mbstate_tPKcS4_m
_ZNSt13random_device7_M_initERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
_ZNSt13random_device9_M_getvalEv
_ZNSt13random_device7_M_finiEv
_ZNKSt8__detail20_Prime_rehash_policy11_M_next_bktEm
_ZSt18_Rb_tree_incrementPKSt18_Rb_tree_node_base
_ZNSt12out_of_rangeC1EPKc
_ZNSt12out_of_rangeD1Ev
_ZTISt12out_of_range
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE6substrEmm
_ZNSt7__cxx1118basic_stringstreamIcSt11char_traitsIcESaIcEEC1Ev
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE5rfindEcm
_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEED1Ev
_ZSt15__once_callable
_ZSt11__once_call
__once_proxy
_ZNSt13__future_base12_Result_baseD2Ev
_ZSt17current_exceptionv
_ZNSt15__exception_ptr13exception_ptr4swapERS0_
_ZNSt15__exception_ptr13exception_ptrD1Ev
fputs
_ZNSt28__atomic_futex_unsigned_base19_M_futex_notify_allEPj
_ZSt28_Rb_tree_rebalance_for_erasePSt18_Rb_tree_node_baseRS_
__isoc99_sscanf
strerror
ferror
_ZSt15future_categoryv
_ZNSt11logic_errorC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
_ZTVSt12future_error
_ZTISt12future_error
__cxa_init_primary_exception
_ZNSt11logic_errorC2ERKS_
_ZNSt15__exception_ptr13exception_ptrC1EPv
_ZNSt12future_errorD1Ev
_ZSt20__throw_future_errori
fseek
ftell
munmap
fclose
logf
munlock
realloc
strstr
fgets
_ZNSi10_M_extractImEERSiRT_
_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc
toupper
_ZNSt13__future_base12_Result_baseC2Ev
_ZNSt3_V216generic_categoryEv
fileno
posix_fadvise
mmap
posix_madvise
_ZNSt28__atomic_futex_unsigned_base19_M_futex_wait_untilEPjjbNSt6chrono8durationIlSt5ratioILl1ELl1EEEENS2_IlS3_ILl1ELl1000000000EEEE
_ZNSt15__exception_ptreqERKNS_13exception_ptrES2_
mlock
getrlimit
_ZNSt15__exception_ptr13exception_ptrC1ERKS0_
_ZSt17rethrow_exceptionNSt15__exception_ptr13exception_ptrE
_ZTTSt14basic_ofstreamIcSt11char_traitsIcEE
_ZTVSt14basic_ofstreamIcSt11char_traitsIcEE
_ZNSt8ios_base7_M_swapERS_
_ZNSt9basic_iosIcSt11char_traitsIcEE15_M_cache_localeERKSt6locale
_ZNSt13basic_filebufIcSt11char_traitsIcEEaSEOS2_
_ZNSo5writeEPKcl
_ZNSt14basic_ofstreamIcSt11char_traitsIcEED1Ev
tolower
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE5rfindEPKcmm
_ZNSo5seekpESt4fposI11__mbstate_tE
_ZTINSt13__future_base12_Result_baseE
pthread_once
_ZTIN10__cxxabiv115__forced_unwindE
_ZTISt12system_error
expf
powf
exp2f
log2f
_ZNSt19__codecvt_utf8_baseIwED2Ev
_ZSt9use_facetISt5ctypeIwEERKT_RKSt6locale
wmemcpy
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE9_M_createERmm
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE14_M_replace_auxEmmmw
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE9_M_mutateEmmPKwm
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE9push_backEw
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE12_M_constructEmw
_ZTTNSt7__cxx1119basic_istringstreamIwSt11char_traitsIwESaIwEEE
_ZTVSt9basic_iosIwSt11char_traitsIwEE
_ZNSt9basic_iosIwSt11char_traitsIwEE4initEPSt15basic_streambufIwS1_E
_ZTVNSt7__cxx1119basic_istringstreamIwSt11char_traitsIwESaIwEEE
_ZTVSt15basic_streambufIwSt11char_traitsIwEE
_ZTVNSt7__cxx1115basic_stringbufIwSt11char_traitsIwESaIwEEE
_ZNSt7__cxx1115basic_stringbufIwSt11char_traitsIwESaIwEE7_M_syncEPwmm
_ZNSt13basic_istreamIwSt11char_traitsIwEE10_M_extractIlEERS2_RT_
_ZNSt7__cxx1119basic_istringstreamIwSt11char_traitsIwESaIwEED1Ev
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE9_M_assignERKS4_
_ZSt9use_facetINSt7__cxx117collateIwEEERKT_RKSt6locale
wmemcmp
_ZNSt5ctypeIwE2idE
_ZTISt5ctypeIwE
_ZNSt7codecvtIwc11__mbstate_tEC2Em
_ZNKSt19__codecvt_utf8_baseIwE13do_max_lengthEv
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEE6resizeEmw
_ZNSt7__cxx1112basic_stringIwSt11char_traitsIwESaIwEEC1EOS4_
_ZTISt19__codecvt_utf8_baseIwE
_ZNKSt19__codecvt_utf8_baseIwE6do_outER11__mbstate_tPKwS4_RS4_PcS6_RS6_
_ZNKSt19__codecvt_utf8_baseIwE10do_unshiftER11__mbstate_tPcS3_RS3_
_ZNKSt19__codecvt_utf8_baseIwE5do_inER11__mbstate_tPKcS4_RS4_PwS6_RS6_
_ZNKSt19__codecvt_utf8_baseIwE11do_encodingEv
_ZNKSt19__codecvt_utf8_baseIwE16do_always_noconvEv
_ZNKSt19__codecvt_utf8_baseIwE9do_lengthER11__mbstate_tPKcS4_m
backtrace
backtrace_symbols_fd
sched_yield
sincosf
vfprintf
getpid
fork
waitpid
execlp
clock_gettime
clock
pthread_self
pthread_getaffinity_np
getcpu
log1pf
log2
stpcpy
pread
GOMP_barrier
posix_memalign
tanhf
expm1f
pthread_setaffinity_np
__sched_cpualloc
__sched_cpufree
GOMP_single_start
omp_get_thread_num
omp_get_num_threads
GOMP_parallel
qsort
strncat
_ZNSdD2Ev
_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE13find_first_ofEPKcmm
localtime_r
gettimeofday
_ZNSo9_M_insertIlEERSoT_
ioctl
usleep
mmap64
strncasecmp
_ZTIa
_ZTIb
_ZTIi
_ZTIh
_ZTIl
_ZTIt
poll
sqrt
dlsym
dlopen
dlerror
__fxstat
dirfd
fpathconf
readdir_r
readlink
strrchr
chown
geteuid
chmod
__xmknod
getpagesize
strcasecmp
__getauxval
libgomp.so.1
libpthread.so.0
libstdc++.so.6
libdl.so.2
libm.so.6
libgcc_s.so.1
libc.so.6
librkllmrt.so
GCC_3.0
GLIBC_2.17
GOMP_4.0
GOMP_1.0
GLIBC_2.27
GLIBC_2.29
GLIBCXX_3.4.20
GLIBCXX_3.4.17
CXXABI_1.3.11
CXXABI_1.3.2
GLIBCXX_3.4.18
GLIBCXX_3.4.26
GLIBCXX_3.4.9
CXXABI_1.3.3
GLIBCXX_3.4.11
GLIBCXX_3.4.14
CXXABI_1.3.5
GLIBCXX_3.4.15
GLIBCXX_3.4.21
GLIBCXX_3.4.22
GLIBCXX_3.4.19
CXXABI_1.3
GLIBCXX_3.4
?h 8
RAgC
R@  
R@H 
R@p 
R@("
R@P"
R@x"
R@@#
R@h#
T"C*
B@y?
T"C*
B@y?
B@y?
B@y?
B@y?
T"C*
B@y?
B@y?
T"C*
B@y?
fN@9eN
4fN@9
aJ@9
 nFxa
BxaN%xaN
xaN!xa
ja8_
/Gm!
'Fm@
@9!|
@9!|
@9!|
@9!|
@9!|
@9!|
4b2A
T`6A
h48 
h48 
Tb"@
R`"@
h58`
h48`
h58#
x{Z9X
h78b
awZ9
h48awZ9
Tu^D
T`'@
`{Z9
9`KB
T`^@
T`sZ9`$
T`"@9@
bsY9
TysZ9
`{Z9 
T`"@9
T`sZ9
4`&C9
5`:A
?h98-
`wZ9
*!@*
T`xu
TasZ9
T`sZ9
`sZ9`
Tc2A
5a:A
5`6A
Tp:A
k`:A
5a:A
T!x`
9`GB
T`:A
T`:A
Tu:D
Tu:D
@yib
@ygV
@9C"
 @9|
b!9a
<bp@
h#8f
h#8f
"`@9!
?h 8
aH`8`Hf8
H38s
tHt8`H`8
h&8_
h$8B
hd8"
`B@9!
`B@9
aB@9
Ahax
T`@@9
4`L@
TA@@9
4AP@
`@@9`
5@@@9
4@L@
TBk6
@9:"
8h78
?h68z
Z9 "
Z9 "
jZ9 "
Z9 "
h9 "
Z9 "
T`2@
bh48
bhs8_p
T`hu8
`h48
Tyh48s
Tyh48s
`h48
9chd8
{h48
zh48
@h48
R h48
Dh!8
%*B|E
%*B|E
%*B|E
#*B|C
 *B|@
obR"
!n"xa
!xaNA
obR"
N"xa
!xaNA
'Dmd
 nGxa
BxaN&xa
!xaN
p~Ct
Te|@
Rp@`
@9aB
!N@h
T@xa
h481j
!N h
"A9`j
2Y9b
Y9`"
B^9`B
y`B#
*c9b*#9
jSy`"'
?h58{
h58{
?h58|
h58{
?h58|
h58{
h58`
y"TC
h58`
h58s
h58s
T!hb8
T`FF
T`JF
 k`8
H#8c
cE9@
Uhy8
RAh98
2B9@
2B9 
<h:8
Ahax_
<h:8
Ahax
b@9!
2B9!
@+@9\
@9?|
rZ9@
T`fZ9 
Z9Zc.
RB`.
b#A9
*!`0
Z9`!
qB`.
Z9a!
qB`.
 @9 
@9b2
ha8!
H#8c
Sis8
Hf8aH48
QbH 8
?h38
SIs8@I`8`
9bN@
A,@8
Tab@
 h`x
!xbxa
T7h68
h48`
h48`
Tab@
!xbx
T9h88`f@
h78`
Tab@
!xbx
T9h88`f@
Tab@
!xbxa
T8h78`f@
h48`
Tab@
!xbx
T8h78`f@
h48`
h!x!
h!x!
2Y9bJ
rY9bZ
Y9ar
Y9a:
"Z9aB
!9_|
*c9bj
c*#9"
jSywb'
@9@c
j48`
@9@c
j48`
@9`C
j48`
@9`C
h58`
@9`C
yi;8
R h"8
?h;8
Ah`8
H#8c
Vhv8
Ah`8
H#8c
h{8 
h58`
h58`
h58`
h58`
T`n@
R h98
?h48
T6h88
h78?
R h88
?h48
h88_
 h`x (X6
 @@9
h38B
Ahax
hcxc1X7a
4Sxa
h68s
h38_
h38B
h78s
h68_
 @@9
43d@
h68s
h58?
h58?
C@@9
43h`
h68s
C@@9
43h`
h68s
h68s
h58?
R h58
CA9_
CA9?
CA9?
Tcb@
qd.@
Tcb@
qd.@
T`Z@
k48S#
bB@9
aB@9c`
T  @9
h48`
!k38
 ks8
*!LG
9bN@
A,@8
 h`x@
Tbj@
Tab@
ahax?
h68`f@
h58b
Tab@
ahax?
h68`f@
Tub@
@9wR@
*BLG
87`"
Tcb@
ahax!
*BLG
Tvb@
Tb^@
6ajc
@9?x
Tcb@
hcxC
@9ab@
!xbxa
T7h68
h58`
h58`
h48`
h48`
h48`
T\S@
=`b@9
=`b@9
=`b@9
=`b@9
=`b@9
=`b@9
h:8z
h;8@!
=`b@9
`R@9
=`b@9
Zaxb
R!`/
R!@.
R! 8
R!`4
R! 3
R!`?
R!@>
R!`9
R!@(
R!@#
=ab@9
=`b@9
=`b@9
=`b@9
`R@9
h88A!
h48`
=`b@9
R`b@9C
T4h88
R`*@
`b@9C
yBB9
h88`*@
h48@!
=`b@9
R`*@
h48b
`b@9C
h98`*@
h88@!
=`b@9
T4h:8
h88`
=`b@9
TaR@9
T4h;8
aR@9
aR@9
`@9c
`b@9a
`B@9
`b@9`
ab@9
ab@9`
T`b@9a
`b@9a
`B@9`
=`b@9
=bb@9
=bb@9
`b@9!
T`b@9a
`b@9B
ab@9`
=`b@9
=bb@9
=bb@9
=bb@9
=`b@9
=bb@9
=bb@9
T`b@9
`B@9`
h68u
T`Z@
h68u
6bjc
Tbj@
9`dG
T x`
9cZ@
j48`
T`:@
Tcb@
qd.@
9bJ@
Tcb@
qd.@
Tcb@
qd.@
Tcb@
qd.@
Tcb@
qd.@
Thx!
THx5
R@hu8
R@hu8
@	P7`
T`Z@
"Bz(
T`Z@
!hyx
T`6@
!hyx_
9 hC
LAhE
T`Z@
T`:@
!hux
T`Z@
T`:@
!hux
LAxG
TvjC
Tvb@
!hxx
`B9?
T`:@
!hxx_
@9a6@
Tvb@
T`:@
!hbx_
`B9?
!hbx_
`B9?
9 xF
LA,E
T6h78
b@9@!
 7a6@
b@9!
*c\P
@9{C
#@@9
Tcr@
Tar@
dkc8
 hb8
T`2B9
`2B9
 hb8 
c@9!
*c\P
@9{C
t2B9
`2B9
"@@9
j|8c
A@@9A
5b"@
TBx`
B9`b
B9`b
B@9`B
@9aB
T`^@
h78v
T`Z@
b@9a
R!@$
#E9@
R!@$
#E9@
R!@$
#E9@
R!@$
@h|8
`hb8B
R!`%
T3h68
e$@x
xex"
R!@$
`	 7
Ay"$
Ay"$
R!@*
R!@(
cA9@
xex"
R!@$
Ay"$
Ay"$
R!@*
R!@(
R!@*
xex"
R!@$
`	 7
R!@(
cA9@
R!@*
@9`:@
xex"
R!@$
R`:@
4`6@
R!@(
gA9^
@hu8
R!@,
R!@,
T`~@
R!hs
@H-c
CA9t
! @9A 
!@@9
?h 8
m	(H-
TxrA)
q`*@
l6B-
n>C-j&D-
TA))
R`Z@
B @9
	!@9
@ @9
@ @9
T@$@9s
` @9
` @9
@9_p
@9Ax
h68#
H#8c
@8?4
@8_4
@8_4
@8_4
h<8n
@8_4
h#8B
@8_4
T`B@
@8?4
Ta"@
SIs8@I`8
H#8c
sIs8`I`8
T  @
h&8_
h$8B
hd8"
`B@9!
`B@9
aB@9
Ahax
  @9
  @9
T6P@
6hu8
9h58
2B9`
c@9!
R!`F
2B9!
@@9A
T6h58t
6h58t
T!hb8
Bha8
ch`8
@z+!
y"TC
@9@C
@z!	
 @9  @9_
T k<
A@@9a
h58?
T`Z@
h68u
h58?
8che8
R h58t
8chd8
8chg8
R h58t
H#8c
Sis8
Bha8
hc8S
wk:8Z
Rbk:8Z
Rak 8
yk:8Z
yk 8
Rbk:8A
ak 8
Rbk:8Z
ak 8
Rkk"8d
Rfk!8
Rck 8
Rck:8Z
ek"8
dk!8C
ck 8
Rbk:8Z
ak 8
Rbk:8
ak 8y
Rak:8Z
yk 8r
Twk:8Z
@9`B
T`"@9 
 @9E
" @9_
" @9E
TB|@
0A)!
|	Sep
R$		
aj`8?
ajd8?
Qaj$8a
aj`8?
Qaj 8
bjh8_
Qbj(8b
*a2A
8`h`8
*a2A
5`r@
@@9B
9wh$
9uh 
3D9_
Je8`H38s
QaH"8
Ha8a
Rb&@
Tha8
 @9?
 @9F
h98`
T@ha8
#D9"
hk8&
# @9_
# @9i
T9h78
h68`
#F9"
7h68
h48a
7h`8
T6h98
h78`
6hb8
C9`r
H#8c
T	x(
Rb )
J)wXu
5`*@
Tc(@
38 *
4vfA9
4yfA9
4$|@
R!hd
Tt~z
4szJ
TA#D9
G9W[A
T$#@
?h38)
?h 8
@X`xb
?h 8
?h 8
?h 8m
! @y
?h 8N
!@@9
?h 8
h38 
T@ @
T  @
T` @
B@9U
T  @
B@9`
T` @
B@9 
Ta+@9`(@9?
E$?)D
Xbxa
7u{s
Xbxa
7u{s
 H`8a
Ta @
!Xdxb
TA @
TAii
7`~@
T@ig
TB @
4 |@
TSxc
TSxc
_.?)I
c	9!
Ks~~
O9 *
4 +K
0@)B 
* CC
c	9!
/"@`
H;8{
Hf8AI;8{
QBI#8
Hf8AI;8{
QBI#8
Hf8AI<8
QBI#8
Hf8AI<8
QBI#8
Hf8AI;8{
QBI#8
Hf8AI<8
QBI#8
Hf8AI;8{
QBI#8
Hf8AI;8{
QBI#8
Hf8AI<8
QBI#8
Hf8AI;8{
QBI#8
Hf8AI<8
QBI#8
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
Ha8A
H"8B
#H`8 Hd8C
Hg8@H78
QAH#8
Hg8`H38s
QaH"8
H"8B
@9`H38s
QaH"8
Hg8`H38s
QaH"8
AH`8@Hd8a
H`8a
H`8A
$Hd8 H`8d
9@h38
Hs8 
hv8a
H`8a
_h38
h58B
?h88
?h 8
?h 8
TA @
T!ih
T! @
R`ig
@d9`;
Tk&B
Tax`
@d9"(
T!ih
T!|@
T)zk
T!|@
7A{ 
"@d9
"@d9.
_8!#
T '@
T '@
@)$'@
@9@8
@d9@
4`*K
@9Zd
@9#W
T  @
4#4@
9`*K
T  @
O!P$
T$|@
OAP!
O`P 
TAX!
T@X 
O!P"
T`X 
5 +K
T +K
OAP!
N@)s
N@)s
A)"@
4!H6
A)"@
A)"@
T`R@)
T`R@)
h58"
y"TC
A)"@
T  @
Ta&@
Tb&@
Ta&@
Ta&@
@)c&@
T" @
T" @
*`Z@
N!P"
*`Z@
T" @
T" @
T" @
(g9 "
#@d9
5`2J
Tu&J
T`*K
5y_[
TaC@
TaC@
CF9@W
CF9@[
5y_[
5y_[
Xaxa
@9`B
_h!8
`B@9
R!HN
	TO,
	TT5
_	T/)
 n	T@
E	T@
T  @
Te @
T` @
T  @
Te @
T` @
T" @
T" @
T" @
TA @
!#D9
h58`
T`&@
h58`
Tab@
D$9`"Y
75[@
 X`xa
* [@
TbJ@
@q`g
T`B@
T [@
* [@
T8[@
T`B@
@q 4
0@q`
Xaxa
h38!
P@9`
TaB@
T" @
TaB@
T" @
TaB@
T" @
N9@t
 D@9
4$H@9c
9e~	
@9X;
?h78
?h78
?h78
T" @
T@ @
T" @
T !@
T` @
TB!@
T@!@
T` @
T-BLK
*@D@
qx2@
RdB@
T-BLK
R`v@
Qjv@
TAH@
R`v@
R`v@
*B@@
4T@@
TAH@
#C9 P
TBxu
T:8A
TAH@
#C9@<
TBxv
TAH@
TBxv
4[lH
TAH@
TBxs
TAH@
R`v@
`"C9@u
T`n@
TBxc
R`v@
R`v@
4[lH
TAH@
TBxu
4ZlH
#C9`6
TBxs
TBxv
4XlH
T"D@
4ZlH
TBxs
4[lH
+V)E
TBxt
T @!
TBxu
4[lH
TBxx
#C9 @
TBxt
TAH@
TB|@
*Xhs
TBxu
RB|@
TAH@
TBxu
4ClH
TBxs
4ClH
TBxu
T@H@
TBxu
4ZlH
#C9`6
TBxs
4ZlH
TAH@
TBxs
TAH@
TBxs
TAH@
#C9 B
TBxv
jpb9
TBxu
KFo@
R@w@
@#C9`|
T`w@
Rio@
TBxu
T!8A
R@w@
TBxv
#C9`L
TBxv
R@w@
@#C9
@#C9
*@L@
4@P@
T-@w@
T-@w@
L+V)A
T@w@
RJo@
TBxv
R@w@
R@w@
TAH@
TBxu
TBhx
4c@@
R`w@
`#C9`Q
Rio@
TBxx
l+V)
R`w@
T`o@
R`w@
TAH@
#C9`:
TBxt
T @!
T @!
T @!
#C9`L
TBxt
*@D@
*yl@
4ZlH
TBxs
TBxs
TAH@
TBxu
R`w@
`#C9
TBxu
R`w@
4ClH
RB@@
Vi`w@
`#C9 
R`w@
R`w@
`#C9
T`w@
*do@
TBxu
R`w@
R`w@
4ZlH
4ZlH
TAH@
#C9 P
T-u{
TBxu
T:8A
9e~	
6@xa
 @9`
5tVF
{c@9
7g&@
7y&@
@9@C
T" @
"B95
T" @
T" @
T|VB
@9ab
) [@
a#D9
T  @
T $@
T" @
R [@
h38 [@
_h!8
3C9 
Xuxa
T  @
* [@
* [@
!@D9
9 k@
aB@9
TucC
jz8A
ab@9
TvN@
7y&@
bhb8
j"8_
/6 '@
 '(6?
T7h:8
h88c
_h 8
	@9Mx
ekf8
k&8s
T`'@
T   
T#C@
T#C@
4V4@
!hu8
!ht8
!hy8p
!hz8q
!hz8T
!hy87
T@(@
T@(@
T@(@
!hy8
!hy8x
!hy8[
!ht8>
	hc8$
	ha8E
TvR@
$h{8
@9@ 
h787
 X`xa
h#8u
h#8^
h#8G
) @9l
 @9'
?i%8
"@@y$
C@@yD
T`*@
@9 4@
it8=7
it8J
eif8
T	hg
@9`B
*06A
T`*@
!hw82
!hw8
!hw8
@9`c
h88A+@
C9au
hw8[.
h:8a
9a*@
h"8_
9a*@
ab@9
b@9 
Ts~<
h68`
TyZ@
T`R@
T`R@
T`V@
T`V@
 Bzi
T	x(
T0 "
T0 "
T0 #
T0 #
T0 #
T0 #
Tp !
Tp !
aH@Lc
$H@L!
T`zc
T`za
T`zb
mL@ 
T)A!
!H@L
!xaN
 haN
 Naj
B@9s
TaN_
R:| 
Ru~@
'Fm!
T (@
T 4@
m	@ 
Tc|@
xaN!
T"$@
m)@ 
T`"@
T`.@
T"$@
h&8_
h$8B
hd8"
RB(@
`B@9B`
`B@9B`
`B@9B`
`B@9B`
aB@9
Ahax
hc8b
h68`b@
_h68Pi
Ta@_
QfD$
`X$|
`X |
`X!|
`X |
`X!|
`X |
T`X$|)
bh`xB
2bh xA
bh`xB
2bh xA
bh`xB
2bh xA
bh`xB
2bh x
T  H
T xs
  @9?
  @9
 @9?
 @9%
;hy8
6h98
c@9`
2B9 
R!8F
2B9 
c@9!
2B9!
;hy8
6h98
c@9`
2B9 
_89C
2B9 
c@9!
2B9!
T @@9
@@9!
#@@9#
6Ug@
 h58
T5h:8
Tgze
@@9!
#@@9
T# @
h58%
"`@9!
_h!8
T  @
h58c
hs8p
T  @
T@ @
*B @
*B @
*B @
RB @
RB @
RB @
RB @
*B @
RB @
RB @
RB @
RB @
*B @
RB @
*B @
RB @
T`b@
*c0@
A,@8
T`b@
T`b@
T`b@
TaZ@
C @9
C @9f
$ @9
bB@9
aB@9a
bB@9
aB@9a
A,@8
Tbj@
T`b@
T`Z@
T`b@
87u"
T`b@
*uR@
T`b@
Tb^@
6ajc
T`b@
6bjc
Tbj@
@	P7`
A9b:@
A9b:@
A9b:@
6h78s
6h78
' 7`6@
T`"@
b@9!
*c\P
#@@9
Tcr@
T`r@
ah`8
 hb8
T`2B9
`2B9
 hb8 
c@9!
*c\P
t2B9
`2B9
"@@9"
b@9a
TA@@9A
% 7`6@
T`"@
b@9!
*c\P
@9{C
#@@9#
Tcr@
T`r@
ah`8
 hb8
T`2B9
`2B9
 hb8 
c@9!
*c\P
@9{C
t2B9
`2B9
"@@9
b@9a
TA@@9A
*@xt
R@xu
R@xu
*B @
*B @
R!@$
R!@$
R!@$
R!@$
R!`%
5h68s
Rc0@
5h68
Tdxb
k" BzH
T`&@
T`6@
*B @
b@)g!
T`&@
T`6@
*B @
T`&@
T`6@
*B @
*B @
#Ay!
R!@$
R!@*
R!@(
a! 6
#Ay!
R!@$
*B @
*B @
*B @
*B @
*B @
*B @
*B @
R!@*
R!@(
*B @
T#k"
R!@*
#Ay!
R!@$
*B @
*B @
*B @
*B @
*B @
*B @
*B @
R!@(
*B @
R!@*
#Ay!
R!@$
R!@(
R!@,
,(6 $
T x`
R!@,
 x#|c
o!T0O
T0Oa
T0O h
O$(a
(aN`(a
@(aN
0/#(a
. h$
%h'x_
2c|@
%h$x_
 h#x
o!T0O
T0OBT0O!
"n"xa
!xaN
xaNA
T0O!T0O
xaN 
p~c(`
hfxhhfx@
hgxghgx@
`hfx
xc|d
xd|e
xe|c
x!N"x!
 x!NB
#nAxaNBxa
xaN!
p~"q
	k`	
hb|ahb|
hd|ahd|
`hd|
`hd|
`hd|
`hd|
hb|ahb|
NSD@
!n"u
"N h
!nbh
m	@ 
N!P3
NBT7O
/Emsv
mh@ 
@-!|A
!^c\%
x!N"x!
 x!NB
#nAxaNBxa
xaN!
p~$q
	k`	
@hd|ahd|
`he|Ahe|
@he|ahe|
@he|ahe|
@he|ahe|
@he|ahe|
`hd|Ahd|
!n$u
!n$u
O$(a
(aN`(a
@(aN
0/#(a
. h$
%h'x_
2c|@
%h$x_
 h#x
<#x!N!x!
!hd|!@
@}!@
<#xaN!xa
TB@b
/BT0O!T0OA
/!T0O!
Bh`xA
LA) 
Y-B8'
!^B\#
T!A 
T#LJ
5j"@
* T@
L)iJ@
5j"@
*&l@
L)iJ@
T?x1
h#8b
T #@
h$8b
h$xb
h#8b
5$T@
4!|@
T"||
R9C<
*A\@
TA}~
T x`
m(T@
K`|~
Bx!N
bib|
Tb	@}B!
@}B1
@}BA
@}AQ
@}@a
T`|@
Ta|@
*b{C
5tR@
Tbka8_
KB|~
T+T@
5t$A
g@)x
TO~@
5t$A
[@)x
$@x"
5slA
$@x"
_@){fA
ScP"
[@)F
ScP"
*-|~
TBh|
TBhl
TBhk
p@)X
@}!@
%Nch!
%NBh!
%N!h!
ha|aka|B@
ak!|!
Tb{a|B@
b{!|!
`kc|
U]@)A
S!P"
SAP!
"NAh
"NAh
"N!h
TAht
TAhg
TAhc
"N!h
T#|@
 H`8a
Ta"@
Ta&@
@} (
*!|@
n#hs|"xs|!hf|
n @@M!
!hhx
!hhx
!hhx
!hhx
!hhx
!hhx
ahhx
nchs|bxs|aha|
n`@@Mc
*`|@
@id|
x!Na
 hc|A
8\@)
o!T0O
T0Oa
TD	@y
)ifx	h$x
n#hs|"xs|!hb|
n @@M!
o!T0O
Zkfx@
^k`x
9kfx 
Ekyx
@y <
o!T0O
T0O`i
)i`x@
Ah`x 
`h |
O$(a
(aN`(a
@(aN
0/c(a
n!(a
i&x_
i x_
T~|@
Bz@.
*8$@
T@) 
hh|@hs
@}& 
@}&0
@}&@
@}&P
@}!`
Ta"@
Ta&@
Ta"@
T`&@
T# @
y^@)(
*!@'
T	|@
tN@)(
 h`|
@h |
tN@)(
=!~@
o!T0O
T0OA
O$(a
(aN`(a
@(aN
T"hsx
$i-x
T"hqx
$i-x
T"hux
$i-x
T"h|x
$i-x
T"h~x
$i-x
!hbx 
"i+x
!hcx@
#i xJ
TtN@)
	*k}
{j@)!
o!T0O
T0O!
O$(a
(aN`(a
@(aN
chax`
$i-x
chax
$i-x
chax
$i-x
chax`
$i-x
TBh~x
#i+x
Bhax@
#i+x
Ahax 
"i xJ
zf@)(
	*;}
TAh`
n`h 
T@hp|
`h0|
T@hm|
`h-|
T@hn|
`h.|
 hcx
S@h#xc
2Dh#xc
@h`|
`h |
T@h`|
`h |
@hax
S`h!x!
2dh!x!
So~@
5"T@
`&@)'
*`|@
$nexaNcxa
DxaNBxa
T"x`
Tajt
Tajm
Tajl
T`jt
T`jm
Tajl
ka|@
<Dxa
BxaN
T$hc
Q@d 
KB|~
Qc|@
QC|@
TE|@
TuN@i
*l|~
T hg
T hl
T hw
*D|@
T hg
T hl
T hw
Raid
T# @
T $@
T	|@
 NBh
T!hw|`h|
T!hm|`hq
 h`|
 h`|
 h`|
 h`|
!h`|
<cT0O
T0OB
 Nbh
T0O 
 N`h
@yB 
Td|@
!x`|`x`
T!x`|`x`
Q`|@
n h$
hq|Ahq|
 h1|?
T@hp|
 h0|?
T@ho|
 h/|
T0OcT0OAT0O
T0O!
O$(a
(aN`(a
@(aN
i0x?
i0x?
Tghux0
Ehux
i0x?
i0x?
i0x?
Tch|x'
Bh|x
i'x?
@h`x
Bhdx@
=c|~
cT0OBT0O!
O$(a
(aN`(a
@(aN
Thhjx
Thhkx
hhix
hhix
hhix
chhx
chfx
bxdx@
@x`|!x`
 z |
@hc|
 h#|c
Dhax
`hax
h!x!
h!x!
5tVJ
T\|@
T\|@
T|VA
T^|@
ScP"
K@|~
@yjj!x
@yjj!x
@yjj!x
@yjj!x
@yjj!x
@yjj!x
@yjj!x
6jjxvj*xJ	
#h"8
r;@1
7Hmi
bB@9!
F@9A
T`N@
T`S8
!^C 
dJ@9
T`P"
aJ@9aF
Teh$8
`h$x
!^`h$
`h$|
^`h$<
`h$x
5`h$
^`h$|
`h$|
^`h$
bh!x
TuR@
!N@h
T@je
T`je
TuR@
j3|s
TuR@
TuR@
^@)8
N!T7O]
5uR@
Ez)L
T`hm
T`hp
TvR@
#NB@
SK}~
T@je
T`je
O+~~
!N@h
T`jd
SO}~
SO}~
 n h
T x`
T x`
T_x 
T x`
T_x 
h"8B
T#hb8c
aNar@
Tbz@
"D9`
/Em`
T`N@
T`N@
T`N@
/Emb
T`N@
TuN@
TvN@
*"L@
TvN@
TvN@
/Emb
/Emb
/Emb
/Emb
+$Dm
/Emb
+$Dm
/Emb
TuN@
*yh<
TyN@
TaN@
TuN@
*5L@
*5L@
*5L@
*5L@
m	@ 
'Dmw
5`~S
7Gmz
5`~S
7Gmz
7Gmx
7Gmx
m+@ 
Rc(!
Tc|@
T	@ 
RB|@
'Emy
T`N@
5aN@
5cN@
TaN@
T`N@
T7L@
*"L@
*"L@
mJ	#
m6h@
*,O-
4T@)
7	mn
 ja|
h#|@j:|?
'hgx
gh x@
'hgx@
gh x@
!hgx@
ah x@
ax |
 j`|
h#|@j6|
*,O-
7	mA
D8@z
 X`xa
mhW@
'Fmm
'Fmg
m`W@
K'|@
T x`
m`W@
K'|@
T x`
'FmI
F@)bZA
T xe
axaNcxa
T!ht
T!hx
TaKC
b@)fOA
T`W@
T@@ 
 n@h
T`~@
'Fm;
N@)N=A
Ts~@
TaS@
*bW@
#N!i
TAjd
Tajd
T?y!
T.h'
T`W@
mj[@
^@)z
T@A 
/Gmc
/GmZ
*aW@
$N"h
Tbjd
5bW@
kF|@
Hzhxhz x?
Hzhxhz x?
Hzhxhz x?
Hzhxhz x?
Hzhxhz x?
Hzhxhz x?
Hzhxhz x
hh`xHh x
Thh`xHh x
@zbhf
5c+A
m"A 
T jc
T`jc
/Gm5
'Fm#
5vS@
md'A
J@)$
TR~@
'Fm5
'Fm/
'Fm)
'Fm#
5ao@
T*}@
*6d@
TA{d
Qf[@
 X`xa
T!O@
T<O@
T`O@
T!O@
T"O@
Ji@*
T@O@
T<O@
T!O@
5<O@
T:M@
6cxb
6cxb
6cxb
T@xs
T"S@
T S@
T S@
T W@
T S@
Jb8a
*"CF
T"S@
T!W@
T`~@
a2@)
TbJx
T`J@
T`N@
T`R@
T`V@
7fN@
7@O@
Tax`
@#D9 
r@S@
T\cA
*Uxw
Tdx`
Tbx`
T`V@
T@D@
E-`$@
a8G-
m<H-W
 @B9 @	
* 	 
!^!A 
T@xa
!n"xaN!xa
T@D@
K9`o
Tk	(
"N!h
T`xb
Tc}@
K9@	
Q@|~
"N!k
T!jz
T!jl
T@\@
Tg~|
Xsxa
hc8Dhd8
h#8c
T`"@
5`b@9
T`b@9
T`2@y
T`2@y
T ;@
<!8@
<!8@
T`b@9
5"x@
`@9"
7"y@
T# @
T"$@
T*y@
Tbxa
Tbxa
Rail
@`@9
TAh`
R!xu
Tb{@
*a&@
Ta"@
Ta&@
Ta"@
Ta&@
 @9a
  @9`
  @9`
  @9`
@ @9`
@ @9`
  @9
Tt*@
T!|}
RKyg
T+cA
T$cA
T`Q@
Tvk4
Txk4
TcbA
T`7@
Ta_@
T`S@
jd8"
j$8`z@
_t@-
~p@-
[dA-
z`A-
WTB-
vPB-SDC-r@C-
@y#=}
VP@-
uL@-
R@A-)E%
Qc|C
D'A-l
C-x  
B-J	/
/7G-
=J	/
Tc@!
RX  
TB@!
2)A!
7` "
PQBX
@zl<
*I)	*
Tc@!
WW-s
	k'X
gF-n	+
n+++
n7+7
nk2@
nm:A
TB@!
*8  
T!@!
*x  
2c@!
q!<	
qk=	
	*	9
Sk	"
]-+,
PQBX
o^-s
@z,7
*I)	*
R	@ 
t$@-+ 
PQhX
n,+,
	k'X
Y-H<
PQB<
k]-v
\l@-
ZdA-
X\B-
VTC-
@yD<}
Q*}I
9D|B
Qc|C
B-c|
QB|B
2a@!
2G@!
2(@!
"N8  
 n,!
@zl+
/H9cD
N!T<O
T<O!
A-@1
PQ'X
'N8  
?	m@
2`@!
2@@!
2'@!
"N8  
9${b
H9cD
@-hP@-
N!T<O
T<O!
A-@5
PQ'X
#NX  
Qx! 
T`A!
T A!
2,@!
Oo)a
N+*a
+(aN
a)!N(
o/)a
!NI*a
	)aN
()!N/
!N!R
2N/Q
!Nkm
/n)m
/nkm
!Nkm
p)aNs
*!N)
.nsn
4N)m
+Nk*a
+)aN
)nRn
O*aNR
!Ni)!
)!NW
Z@-Q
n (!
+N8  
-	 @-B
-E0@-
R`A 
A@-k	1
BA-a=
&B-r=
"C-q=
"N8  
?	m`
d@-`" 
Rc0A
mM,A-A
^0@-
J$B-H|C-
n!(!
/b0A
R%hd8Dxd
#h$8
Tp! 
mn9(
Nv^@
/NRn
!NBl
T(aN1f
;n5*a
U*aN1
*!NP
!NBd
!NN(a
)aNcd
"no(a
)aNC
Tn6B
%NRf
0NZ*a
(aNn
.NN+!
2NtJC
?Hm(
=oJB
NtNC
=NRf
!NBd
!NL*a
L(aN
!NBd
G(aNB
@9  @9
@9$ @9 
"k`8_<
Tak`8B@
*ak 8
h`8#@
*bk`8B
*bk 8
E(aNd
NB)!
(!NB
(aN!d
N"(a
(aN@)!
@(!N@
NWXA
NY`@
+nK*!
NO8B
#NM0C
!NJe
(aN2
1nBd
'NG)a
G(aN
$nc)!
(!NB
2N0<
!nX  
NG<B
(aNcd
Ng(a
NWXA
NY`@
!NBd
P(aN
NL,B
dncd
!NId
!NM)a
-)aN
*n!d
/Nk(a
+(aN@
b)!N
>wA-
<oB-
:gC-
RC-R
BD-1
A9B(
DoF-C{@-BwB-AsD-Z[A-YWC-XSE-
WCG-9+
Nd(a
D(aN"(a
@(!N
[Y--@
Nd(a
D(aN"(a
@(!N
"N!T
"N!T
Sai"8
* i"8 
*@i"8B
D9e|
D9b/
@9  @9c
@9# @9 
E(aNd
(!N"
(aN!d
N"(a
@(!N 
RC@ 
T0 1
9@ym
T0 0
TAie
Tx  
TH" 
@@9 
D@9 
H@9 
L@9 
P@9 
T@9 
X@9 
\@9 
`@9 
d@9 
h@9 
l@9 
p@9 
t@9 
x@9 
<@9 
T0 #
QCA-
O;B-
M3C-1"
K+D-c 
9?-k	&
-)	$
E-B(!
?- (*
X@- 
PQcX
PQ_<
PQcX
PQ_<
+Z-dX
PQ'	'
kF	&
T(  
rel@-
PQcX
PQ<`
PQ_<
PQcX
CE9Z
WE9R
wE9Z
_E9B
kE9A@
gRF-c
</f^@-eZB-c
!^dVD-s>A-g
r:C-o<
q"E-G`
pfG-rH
(aNd(a
D(aN
OT(a
4(aN
`*!N
f(aNB
l0NC(a
#(aN
a(!N!l0N
TB8!
<!@}
W(aNb
*!N!
l1ND(a
$(aN
(!N!l1N
N~+a
~(aNB
=(aN
N{o'N
+aN 
}(aN{
<ocl'N=
<oBD
$NcT
R"C 
TB8!
+aN>t~
Nh+a
((aN
+!N=
<oBD
#N{W
0(aN
F(!N
e(aN"(a
(aNF
@(!N@
P(aN!
!Nt*a
T*aN
*!N`(a
 (aN
(aNB
(!NC
 _8^
0_82
`_8p
-7X	-1
_8F|
 _8l
0_8K
-1@	-9h
_|Vd
nY+a
Y(aNzD
(aN`+!
 +!NY(a
+aN"
OX+a
x(aN!+!
NY+a
Y(aNzD
(aNcD
n`+!
 +!N=
NY(a
+aN<
NX+a
x(aN"+!
-8D-
/@E-
1HF-3PG-
Tp  
Tp  
Tp  
Tp  
TP ,
Tp ,
TP -
Tp -
TP .
Tp .
TP /
Tp /
TP 0
Tp 0
TP 1
Tp 1
TP 2
Tp 2
TP 3
Tp 3
TP 4
Tp 4
TX  
T@ #
Tu8"
)aNk
+!N|
(aN$(a
(!Nm
TB@!
@}FLB-B@
EHD-DDF-&
CP@-$
P0A-#
O,C-0@
N(E-,0
M G-/<
Nd(a
D(aN"(a
@(!N
TB@!
4@-	H	
0@-J
@-)@	
A-#@
M@9	Q@9
Tb @
Tb$@
Tb(@
Tb,@
Tb0@
Tb4@
Tb8@
Tb<@
!N!d
?nM(a
(aNN
!N,(a
l(aN
$u@-#iB-"aD-!YF-.)A--%C-,!E-
+yG-
h(aN"(a
@(!N
h!8m
ic8`
*%AZ8
%QZ8
*%aZ8
Z8G|
%qZ8C
$!Z8
$1Z8
%![8
%1[8
%A[8
%Q[8
%a[8
%q[8 
` @9
`$@9
`(@9
`,@9
`0@9
`4@9
`8@9
`<@9
`@@9
`D@9
`H@9
`L@9
`P@9
`T@9
`X@9
`\@9
``@9
`d@9
`h@9
`l@9
`p@9
`t@9
`x@9
`|@9
Tp" 
Tc:%
!N!l
,N^(a
<(aN
.nBd
Q(aN
-(aN
N$*!
)!N!
!N<*a
!Ncd
,Np(a
2ncl
|(aN@
+!Nc
 nx  
|-SDA-
@9A @9
@9@ @9A
!nP !
(aNcd
Nd(a
D(aN
,Ncl
g(aN!d
N"(a
@(!N
@9a @9
b$@9
!N	 
@9d @9)}
@9!|
*d$@9
Tp" 
Tc:%
!N!l
,N^(a
<(aN
.nBd
Q(aN
-(aN
N$*!
)!N!
!N<*a
!Ncd
,Np(a
2ncl
|(aN@
+!Nc
 nx  
 nl%
|-SDA-
@9A @9
@9@ @9A
@9J}
h`8_<
h`8B@
h`8#@
h`8b
!nP !
(aNcd
Nd(a
D(aN
(!Nb
,Ncl
g(aN!d
N"(a
@(!N`
C|!@
	-a	
@9% @9
"$@9
@9# @9%
@9p|
*#$@9
[Z-2,
Nd(a
D(aN"(a
@(!N
"N!T
"N!T
i"8 
*`i"8B
id8#
id8f
id8!
D9c|
D9B|
[D9k}
'D9k
gD9J
kD9{
/D9)}
oD9Z
3D9{
sD9)
wD99
;D9i
D9B@!
D9J}
D9)}
	*1~
hc<G
[|1B
Ajo8
!|	SPhn<Ghm<Fhl<
!^Ehk<
!^Dhj<?
Chi<
!^Bhh<
!^Ahg<c
-P@!
@9!%
aIa8
[|+	
>ie8
h`<R
@=TB!
T^ie8
S!|}
8s~}
@9(B
@yB|
*!0V*
nc|}
@91~
@9~|
SL @9
SK$@9
SJ(@9
SI,@9
SH0@9w}
SG4@9V}
SF8@95}
SE<@9
SD@@9c
CD@9
{<BH
r<z|
x!NA
@|1B
_8Ep_8
TH  
%NBl
R(aN!l
N"(a
(aN@*!
@(!N@
+NcX
*NsZ
+NRZ
2NBX
'NX@@}
(`Nc
s*`N
*`N!(`Np
B(`N
(`NB
c(`N
2nB*1
@91"
w @9
Sg$@9
Ql(@9
f,@9
Sm0@9d
z4@9
j8@9
b<@9
Qe@@9
dD@9G}
Q`$A|J-
1nB*1
oPD@}f
`]|Zp@
D@[|]
*`N1
(`NB
1*`N!(`N
NB(`N
(`NB
^C*#
P @9
G$@9
E(@9
H,@9
F0@9
D4@9
C8@9I1
I<@9^*
Y@@9
WD@9c|
EH@9*
DL@9)
@}f"
[|Hxh
 @}Gxg
]|`@
B(`N
(`Nc(`Ns*`N
(`Nc
N!(`N
(`N!
B(`NB
1n"*'
NCdA|
.)aNc@
o)aN
)!NJE
<m)a
M)aN
$B|+)a
})!N
NC	#
#D@}
A ^|c@
N#h@
3@[|
\|R*`N
!(`N
(`NA
*`Nc(`N
*`NB(`Nc
*`NB
^c(%
r_8)-
_8	|
oM)k
_8B	
_8"	
]|s*`N
R*`N
!(`N
(`Na
*`Nc(`N
(`Nc
"nD(1
h`|Bh
q)`N+
+`Ni)`NX
*`N5
@Lw=
*`NB(`N
s*`NJ)`NJ
(NsR
^2)`NJ
^))`NI
@L^=
c(`Ns*`Ns
N2(`NA
!(`NA
@Lo>
1*`N
(`N1
)`NR
c(`Nc
))`N
)`N,
+`Nk)`N
S-G-
0X n
8NcT	O
'NBT	O
'NL 
 @L_
^ (`N*
J+`N:
NZ+`N
)`NZ
c(`N
+`NB(`N!
!(`Nz
Z+`N!
Z npZ n
-NB|
+No4H
@LgTP
(`N^
^B(`N9
=c(`N
+`NZ
^c(`Nk
^s*`Ns
@LB(`N)
9+`N
^!(`N1
^R*`Nk)`N2
+`N1
!(`N
(`N!
Nc(`Nh
=1*`N
=9+`NH
+`NX
)`NJ)`N))`N
O4"@LcT
s*`N
)`N8
S @L
+`Nk
k)`N
/Jm9+`N)U
^!(`N
SKm)
)`NR
^B(`NR
c(`N
^s*`N!
*`NJ
(`NR*`N
^B(`N1*`Nk)`NB
*`Np
!(`NJ)`N
*`N!
N))`N
5NH 
 NZW
^Z+`N
NB(`N
^!(`N
*`N!
NR*`N
+`NR
N1*`N
*`N1
N{+`Nc(`Nc
Ns*`N9+`Ns
nrxr
!^yxj
nc('
[FmU
s*`NB(`NB
R*`N!
!(`N
(`N 
 _xr"
_x1>I
@_xJ=I
	`_x
L)!@
nrxm
nUxf
WEmT
(`Nc(`N
*`NB(`N!(`N
(`Nc
c(`N`
!nil
#Ndt
5N@|
1*`N
^!(`Ns
GFmU
s*`NB
B(`NB
^s*`NR
^R*`Nr
OHm!
1*`N
(`N 
LDxo
 _8U
NSxv
p_8Exs
P_8o
nBxn
0_8nPN
_8Cxp
N[xk
nAxl
nCxj
n@xh
nWxp
[Emt
s*`N
!^B(`NB
OFmc
!(`N
(`N 
jc8f|
!Dgn
Dgnc
#N3<
8NX!
*`Ns
*`N!
B(`N
Ims*`N
@yB 
xR*`N
(`NF
(`N!
!(`N!
1*`N
(`Nc
c(`N
e	@9B 
ShE@
`|)	
<{+`N9
9+`N{
<9+`N
B(`NB
+`N9+`N
*`N7
c(`N
^!(`N!
JmZ+`N
NB(`N
+`NB
!^!@
^@@@}VT@
R*`N!(`N1*`N
(`NQ
!(`Nc(`NB(`N#
!(`NA
Si @9
9e$@9(&
m(@9
j4@9F
l,@9Q
i0@9H
~8@92
f<@9
e@@9
mD@9
a$A|
_8Q @L
@LQ 
(`Nd
i(`N
pW8Z
R*`N
Z+`NZ
+`NJ
(`NJ)`N
+`N!(`N]
c(`N
+`N!
+`N!
NB(`N
+`NB
(`N{+`Ns
NZ+`N
*`NW
Nc(`N9+`N
+`Nc
NB(`N
(`NB
!(`Ns*`N
(`N!
N1*`N
T @ 
7Bm 
VzAZ
T"|@
oA)!
!)!N
J(!N
ob)!
b(!N
#)!N
	)!N!
h)!NB
'NiU	OHU	O!T	OBT	OcT	O
&N*8
NH8	Ncx
NBx	NK9
	NcX
kNcX
tncX
"i x!
o"(!
(!N0
h(!N
oBT	O
c)!ND
)N"(!
(!Nc
U	O@
*NaT	O
T	O&
SB,I
SB,I
SB,I
SB,I
SB,I
SB,I
QB|B
Q!|A
T,|~
TD|~
	K$,
	K$<
	K$L
Kc|@
	K$h
K)}	
T@{w
TN|~
Tg|~
W)"	
RL{7
T(  
2N8  
@z,!
TX! 
c8H! 
PQ'X
6@A 
-i	)
PQcX
?	mY
Rc90
_h#8
Lh#8
Eh#8?|
By`|
R		.
QB|B
O3A-'	'
9B|B
M;@-!
9&	&
K'B-&|
9B|B
B-B|
-!0@-H
@y")
@y!)
@y))
@-p"A-b
fNC-
aJD-
q^E-
`ZF-B
uRG-
T`"@
T`&@
T`*@
T`.@
T`2@
T`6@
T`:@
T`>@
T8  
5d|}
?h%8_
Tb|@
$h#8
RD|@
#h%8@	
#h%8
#h%8
#h%8
#h%8
#h$8
#h$8
#h$8
#h$8
#h$8
#h$8
#h$8
#h$8
#h$8
#h 8
#h 8
Th! 
%@xG
5X@-'
4LA-
4x  
hcx!
8Cke8
Ik%8
dC-s
hD-R
XF-c
PG-1
@-Bt
|t@-"!
0A-B
yDA-P
Q1~Q
mLB-B|
A3Ax
ESAxDsAx
/Gmq
n]m@
nC	B
TP 2
T0 1
i"8B
Tx  
T0 1
(8)y
!Xtxb
@yD8
@yD8
@yD8
@yD8
@yD8
@yD8
@yD8
@yD8
T  !
T  !
T  !
T  !
T  !
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@y@8
T_$@
@yc|
0@*B
T_$@
zexe
zexe
zexe
zexe
zexs
zsxB8
@y@8
T_$@
@y@8
T_$@
T  !
T  !
T  !
T  !
>Nc 
lD<N
8N1z!
OfG<N
G<N{
=qD)N
E)Nc
=N9#
Sc|@
Sc|@
Sc|@
Sc|@
Sc|@
Sc|@
*ApC
R:,C
A-!(#
 n!( 
<@ke
@kbx
@kbxc
@kbxS
@kdxE
@kbx4
@kbx"
@kbx
@kbx
@kbx
@kbx
@kbx
@kbx
@kdx
@kbx
@kbx
@kbx
7`*C
T  @
@y_0
@y? 
@k`8
@y?8
@y_8
@y_@
 @y@<
T" @
4B<@
T` @y
T`$@y
Ta @ya
4!<@
Ta$@y
4!<@
Ta @ya
4!<@
Ta$@y
4!<@
@y?(
4 hc
@y_(
R!hc
4!<@
@y?(
4C<@
@y?8
@y`=
@y_0
@y_8
@y? 
4B<@
T"'@
@y?8
T"/@
@y?8
T"7@
(@y 
@y?8
T ?@
@y_ 
Tb#@
c	@)
T`&B
Ty>B
Tx6D
T`ND
R`~	
4!ia
@	@y
@y_0
4#<@
@y_0
4 <@
@y_ 
4!<@
Tc$@yc
4c<@
@)c|
@y?8
@y_0
4 <@
@y? 
Tc$@y
@y_8
Tc$@yc
4c<@
T!<@
ahax
4 <@
	)d;
T  @
@y#<@
@y_ 
Tb6@
Tb2@
Tc&@
Rd6@
Td6@
h"8B
Tc&@
Ta2@
Td6@
h!8!
h!8!
Ta&@
Ra2@
h!8!
Ka2@
?h 8
T`&@
Tb2@
9u2@
4`6@
T_p}
Tt2@
TaR@
4`6@
Tt2@
TaR@
4`6@
Tt2@
TaR@
A9@S
4`6@
Tt2@
TaR@
4`6@
T_p}
Tt2@
T`R@
A9@J
4`6@
Tt2@
TaR@
4`6@
T_p}
Tt2@
T`R@
4`6@
4a6@
T`2@
T`R@
@yD 
4`2@
T`2@
T`R@
@yD 
*`"@
Ta2@
Td6@
h!8!
*d6@
h"8B
Tf&@
h!8!
Ka2@
?h 8
T`&@
?h 8
T`&@
?h 8
Tb&@
?h 8
Td&@
?h 8
T`&@
?h 8
Td&@
?h 8
T`&@
?h 8
T`&@
h"8B
?h 8
T`2@
?h 8
Tb&@
9b6@
Te6@
Tc2@
R`6@
T`6@
T`2@
*`&@
T`2@
4`6@
TaR@
@y@ 
4b2@
Tb2@
TaR@
4`6@
4a6@
T`2@
T`R@
@yD 
4`6@
4a6@
T`2@
T`R@
@yD 
4`6@
A9!H
4a6@
T`2@
T`R@
@yD 
4`6@
Ta2@
TaR@
4`6@
Ta2@
TaR@
4`6@
Ta2@
TaR@
4`6@
Ta2@
TaR@
*`"@
Ta2@
Td6@
h!8!
h!8!
h!8!
Ta&@
Tb2@
?h 8
T`&@
Tb2@
h!8!
Ka2@
?h 8
Tb&@
?h 8
T`&@
?h 8
h!8!
Ta&@
?h 8
T`&@
*`&@
4b&@
4b&@
?h 8
T`2@
?h 8
T`2@
?h 8
T`2@
?h 8
Tb&@
?h 8
Tb&@
?h 8
Tb&@
?h 8
?h 8
T#D@
T?t~
Tb2@
Td6@
?h 8
T|RD
9t2@
4a6@
4`6@
Tb2@
TaR@
4`6@
4a6@
T`2@
T`R@
@yD 
Tb6@
?h 8
Te&@
T`2@
Tb6@
?h 8
?h 8
T|RD
R`2@
Tb2@
Tb2@
?h 8
?h 8
?h 8
T`RD
?h 8
T`2@
?h 8
Tb2@
?h 8
Tb&@
?h 8
T`&@
?h 8
Kd2@
Tb2@
?h 8
?h 8
Tf&@
*b6@
Tc6@
Ta2@
9`6@
Tb2@
9w2@
4a6@
4`6@
TaR@
Tb6@
?h 8
Tf&@
Td6@
?h 8
T`2@
h!8!
h!8!
Ta&@
?h 8
Ke2@
?h 8
T`&@
?h 8
Tb2@
?h 8
T`&@
Tb2@
9u2@
4a6@
4`6@
Ta2@
TaR@
Ta6@
Ta6@
Tb2@
Ta6@
Ta6@
Tb2@
T?t~
9a6@
Ta6@
T_t~
T`2@
9y2@
4`6@
4a6@
T`2@
T`R@
@yD 
4`6@
4a6@
T`2@
T`R@
@yD 
4`6@
4a6@
T`2@
T`R@
@yD 
*d&@
R`6@
Tb6@
Tb6@
?h 8
?h 8
?h 8
?h 8
?h 8
?h 8
Ku2@
?h 8
T`&@
?h 8
?h 8
?h 8
T`2@
?h 8
T`2@
?h 8
T`2@
?h 8
Tb&@
?h 8
Tb&@
?h 8
Tb&@
?h 8
?h 8
Tb2@
9u2@
4a6@
4`6@
4`6@
4`6@
4`6@
Tb2@
TaR@
4`6@
4`6@
*`"@
Ta2@
Td6@
h!8!
?h 8
Td&@
h!8!
Ka2@
?h 8
T`&@
?h 8
K`6@
?h 8
Tf&@
?h 8
T`2@
?h 8
Ta2@
?h 8
Ta2@
?h 8
T`2@
?h 8
T`2@
?h 8
T`2@
?h 8
T`2@
?h 8
?h 8
Td&@
*b6@
?h"8B
?h"8B
_h!8!
T  @
(A: 
@y_@
4D<@
@y?@
TA @y
4!<@
@y?8
T  @
T" @
@y?(
@y?(
@y?@
 @y@_
@y?0
4!<@
@y?(
4!<@
@y? 
4!<@
@y?P
(@y`
H"8B
H!8!
#Hc8!Hb8
T!<@
haxa
4!<@
`"@9
?h"8B
Tb6@
Ta2@
h"8B
T`2@
h"8B
T`&@
4`6@
Tb2@
T`R@
h#8c
Ta&@
Ta6@
T`2@
Tb2@
T`&@
T`&@
Tb6@
Tb2@
h#8c
h#8c
Tc&@
T?t~
T`2@
_h 8
Ta&@
KuR@
A9u&
y{2@
Ta.@
_h 8
Ta&@
4`6@
TaR@
4`6@
Ta2@
TaR@
_h 8
T`&@
4b&@
Tb2@
TA @
T#hs
9jB	
bB@y
 X`xa
T  @
Rf~	
L) |
K!|@
*!|A
Ts~S
SALA)
BmA)4}
*D+A
Dz 	
TA|B
R	h@
	Bz!
*Wyf
cB9h
CB9!
L)s~
K`f@
Kcf@
Kcf@
Rzj@
A)SX
@)#}
*A|@
5@k@
"@9`
5@C@
5@O@
Ta"@9A
Rc~#
*||<
*b~"
5 L@
4`B@
I0@)"
*b@;
i!8_
!^fd
T0 &
#h%8
Q$h#8c
h!8!
hb8E
Tc|@
L@9_
9 3@
TLA)?P
T!'@
*C|~
"$@x
"$@x
"$@x
*E~@
T0 %
*%~@
T0 %
*E~@
T0 %
*%~@
T0 %
*C|~
 y`x
 y`x
x!x!
 y`x
x!x!
h!8!
x!x!
x!x!
x!x!
!^dd
T0 $
#h$8
T0 $
#h$8
!^dd
T0 $
#h$8
T0 $
#x$x
T0 $
"h$x
hdxe
T0 $
#h$x
T0 $
#x$x
*$x&x
*$x&x
S$x%x
*"h%x
*"h%x
S"h$x
AT@)
QV8@)
Wl@)c|
T`|~
T`|~
T`|~
QV8@)
QX<@)R~
Wh@)
QV8@)
QX<@)R~
Wh@)
QV4@)
V8@)
X<@)
X<@)
QW8@)
QX@@)<~
@)c|
\l@)
y	$@x
\l@)
)V@@)<~
Xl@)c|
Ry~@
QX@@)R~
QX@@)R~
W8@)
\l@)
y	$@x
\l@)
V<@)
QV8@)
QX@@);~
QX<@)
QX<@)
+M){
QX@@)R~
QX@@)R~
Xl@)c|
T`|}
Ry~@
T`|}
QX<@)R~
QX8@)
h"8B
T>@P
h"8B
R@|@
^@y |
T@xax
T!|@
T!|@
chsxj
T {a
RW~~
T!|@
Ry}	
y!hsx
T:@P
T!|@
!hsx
T!|@
T!|@
T!|@
T!|@
T!|@
9A$@
9C$@
9C$@
x"xB
9A$@
"x`x
9C$@
x"xB
9C$@
xcx$
9C$@
x#xc
x#xc
9C$@
x#xc
x#xc
9C$@
h"xB
hbx#
h"xB
9A$@
Ta4M
j"xB
9A$@
!^ h 
9A$@
@ha<
9A$@
@ha<
9A$@
9A$@
9A$@
^@h <
9A$@
9A$@
9A$@
^@x |
9A$@
9A$@
^@h <
9A$@
S`h"xB
9A$@
S`x"xB
9A$@
dx`x
^@h <
9A$@
dh`x
^@h |
9A$@
^@x |
9A$@
h"<B
h"<B
9A$@
h"|B
h"|B
9A$@
x"xB
x"xB
9A$@
h"xB
h"xB
ah 8
h#8c
Ax`xah 8
h#<c
8ax x
x#|c
9C$@
@h!8!
9C$@
ah`8!
QAh 8
~ h#<c
@9 "
@9 "
A9o|
A9ez
3XA)
@9@ 
A98x
4LA)
@9@ 
4LA)
4LA)
@9` 
A9@q
4LA)
@9` 
4LA)
@9` 
@9 "
@9 "
PB)x%
PB)8%
PB)y*
kc}@
RxTA)
A9da
kc}@
RxTA)
A9)_
TA3@
M)u~
RtLA)
Ta3@
'N)p~
kC|~
RtLA)
A9yZ
Ta3@
'N)p~
kC|~
RtLA)
A9QX
T!3@
lB)u4
RtLA)
Ta3@
RtLA)
Ta3@
'N)o~
RtLA)
A9qQ
RxTA)
A9IO
Ta3@
PB)x+
T$@P
RgTA)
TA3@
M)u~
RtLA)
A9pJ
TA3@
lB)51
RtLA)
Ta3@
'N)p~
RtLA)
T!3@
"p@)
RtLA)
A9lC
Ta3@
RtLA)
A93A
Ta3@
'N)p~
!~ D
RtLA)
T!3@
lB)u4
RtLA)
Ta3@
hB)u+
RtLA)
A9N:
RxTA)
A9(8
Ta3@
RtLA)
Ta3@
hB)u(
'N)o~
RtLA)
Ta3@
RgTA)
PB)Y)
RxTA)
A9A/
Ta3@
'N)p~
!^ D
RtLA)
Ta3@
hB)U(
'N)p~
RtLA)
Ta3@
hB)5+
O)p~
RtLA)
Ta3@
RtLA)
A9g&
T!3@
"p@)
RtLA)
Ta3@
'N)p~
RtLA)
RxTA)
Ta3@
'N)p~
RtLA)
IpA)
T |~
T!'@
<lA)
 {`x
x"xB
T!'@
<lA)
TX~~
TA'@
5pA)
~@i"<B
TA'@
5pA)
Tz|~
T!'@
<lA)
T7~~
T!'@
<lA)
 {`x
Ta3@
L)h~
)B8 
RuLA)
Ta3@
L)h~
)B8 
RuLA)
*@)P
.A)?
Ta3@
L)h~
)B8 
RuLA)
Ta3@
)B8 
RuLA)
TA'@
6\A)
z`x|
TA)_P
ZlA)
*@)P
.A)?
TA'@
5pA)
*@y"xB
*@y"xB
R!|~
5LA)
5LA)_S
N)||~
:LA)?S
!^dd
!^dd
9 3@
UPA)
9 3@
UPA)
!~ D
5LA)_S
5LA)_S
R)\|
!^ D
Dz D
TD$F
TD(F
TD<F
TD@F
TD$K
TDDF
TD\F
TD4K
TD,K
9`.@
`K9a
G)? 
T`ht
T$@B
@9c6@
T@ku
af@)
T@ky
T@ks
T@ks
*@C6
T%<A
T`'@
T`7@
*@C6
T3<A
A)!|
9`"@
9`*@
9`2@
9`:@
9`*@
*dD@
TxrD
T#H_
T`Z{
T`Z|
T`Z}
T`Z~
5a"@
TDHT
5a"@
TDHT
TC|B
qc@2
R!P@
5\A)"
9{:A
5ab@
T`<A
AzAG
*bz@
TCp]
T#t]
T@O@
T@C@y
TBcB
TEt]
T#t]
@@@y
T`zd
9t6@
bB@y
$PA)
Ts~@
T! @
T@$@
T! @
T@$@
9v6@
@9  
9{6@
T`B@yv
E)aR
T$x]
T$ ^
T$P^
T$\^
T$h^
T$t^
T$Tc
T$L_
!,A9
*F @
T" @
@@@yaB@y?
T  @
P)C @
T" @
T $@
T  @
T!|@
T  @
T  @
T  @
T" @
?  k
?  k
T  @
T $@
T9<@
bA)w
T  @
T $@
T" @
_  k
Tb~A
T  @
_  kA
*d~A
T  @
?  ka
Ta+@
T{"%
T`"@
T  @
T $@
T  @
T@'@
TVSA
TYc@
Tb$K
Rt4K
TC@G
TCTG
TCHG
TCDG
TCLG
T#@G
T#TG
T#HG
T#DG
T#LG
Tc{@
RdXU
T#DG
T#LG
T`B"
T`VB
T`ZA
Dz 	
Tb"@
4b"@
RCXU
RCXU
5`6@
*c~I
5`F@9 
T#4B
T#8B
TbFA
9wFA
T#4B
T#8B
TA<@
T#8B
4bFA
cB@y
 @@y
@@y?
@@y?
@y @@y_
cB@y
 @@y
@@y?
@@y?
@y @@y_
T  @
Rc"@
Rc"@
T  @
T $@
Rc"@
Rc"@
T  @
T $@
T  @
T  @
T  @
T  @
RST@
TA|@
9b6@
T`B@yv
E)aR
RcP^
Rc\^
Rch^
Rct^
R! ^
RcX_
Rcx]
5,A9
T`"@
RcD^
R#x]
Rc,d
RcPd
R!,d
R!Pd
4#\^
RcT]
RcT]
4$x]
R#T]
4#D^
@@@yaB@y?
RB`i
RBT]
RBOA
R_h!
?# k
R"T]
T@$@
5`(B
T"OA
R'WA
Re(B
qe(B
Rb,B
*b~I
5`F@9
@y? 
T#4B
T!TQ
R!H_
T#4B
T"8B
T!TQ
@y?(
@y c
T#p]
T#p]
TCH_
T!H_
TCH_
T!$c
" k@
" k@
" k`
@y!	
@QB<
" k@
@y!ha
" k`
R$<@
*!<P
T$<@
RB<@
2!<P
TB<@
2!pN
@xclm
@yvB
T @@y
(6!Xb
C@@yF
T"@@y_
y!T]
T @@y
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
4!Xb
T`"B
`R@y
R@y`R
aR@y
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?
@@y?  qI
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?@
@@y?P
@@y?P
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?P
@@y?P
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TaN@
"@@y$
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
TbN@
C@@yF
@@y?P
TaN@
"@@y$
@@y?P
TaN@
"@@y$
@@y?P
TaN@
"@@y$
@@y?P
TaN@
"@@y$
@@y?P
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
"@@y$
@@y?  qH
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TbN@
RC@@yF
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
RC@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
B@y?
cB@y
 @@y
@@y?
@@y?
@y @@y_
@@@y
B@y?
@@@y
B@y?
`R@y
R@y`R
aR@y
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?
@@y?  qI
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?@
@@y?P
@@y?P
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?P
@@y?P
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TaN@
"@@y$
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
TbN@
C@@yF
@@y?P
TaN@
"@@y$
@@y?P
TaN@
"@@y$
@@y?P
TaN@
"@@y$
@@y?P
TaN@
"@@y$
@@y?P
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
"@@y$
@@y?  qH
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TbN@
RC@@yF
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
RC@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
`R@y
R@y`R
aR@y
@@y?P
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?@
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?@
C@@yE
C@@yE
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
TbN@
C@@yF
@@y?
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TbN@
C@@yF
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
C@@yF
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
RC@@yF
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
RC@@yF
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
RC@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TbN@
@@y? @qh
TaN@
@@y? @qh
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
R"@@y$
R"@@y$
TbN@
RC@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
`R@y
R@y`R
aR@y
T"@@yB
@@y?
@@y? @qI
@@y?
@@y?
@@y? 
@@y?@
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y? 
@@y?@
@@y?@
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
TbN@
C@@yF
@@y?P
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TbN@
RC@@yF
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
C@@yE
C@@yE
TaN@
"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
RC@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
RC@@yF
C@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
@@y? @qh
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
R	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
R	A@y
	A@y
`R@y
R@y`R
aR@y
T"@@yB
@@y?
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y? 
@@y?@
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y? 
@@y?@
@@y?@
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
TbN@
C@@yF
@@y?P
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y? 
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
C@@yE
TbN@
RC@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
RC@@yF
C@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
@@y? @qh
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
R	A@y
	A@y
`R@y
R@y`R
aR@y
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?@
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y? @qI
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
C@@yE
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
TbN@
C@@yF
@@y?
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
RC@@yF
C@@yF
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
RC@@yF
C@@yF
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
RC@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
A@y?
TaN@
R"@@y$
@@y?
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
A@y?
TaN@
R"@@y$
@@y?
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
A@y?
TaN@
R"@@y$
@@y?
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TbN@
@@y? @qh
TaN@
@@y? @qh
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
TbN@
RC@@yF
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
`R@y
R@y`R
aR@y
T"@@yB
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?P
@@y?`
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?  qI
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?@
@@y?@
@@y? 
@@y?
@@y?
@@y?
@@y? 
@@y? 
@@y?
@@y?P
@@y?`
@@y?`
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
TbN@
C@@yF
@@y?P
TbN@
C@@yF
@@y?`
TaN@
"@@y$
@@y?`
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?  q
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
C@@yE
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
 	SsB
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
`R@y
R@y`R
aR@y
@@y?
T"@@yB
@@y?
@@y?
@@y?
@@y? 
@@y?@
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?  qI
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?P
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y? 
@@y?
@@y? 
@@y?@
@@y?@
@@y?P
@@y?
@@y? 
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y?
@@y_
T`N@
TbN@
C@@yF
@@y? 
TaN@
"@@y$
@@y? 
TbN@
C@@yF
@@y?@
TaN@
"@@y$
@@y?@
TbN@
C@@yF
@@y?P
TaN@
"@@y$
@@y?P
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TaN@
"@@y$
@@y?
TbN@
C@@yF
@@y? 
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
C@@yF
@@y?  q
"@@y$
@@y?  qH
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TaN@
"@@y$
TbN@
RC@@yF
TbN@
RC@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
C@@yF
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
C@@yE
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
RC@@yF
TbN@
RC@@yF
TaN@
"@@y$
TbN@
C@@yF
TaN@
"@@y$
TbN@
C@@yF
TbN@
C@@yF
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
TbN@
RC@@yF
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
TaN@
R"@@y$
C@@yE
C@@yE
TbN@
C@@yF
TbN@
RC@@yF
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
d@@yf
#@@y%
TA@@y?
	A@y
	A@y
	A@y
	A@y
	A@y
	A@y
Hf8`H38s
QaH"8
Ht8a
9@i98
Hf8`H38s
QaH"8
AHa8@Ht8a
9@i68
Ti68
Ti98}
`R@y
R@y`R
aR@y
TCDF
TC$K
TCHK
TCLK
TC0K
TC4K
TC,K
TC(H
xhA)
TC K
TDxY
TB<F
Tb C
TA,U
TCDF
TC$K
TCHK
TCLK
TC0K
TC4K
TC,K
TC(H
xhA)
TC K
TDxY
TB<F
L)D|
L)#|
c@9+
T$|A
)9|`
TC<F
RVtG
TC<F
T#xG
T#,G
Q#xG
A9[|@
TC<F
T#xG
T#,G
Q#xG
TC<F
TC U
TDXU
T#,U
Dz`P
TC<F
TC U
TDXU
T#,U
Dz@E
TC<F
RVtG
T#,U
TC<F
T#xG
T#,G
A9[|@
TC<F
T#xG
T#,G
9Z|@
TC<F
TC U
T#,U
T!+@
Q\|@
TC<F
TCtG
TCxG
TC,G
Dz@?
Q[|@
TC<F
TCtG
TCxG
TC,G
TCDG
TCLG
TD8Y
k3|@
A9g"
k3|@
TCDG
TCLG
TD8Y
TC K
TCxY
TC(H
TC@H
TC@I
TC<K
@9C7
TC8G
TC`H
TC\H
TD8Y
T#(F
T#,G
T#tG
T#xG
T#LF
T#@F
T#DF
TC|F
TC,U
TC$K
TC@K
TCHK
TCLK
TC0K
TC4K
RU,K
TC@H
TC@I
TC<K
TC`H
TC\H
TD8Y
TC(H
TC K
TCxY
T#(F
T#,G
T#tG
T#xG
T#LF
T#@F
T#DF
TC|F
TC,U
TC$K
TC@K
TCHK
TCLK
TC0K
TC4K
RV,K
TC@H
TC@I
TC<K
TC@I
TC<K
gW)@
TC$F
TC(F
TD,G
TCtG
TCxG
TCLF
TC@F
TCDF
TC|F
TC,U
TA,U
TC$K
TC@K
TCHK
TCLK
TC0K
TC4K
RS,K
T#<F
T#<K
QD,G
R)A|
TC(H
TC K
TCxY
RdxY
RCxY
T"<F
TC,U
Rd,U
Rd,U
RD,U
TA,U
RdxY
RCxY
RA,U
RC,U
Rd,U
TC$F
TC(F
TD,G
TCtG
TCxG
TCLF
TC@F
TCDF
TC|F
TC,U
TC$K
TC@K
TCHK
TCLK
TC0K
TC4K
RY,K
TC(H
TC K
TCxY
T#<F
TC@I
TC<K
QD,G
T)A|
sY) 
TC$F
TC(F
TD,G
TCtG
TCxG
TCLF
TC@F
TCDF
TC|F
TC,U
TA,U
TC$K
TC@K
TCHK
TCLK
TC0K
TC4K
RX,K
TC(H
TC K
TCxY
T#<F
QD,G
T)A|
RA,U
T3D@
Wz-4
b2Aya
Dz@#
Wz-4
a"Ay`
Dz@#
Wz-4
b2Aya
Dz@#
TBPF
T#$F
T#(F
T#LF
T#@F
T#DF
TC|F
TC,U
T#$K
T#@K
T#HK
T#LK
T#0K
T#<F
T#4K
T#,K
T#xG
T#,G
T#TF
T#PF
T#@I
T#<K
Z)A|
T#0G
T#`K
T#8T
T#xB
TbxB
KbDB
R)B)
TC(B
4C0B
TC(B
TC$B
TG,B
TC$A
4C(A
TC<A
TC@A
TCDA
TCHA
TCLA
TCPA
@9CxA
TCPO
RV|A
RDPO
TAtP
TAtP
@9a'
TCXB
TCLC
TCPC
TCTC
TCXC
TC|C
TCpC
TGHB
TCtE
TCxE
TDHT
TD$F
TD(F
TC<F
TCDF
@9CHF
TCLF
TCPF
TCTF
TC U
RY,G
"@9`
4#8G
T#0I
TC G
TC8I
TC<I
TCDI
TB@K
RVLB
TC C
TC`C
TC4B
TC8B
5C4B
*@9 
4C\A
TC$C
TC(C
TClC
RZxG
TC,U
TD,U
TC,U
RX\K
TC|G
TC0A
4C Y
TC8B
TChH
RVLB
@9aj
TC$B
TbxB
TdLB
@9`@
TCPO
RV|A
4#8G
@9 @
@zA3
TC,K
TC4K
TChA
4ChA
TBtH
TChH
TD$B
TA8U
TCdU
RX\K
L)"|
4C,U
TC,K
TC4K
TC U
@9C(K
TC,U
TC,U
TC,U
_)v&A
4`2@
4C(A
TC<A
TC@A
TCDA
TCHA
TCLA
TCPA
5CPO
RZ|A
TExA
TAtP
TAtP
TCXB
@9C C
TCLC
TCPC
TCTC
TCXC
TC|C
TCpC
TGHB
TCtE
TCxE
TClG
TD$F
TD(F
TC<F
TCDF
@9CHF
TCLF
TCPF
TCTF
5D U
RC,G
Ta"@9
4C8G
TC0I
TBLH
Rb&A
TC8I
TC<I
TCDI
TC,U
T`"@9
@9@E
TE$V
TE V
R$ U
TC,K
TC0K
TC4K
RX C
T#LB
T#xB
Ta2@
T" B
T`&@9
T`*@9@
4`.@9a
TG,B
@9C,C
RW\C
RXxG
5CPO
RZ|A
5`Z@
TELB
TBxB
T#,K
T#4K
TCtH
TChH
`.@9`
HzAs
5eZ@
4`Z@
TD U
TC0K
TC,K
TC4K
@9C(K
Rz C
Tg,B
TC,K
c[9"5@
QB@8
T#,U
T# C
Dz *
@9c6@
3B9!
A)@|
@9B7
Ai!|
@)"}@
A)@|
T!c@
L)a#
#lAi
jAic|
*U3@
@)b|
@9a6@
CB9`
gr_)
`.@9`
TC<A
TC@A
TCDA
TCHA
TCLA
TCPA
TAPO
TC C
TC0C
Ta2@
TC0C
TB4C
TCLC
TCPC
TCTC
TCXC
TC|C
TGHB
TD$F
TD(F
TC<F
TCDF
@9CHF
TCLF
Ta"@9C8G
TC@G
TCTG
TCDG
TCPG
TCHG
5CPF
TCTF
TBLH
4"pH
T"8I
T"<I
T"DI
T#,U
T`"@9
TC U
TC0K
TC4K
T#dB
4#hB
T"4B
T"8B
Tb&@9
5"4B
Tb*@9B
qb.@9
T#tB
Ta2@
TG,B
TAPO
TAtP
TAtP
@9CXB
TC C
RC4C
a"@9
TCPF
TCTF
TC U
TC,K
TC0K
TC4K
TCtB
Ta2@
4APO
Dz@v
TC,U
T# C
@9c6@
`.@9
TC<A
TC@A
TCDA
TCHA
TCLA
TCPA
TAPO
TAtP
TAtP
@9CXB
TC C
TD$F
TD(F
TC<F
TCDF
@9CHF
TCLF
TCPF
TCTF
Ta"@9C8G
TC@G
TCTG
TCDG
TCPG
TCHG
TBLH
4CpH
TC8I
TC<I
TCDI
TC,U
T#,K
T#0K
T#4K
T`"@9
TC U
T" U
T#dB
4#hB
T"4B
T"8B
Tb&@9
5"4B
Tb*@9
5"8B
TBtB
Ta2@
T`2@
a"@9
TCtB
Ta2@
TG,B
TClC
RYxG
T`f@
T$XA
T`*A
Ta&A
TC U
@9C(K
Ta2@
TAPO
Rax`
@)(}@
l0F9
S;|`
qzpJ
9axA
 0F9@
TC C
T 8F9
TC U
Dz`|
Qc@8
TC,U
*u2@
jAi'
@9a6@
#D9`
@)B|
@9a6@
T`j@
T`j@
*i|@
Raz`
T  @
T# @
Tbht
T# @
T4W@
T@hu
T# @
T@hu
T# @
QCP@
)G"@)%
Ry|@
5s~S
TCh{
@9C7@
T  @
B)u"
T`N@
*Z)`
TuVA
TunA
 AiB
@)B|
@9a6@
9b6@
Ai(|@
T  @
T  @
T  @
T#,K
T#4K
A)B|
@9!|
@9a6@
@9a6@
@9c6
T#@Y
T`#@
aR@y
R@ya
T`~@
T# Y
T#8Y
T#<Y
T#LY
TD$F
TD(F
TD,G
TCtG
TCxG
TCLF
TC@F
TCDF
TE|F
TC,U
RC,U
TC$K
TB@K
TB<K
RU,K
c2Ayb
Tb$F
Tb(F
Tb@F
TbDF
Tb,U
TB$K
TD$F
TD(F
TDtG
TDxG
TDLF
TD0K
TD@F
TDDF
TD,U
TC$K
TC@K
RT4K
TB<K
RU,K
c"Ayb
TD$F
TD(F
TDtG
TDxG
TDLF
TD0K
TD@F
TDDF
TD,U
TC$K
TC@K
RT4K
TB<K
c2Ayb
TCPZ
TCH[
Tg*@
Thf@
RCPZ
9CH[
9`~@
a"@9
 @9@
;d@)
;d@)
;d@)~
6P@)
6P@)
6P@)d
3X@)
Q!|@
3X@)
3X@)n
3X@)
Q!|@
3X@)
X@)j
3X@)n
yc"@
Cyc:F9
9`"@9
9`&@9
9`*@9
9`.@9
J$@9G
A)j$
9I(@9H,@9R
@9K @9r
J$\)j$
T  @
@xaB
@xaB
_h!8
*`#.
7`#.
*`#.
?h 8`
?h 8`
?h 8
?h 8
Kza	
Kz!	
S!|@
S!|@
@8#x
)!|}
T) @
Rb*L)
4 (@
@)tLA)"c@
T7'A
F9B 
4`xa
T`j@
T`j@
T 3A
T 3@
R'xx
R!ht
T 7@
T G@
T 3@
R(+@
T ;@
T K@
T!3@
T"3@
T!;@
T!K@
T";@
T"K@
T 3@
T K@
T ;@
R(+@
T +@
T6/@
44k@
T +@
T67@
T ;@
T K@
Rfhu
A)`.
T!/@
4!k@
T!7@
T!G@
T6G@
sL9&
*-y 
T!;@
T!;@
R!ht
*gx 
T67@
T6G@
T!K@
T 3@
T!3@
T K@
T!;@
T ;@
T!K@
T"3@
T";@
T"K@
T";@
Tp !
a2F9
`6F9
a:F9
4 0 
* |_
* |_
RKLLM SDK (version: 1.2.1b1 | target: Linux | build: 27637c95 2025-05-02 17:46:07)
%s/%s
scandir
Warning: Get dump file number larger than %d
Error: Vectors must be of equal size in %s
: %s
rkllm_accuracy_dump
create dir %s fail
create dir %s
Analysis:
    ID  name                               Type                 entire                                    single
                                                             cos       euc                             cos       euc
--------------------------------------------------------------------------------------------------------------------------
rkllm_accuracy_dump/rkllm_dump_quant_entire
rkllm_accuracy_dump/rkllm_dump_golden
rmsnorm
rkllm_accuracy_dump/rkllm_dump_quant_single
%6d  %-34s%-18s%.5f | %-32.1f%.5f | %.1f
vector::_M_realloc_insert
fff?
I rkllm: create dir %s fail
I rkllm: create dir %s
basic_string::append
E rkllm: RKLLMExtendParam pointer is NULL
I rkllm: Base Domain ID: %d
I rkllm: Embed Flash: %d
true
false
E rkllm: RKLLMParam pointer is NULL
I rkllm: Model Path: %s
I rkllm: Max Context Length: %d
I rkllm: Max New Tokens: %d
I rkllm: Top-K: %d
I rkllm: N Keep: %d
I rkllm: Top-P: %f
I rkllm: Temperature: %f
I rkllm: Repeat Penalty: %f
I rkllm: Frequency Penalty: %f
I rkllm: Presence Penalty: %f
I rkllm: Mirostat: %d
I rkllm: Mirostat Tau: %f
I rkllm: Mirostat Eta: %f
I rkllm: Skip Special Token: %s
I rkllm: Is Async: %s
I rkllm: Image Start: %s
I rkllm: Image End: %s
I rkllm: Image Content: %s
I rkllm: reset chat template:
I rkllm: system_prompt: %s
I rkllm: prompt_prefix: %s
I rkllm: prompt_postfix: %s
lite
RK3588
RK3576
RK3562
RV1126B
UNKNOWN_PLATFORM
Get device properties failed
basic_string::_M_construct null not valid
0.9.7
stoi
W rkllm: Warning: Your rknpu driver version is too low, please upgrade to %s
Platform error, must be either RK3588, RK3576, RV1126B or RK3562. Your platform is %s
1.2.1b1
I rkllm: rkllm-runtime version: %s, rknpu driver version: %s, platform: %s
RKLLM_LOG_LEVEL
RKLLM_DUMP_LEVEL
I rkllm: RKLLM_DUMP_LEVEL=%d
rkllm_dump
rkllm_accuracy_dump/rkllm_dump_input
E rkllm: The n_keep must be less than the max_context_len
E rkllm: The number of enabled CPUs must be greater than or equal to the number of NPU cores.
E rkllm: Mismatch between enabled CPUs mask and expected count. Please check the configuration.
E rkllm: Expected The number of enabled CPUs between 1 and 8 for %s, but got %d.
E rkllm: Expected The number of enabled CPUs between 1 and 4 for %s, but got %d.
E rkllm: For %s, only CPUs 0 to 3 can be set, but additional CPUs are enabled.
I rkllm: Using mrope
Lora adapter '
' is already initialized!
Lora adapter path does not exist!
AddLora
%s: error: failed to apply lora adapter
W rkllm: The rwkv model does not support loading prompt cache!
I rkllm: load prompt cache from '%s'
E rkllm: prompt cache file '%s' does not exist
E rkllm: prompt cache file '%s' is empty
E rkllm: failed to load prompt cache from %s
I rkllm: loaded a prompt cache with prompt size of %d tokens
user
D rkllm: rkllm_infer_params is NULL
D rkllm: rkllm_input is NULL
Not Found Lora adapter named: 
./prompt_cache.bin
I rkllm: prompt_cache_save_path is null, save prompt cache to ./prompt_cache.bin
I rkllm: current kv cache size: %d
I rkllm: keep history status: %d
llama_add_eos_token(model) != 1
GGML_ASSERT(%s) failed
<image>
E rkllm: multimodal input must contain the <image> tag, for plain text input, please use prompt_input
E rkllm: The n_image_token of multimodal_input is not set
E rkllm: The n_image/n_image_token of multimodal_input is not set
E rkllm: The image_embed of multimodal_input is empty
basic_string::replace
%s: __pos (which is %zu) > this->size() (which is %zu)
system
I rkllm: prompt text: "%s"
I rkllm: prompt tokens: %s, total: %lu
E rkllm: the length of prompt is greater than max context (prompt: %d tokens, max context: %d)
I rkllm: match img_content %s = %s 
I rkllm: match same image, so keep the image_embed cache, total %d
I rkllm: kv cache matches %zu / %zu tokens of prompt
I rkllm: kv cache size after matching is: %d
I rkllm: n_keep = %d
ga_n > 0 && "grp_attn_n must be positive"
ga_w % ga_n == 0 && "grp_attn_w must be a multiple of grp_attn_n"
vector::reserve
%s: failed to initialize sampling subsystem
I rkllm: context to be full[%d + %d], delete the kv cache in [%d, %d), total: %d
E rkllm: the context is not enough! history_s: %d, cur_input_s: %d, discard_s: %d, max_context: %d!
E rkllm: failed to clear kv cache
I rkllm: actual input tokens: %s, history length: %d
vector::_M_range_insert
E rkllm: patch_h[%d] * patch_w[%d] != n_image_token[%d]!
E rkllm: malloc input_embed_data mem error
D rkllm: malloc input_embed_data mem error
W rkllm: The rwkv model does not support saving prompt cache!
I rkllm: saved prompt cache to %s
I rkllm: rkllm_run ended
I rkllm: rkllm_run was aborted
I rkllm: In this conversation: the newly added user cache size is %d; system cache size is %d
unknown
127.0.0.1
imatrix.dat
control_vector.gguf
examples/cvector-generator/positive.txt
examples/cvector-generator/negative.txt
ggml-lora-merged-f16.gguf
vector::_M_default_append
cannot create std::deque larger than max_size()
St11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE
St19_Sp_make_shared_tag
St16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE
NSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvP7LLMCallES4_EEEEEE
St23_Sp_counted_ptr_inplaceI7RunDataSaIS0_ELN9__gnu_cxx12_Lock_policyE2EE
00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
33s?
kfypmt
m_data.m_type != value_t::object || m_data.m_value.object != nullptr
m_data.m_type != value_t::array || m_data.m_value.array != nullptr
m_data.m_type != value_t::string || m_data.m_value.string != nullptr
m_data.m_type != value_t::binary || m_data.m_value.binary != nullptr
vector<bool>::_M_insert_aux
HF_TOKEN
enabled
disabled
general
print usage and exit
-h,    --help, --usage
show version and build info
       --version
print verbose information
-v,    --verbose
set specific verbosity level (default: %d)
       --verbosity N
print a verbose prompt before generation (default: %s)
       --verbose-prompt
don't print prompt at generation (default: %s)
       --no-display-prompt
colorise output to distinguish prompt and user input from generations (default: %s)
-co,   --color
RNG seed (default: %d, use random seed for < 0)
-s,    --seed SEED
number of threads to use during generation (default: %d)
-t,    --threads N
number of threads to use during batch and prompt processing (default: same as --threads)
-tb,   --threads-batch N
speculative
number of threads to use during generation (default: same as --threads)
-td,   --threads-draft N
number of threads to use during batch and prompt processing (default: same as --threads-draft)
-tbd,  --threads-batch-draft N
number of tokens to draft for speculative decoding (default: %d)
       --draft N
speculative decoding split probability (default: %.1f)
-ps,   --p-split N
path to static lookup cache to use for lookup decoding (not updated by generation)
-lcs,  --lookup-cache-static FNAME
path to dynamic lookup cache to use for lookup decoding (updated by generation)
-lcd,  --lookup-cache-dynamic FNAME
size of the prompt context (default: %d, 0 = loaded from model)
-c,    --ctx-size N
number of tokens to predict (default: %d, -1 = infinity, -2 = until context filled)
-n,    --predict N
logical maximum batch size (default: %d)
-b,    --batch-size N
physical maximum batch size (default: %d)
-ub,   --ubatch-size N
number of tokens to keep from the initial prompt (default: %d, -1 = all)
       --keep N
max number of chunks to process (default: %d, -1 = all)
       --chunks N
enable Flash Attention (default: %s)
-fa,   --flash-attn
prompt to start generation with
in conversation mode, this will be used as system prompt
(default: '%s')
-p,    --prompt PROMPT
a file containing the prompt (default: none)
-f,    --file FNAME
an input file (repeat to specify multiple files)
       --in-file FNAME
binary file containing the prompt (default: none)
-bf,   --binary-file FNAME
process escapes sequences (\n, \r, \t, \', \", \\) (default: %s)
-e,    --escape
do not process escape sequences
       --no-escape
main
print token count every N tokens (default: %d)
-ptc,  --print-token-count N
file to cache prompt state for faster startup (default: none)
       --prompt-cache FNAME
if specified, saves user input and generations to cache as well
not supported with --interactive or other interactive options
       --prompt-cache-all
if specified, uses the prompt cache but does not update it
       --prompt-cache-ro
halt generation at PROMPT, return control in interactive mode
can be specified more than once for multiple prompts
-r,    --reverse-prompt PROMPT
special tokens output enabled (default: %s)
-sp,   --special
run in conversation mode, does not print special tokens and suffix/prefix
if suffix/prefix are not specified, default chat template will be used
(default: %s)
-cnv,  --conversation
main infill
run in interactive mode (default: %s)
-i,    --interactive
run in interactive mode and wait for input right away (default: %s)
-if,   --interactive-first
allows you to write or paste multiple lines without ending each in '\'
-mli,  --multiline-input
prefix BOS to user inputs, preceding the `--in-prefix` string
       --in-prefix-bos
string to prefix user inputs with (default: empty)
       --in-prefix STRING
string to suffix after user inputs with (default: empty)
       --in-suffix STRING
skip warming up the model with an empty run
       --no-warmup
server infill
use Suffix/Prefix/Middle pattern for infill (instead of Prefix/Suffix/Middle) as some models prefer this. (default: %s)
       --spm-infill
sampling
samplers that will be used for generation in the order, separated by ';'
(default: %s)
       --samplers SAMPLERS
simplified sequence for samplers that will be used (default: %s)
       --sampling-seq SEQUENCE
ignore end of stream token and continue generating (implies --logit-bias EOS-inf)
       --ignore-eos
penalize newline tokens (default: %s)
       --penalize-nl
temperature (default: %.1f)
       --temp N
top-k sampling (default: %d, 0 = disabled)
       --top-k N
top-p sampling (default: %.1f, 1.0 = disabled)
       --top-p N
min-p sampling (default: %.1f, 0.0 = disabled)
       --min-p N
tail free sampling, parameter z (default: %.1f, 1.0 = disabled)
       --tfs N
locally typical sampling, parameter p (default: %.1f, 1.0 = disabled)
       --typical N
last n tokens to consider for penalize (default: %d, 0 = disabled, -1 = ctx_size)
       --repeat-last-n N
penalize repeat sequence of tokens (default: %.1f, 1.0 = disabled)
       --repeat-penalty N
repeat alpha presence penalty (default: %.1f, 0.0 = disabled)
       --presence-penalty N
repeat alpha frequency penalty (default: %.1f, 0.0 = disabled)
       --frequency-penalty N
dynamic temperature range (default: %.1f, 0.0 = disabled)
       --dynatemp-range N
dynamic temperature exponent (default: %.1f)
       --dynatemp-exp N
use Mirostat sampling.
Top K, Nucleus, Tail Free and Locally Typical samplers are ignored if used.
(default: %d, 0 = disabled, 1 = Mirostat, 2 = Mirostat 2.0)
       --mirostat N
Mirostat learning rate, parameter eta (default: %.1f)
       --mirostat-lr N
Mirostat target entropy, parameter tau (default: %.1f)
       --mirostat-ent N
modifies the likelihood of token appearing in the completion,
i.e. `--logit-bias 15043+1` to increase likelihood of token ' Hello',
or `--logit-bias 15043-1` to decrease likelihood of token ' Hello'
       -l TOKEN_ID(+/-)BIAS
negative prompt to use for guidance (default: '%s')
       --cfg-negative-prompt PROMPT
negative prompt file to use for guidance
       --cfg-negative-prompt-file FNAME
strength of guidance (default: %.1f, 1.0 = disable)
       --cfg-scale N
set custom jinja chat template (default: template taken from model's metadata)
if suffix/prefix are specified, template will be disabled
only commonly used templates are accepted:
https://github.com/ggerganov/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template
       --chat-template JINJA_TEMPLATE
grammar
BNF-like grammar to constrain generations (see samples in grammars/ dir) (default: '%s')
       --grammar GRAMMAR
file to read grammar from
       --grammar-file FNAME
JSON schema to constrain generations (https://json-schema.org/), e.g. `{}` for any JSON object
For schemas w/ external $refs, use --grammar + example/json_schema_to_grammar.py instead
-j,    --json-schema SCHEMA
embedding
pooling type for embeddings, use model default if unspecified
       --pooling {none,mean,cls,last}
attention type for embeddings, use model default if unspecified
       --attention {causal,non-causal}
context hacking
RoPE frequency scaling method, defaults to linear unless specified by the model
       --rope-scaling {none,linear,yarn}
RoPE context scaling factor, expands context by a factor of N
       --rope-scale N
RoPE base frequency, used by NTK-aware scaling (default: loaded from model)
       --rope-freq-base N
RoPE frequency scaling factor, expands context by a factor of 1/N
       --rope-freq-scale N
YaRN: original context size of model (default: %d = model training context size)
       --yarn-orig-ctx N
YaRN: extrapolation mix factor (default: %.1f, 0.0 = full interpolation)
       --yarn-ext-factor N
YaRN: scale sqrt(t) or attention magnitude (default: %.1f)
       --yarn-attn-factor N
YaRN: high correction dim or alpha (default: %.1f)
       --yarn-beta-slow N
YaRN: low correction dim or beta (default: %.1f)
       --yarn-beta-fast N
group-attention factor (default: %d)
-gan,  --grp-attn-n N
group-attention width (default: %.1f)
-gaw,  --grp-attn-w N
verbose print of the KV cache
-dkvc, --dump-kv-cache
disable KV offload
-nkvo, --no-kv-offload
KV cache data type for K (default: %s)
-ctk,  --cache-type-k TYPE
KV cache data type for V (default: %s)
-ctv,  --cache-type-v TYPE
perplexity
return logits for all tokens in the batch (default: %s)
       --all-logits
compute HellaSwag score over random tasks from datafile supplied with -f
       --hellaswag
number of tasks to use when computing the HellaSwag score (default: %zu)
       --hellaswag-tasks N
compute Winogrande score over random tasks from datafile supplied with -f
       --winogrande
number of tasks to use when computing the Winogrande score (default: %zu)
       --winogrande-tasks N
compute multiple choice score over random tasks from datafile supplied with -f
       --multiple-choice
number of tasks to use when computing the multiple choice score (default: %zu)
       --multiple-choice-tasks N
computes KL-divergence to logits provided via --kl-divergence-base
       --kl-divergence
stride for perplexity calculation (default: %d)
       --ppl-stride N
output type for perplexity calculation (default: %d)
       --ppl-output-type {0,1}
parallel
KV cache defragmentation threshold (default: %.1f, < 0 - disabled)
-dt,   --defrag-thold N
number of parallel sequences to decode (default: %d)
-np,   --parallel N
number of sequences to decode (default: %d)
-ns,   --sequences N
enable continuous batching (a.k.a dynamic batching) (default: %s)
-cb,   --cont-batching
disable continuous batching
-nocb, --no-cont-batching
multi-modality
path to a multimodal projector file for LLaVA. see examples/llava/README.md
       --mmproj FILE
path to an image file. use with multimodal models. Specify multiple times for batching
       --image FILE
backend
comma separated list of RPC servers
       --rpc SERVERS
force system to keep model in RAM rather than swapping or compressing
       --mlock
do not memory-map model (slower load but may reduce pageouts if not using mlock)
       --no-mmap
attempt optimizations that help on some NUMA systems
  - distribute: spread execution evenly over all nodes
  - isolate: only spawn threads on CPUs on the node that execution started on
  - numactl: use the CPU map provided by numactl
if run without this previously, it is recommended to drop the system page cache before using this
see https://github.com/ggerganov/llama.cpp/issues/1437
       --numa TYPE
number of layers to store in VRAM
-ngl,  --gpu-layers N
number of layers to store in VRAM for the draft model
-ngld, --gpu-layers-draft N
how to split the model across multiple GPUs, one of:
  - none: use one GPU only
  - layer (default): split layers and KV across GPUs
  - row: split rows across GPUs
-sm,   --split-mode SPLIT_MODE
fraction of the model to offload to each GPU, comma-separated list of proportions, e.g. 3,1
-ts,   --tensor-split SPLIT
the GPU to use for the model (with split-mode = none),
or for intermediate results and KV (with split-mode = row) (default: %d)
-mg,   --main-gpu i
check model tensor data for invalid values (default: %s)
       --check-tensors
advanced option to override model metadata by key. may be specified multiple times.
types: int, float, bool, str. example: --override-kv tokenizer.ggml.add_bos_token=bool:false
       --override-kv KEY=TYPE:VALUE
apply LoRA adapter (can be repeated to use multiple adapters)
       --lora FNAME
apply LoRA adapter with user defined scaling S (can be repeated to use multiple adapters)
       --lora-scaled FNAME S
add a control vector
note: this argument can be repeated to add multiple control vectors
       --control-vector FNAME
add a control vector with user defined scaling SCALE
note: this argument can be repeated to add multiple scaled control vectors
       --control-vector-scaled FNAME SCALE
layer range to apply the control vector(s) to, start and end inclusive
       --control-vector-layer-range START END
models/7B/ggml-model-f16.gguf
model path (default: models/$filename with filename from --hf-file
or --model-url if set, otherwise %s)
-m,    --model FNAME
draft model for speculative decoding (default: unused)
-md,   --model-draft FNAME
model download url (default: unused)
-mu,   --model-url MODEL_URL
Hugging Face model repository (default: unused)
-hfr,  --hf-repo REPO
Hugging Face model file (default: unused)
-hff,  --hf-file FILE
Hugging Face access token (default: value from HF_TOKEN environment variable)
-hft,  --hf-token TOKEN
retrieval
file to load context from (repeat to specify multiple files)
       --context-file FNAME
minimum length of embedded text chunks (default: %d)
       --chunk-size N
separator between chunks (default: '%s')
       --chunk-separator STRING
passkey
number of times to repeat the junk text (default: %d)
       --junk N
position of the passkey in the junk text (default: %d)
       --pos N
imatrix
output file (default: '%s')
-o,    --output FNAME
output the imatrix every N iterations (default: %d)
       --output-frequency N
save an imatrix copy every N iterations (default: %d)
       --save-frequency N
collect data for the output tensor (default: %s)
       --process-output
do not compute perplexity (default: %s)
       --no-ppl
start processing the input from chunk N (default: %d)
       --chunk N
bench
is the prompt shared across parallel sequences (default: %s)
-pps
number of prompt tokens
-npp n0,n1,...
number of text generation tokens
-ntg n0,n1,...
number of parallel prompts
-npl n0,n1,...
normalisation for embendings (default: %d) (-1=none, 0=max absolute int16, 1=taxicab, 2=euclidean, >2=p-norm)
       --embd-normalize
empty = default, "array" = [[],[]...], "json" = openai style, "json+" = same "json" + cosine similarity matrix
       --embd-output-format
separator of embendings (default \n) for example "<#sep#>"
       --embd-separator
server
ip address to listen (default: %s)
       --host HOST
port to listen (default: %d)
       --port PORT
path to serve static files from (default: %s)
       --path PATH
restrict to only support embedding use case; use only with dedicated embedding models (default: %s)
       --embedding(s)
API key to use for authentication (default: none)
       --api-key KEY
path to file containing API keys (default: none)
       --api-key-file FNAME
path to file a PEM-encoded SSL private key
       --ssl-key-file FNAME
path to file a PEM-encoded SSL certificate
       --ssl-cert-file FNAME
server read/write timeout in seconds (default: %d)
       --timeout N
number of threads used to process HTTP requests (default: %d)
       --threads-http N
set a file to load a system prompt (initial prompt of all slots), this is useful for chat applications
       --system-prompt-file FNAME
log output format: json or text (default: json)
       --log-format {text,json}
enable prometheus compatible metrics endpoint (default: %s)
       --metrics
disables slots monitoring endpoint (default: %s)
       --no-slots
path to save slot kv cache (default: disabled)
       --slot-save-path PATH
set custom jinja chat template (default: template taken from model's metadata)
only commonly used templates are accepted:
https://github.com/ggerganov/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template
how much the prompt of a request must match the prompt of a slot in order to use that slot (default: %.2f, 0.0 = disabled)
-sps,  --slot-prompt-similarity SIMILARITY
cvector
positive prompts file, one prompt per line (default: '%s')
       --positive-file FNAME
negative prompts file, one prompt per line (default: '%s')
       --negative-file FNAME
batch size used for PCA. Larger batch runs faster, but uses more memory (default: %d)
       --pca-batch N
number of iterations used for PCA (default: %d)
       --pca-iter N
dimensionality reduction method to be used (default: pca)
       --method {pca,mean}
export-lora
model path from which to load base model (default '%s')
-m,    --model
path to LoRA adapter  (can be repeated to use multiple adapters)
path to LoRA adapter with user defined scaling S  (can be repeated to use multiple adapters)
number of threads to use during computation (default: %d)
usage: %s [options]
  %-32s
%34s
basic_string::substr
%34s
%Y_%m_%d-%H_%M_%S
%09ld
LLAMA_CACHE
XDG_CACHE_HOME
HOME
/.cache/
llama.cpp
params.kv_overrides.back().key[0] == 0 && "KV overrides not terminated with empty key"
%s: llama.cpp built without libcurl, downloading from an url not supported.
%s: llama.cpp built without libcurl, downloading from Hugging Face not supported.
check == -n_chars
n_chars <= (int32_t)text.size()
test
=== Dumping KV cache. total cells %d, max sequences per cell %d, populated cells %d, total tokens in cache %d, largest empty slot=%d @ %d
=== Done dumping
%5d: 
%s: [
%e, 
%d, 
q8_0
q4_0
q4_1
iq4_nl
q5_0
q5_1
Invalid cache type: 
filename.find(DIRECTORY_SEPARATOR) == std::string::npos
failed to create cache directory: 
system_info: n_threads = 
 (n_threads_batch = 
error: --hf-repo requires either --hf-file or --model
%s: malformed KV override '%s'
int:
float:
bool:
%s: invalid boolean value for KV override '%s'
str:
%s: malformed KV override '%s', value cannot exceed 127 chars
%s: invalid type for KV override '%s'
cannot create std::vector larger than max_size()
check == -n_tokens
%s: no valid control vector files passed
%s: failed to load control vector file from %s
%s: no direction tensors found in %s
direction
%s: invalid/unparsable direction tensor layer index in %s
%s: invalid (zero) direction tensor layer index in %s
%s: invalid (non-F32) direction tensor type in %s
%s: invalid (non-1D) direction tensor shape in %s
%s: direction tensor in %s does not match previous dimensions
%s: skipping %s due to invalid direction tensors
%s: control vectors in %s does not match previous dimensions
chatml
this custom template is not supported
You are a helpful assistant
Hello
assistant
How are you?
%s: error: failed to create context with model '%s'
=== Dumping KV cache. total cells %d, max sequences per cell %d, populated cells %d, total tokens in cache %d, largest empty slot=%d @ %d
=== Sequence legend: 
'+'=other sequence ids
%zu=%d, 
invalid_iterator
out_of_range
/sys/devices/system/cpu/cpu
/topology/thread_siblings
wstring_convert::from_bytes
wstring_convert::to_bytes
--seed
stoul
--threads
--threads-batch
--threads-draft
-tbd
--threads-batch-draft
--prompt
--escape
--no-escape
--prompt-cache
--prompt-cache-all
--prompt-cache-ro
--binary-file
error: failed to open file '%s'
Read %zu bytes from binary file %s
--file
--in-file
--predict
--n-predict
--top-k
--ctx-size
--grp-attn-n
-gan
--grp-attn-w
-gaw
--rope-freq-base
stof
--rope-freq-scale
--rope-scaling
none
linear
yarn
--rope-scale
--yarn-orig-ctx
--yarn-ext-factor
--yarn-attn-factor
--yarn-beta-fast
--yarn-beta-slow
--pooling
mean
last
--attention
causal
non-causal
--defrag-thold
--samplers
--sampling-seq
--top-p
--min-p
--temp
--tfs
--typical
--repeat-last-n
--repeat-penalty
--frequency-penalty
--presence-penalty
--dynatemp-range
--dynatemp-exp
--mirostat
--mirostat-lr
--mirostat-ent
--cfg-negative-prompt
--cfg-negative-prompt-file
--cfg-scale
--batch-size
--ubatch-size
--keep
--draft
--chunks
--parallel
--sequences
--p-split
--model
--model-draft
--alias
--model-url
-hft
--hf-token
-hfr
--hf-repo
-hff
--hf-file
--lora
--lora-scaled
--control-vector
--control-vector-scaled
--control-vector-layer-range
--mmproj
--image
--interactive
--special
--embedding
--embeddings
--embd-normalize
--embd-output-format
--embd-separator
--interactive-first
-cnv
--conversation
--infill
-dkvc
--dump-kv-cache
-nkvo
--no-kv-offload
-ctk
--cache-type-k
-ctv
--cache-type-v
-mli
--multiline-input
--simple-io
--cont-batching
-nocb
--no-cont-batching
--flash-attn
--color
--mlock
-ngl
--gpu-layers
--n-gpu-layers
-ngld
warning: not compiled with GPU offload support, --gpu-layers option will be ignored
warning: see main README.md for information on enabling GPU BLAS support
--gpu-layers-draft
--main-gpu
warning: not compiled with GPU offload support, --gpu-layers-draft option will be ignored
--split-mode
warning: llama.cpp was compiled without CUDA/SYCL/Vulkan. Setting the main GPU has no effect.
--tensor-split
layer
warning: llama.cpp was compiled without CUDA/SYCL/Vulkan. Setting the split mode has no effect.
--rpc
[,/]+
warning: llama.cpp was compiled without CUDA/SYCL/Vulkan. Setting a tensor split has no effect.
--no-mmap
--numa
distribute
isolate
numactl
--verbose
--verbosity
--verbose-prompt
--no-display-prompt
--reverse-prompt
--logdir
-lcs
--lookup-cache-static
-lcd
--lookup-cache-dynamic
--save-all-logits
--kl-divergence-base
--perplexity
--all-logits
--ppl-stride
--ppl-output-type
-ptc
--print-token-count
--check-tensors
--hellaswag
--hellaswag-tasks
--winogrande
--winogrande-tasks
--multiple-choice
--multiple-choice-tasks
--kl-divergence
--ignore-eos
--penalize-nl
--logit-bias
--help
--usage
--version
version: %d (%s)
built with %s for %s
--in-prefix-bos
--in-prefix
--in-suffix
--spm-infill
--grammar
--grammar-file
--json-schema
--override-kv
error: Invalid type for KV override: %s
--host
--port
--path
--api-key
--api-key-file
--ssl-key-file
--ssl-cert-file
--timeout
--threads-http
-spf
--system-prompt-file
--log-format
json
text
--no-slots
--metrics
--slot-save-path
--chat-template
error: the supplied chat template is not supported: %s
note: llama.cpp does not use jinja parser, we only support commonly used templates
--slot-prompt-similarity
-sps
-npp
-ntg
-npl
--context-file
--chunk-size
--chunk-separator
--junk
--pos
--output
--output-file
-ofreq
--output-frequency
--save-frequency
--process-output
--no-ppl
--chunk
--from-chunk
--positive-file
--negative-file
--pca-batch
--pca-iter
--method
--no-warmup
error: unknown argument: 
error: invalid parameter for argument: 
error: --prompt-cache-all not supported in interactive mode yet
\\[^n"]
%s: %s
%s: |
  %s
build_commit: %s
build_number: %d
cpu_has_arm_fma: %s
cpu_has_avx: %s
cpu_has_avx_vnni: %s
cpu_has_avx2: %s
cpu_has_avx512: %s
cpu_has_avx512_vbmi: %s
cpu_has_avx512_vnni: %s
cpu_has_cuda: %s
cpu_has_vulkan: %s
cpu_has_kompute: %s
cpu_has_fma: %s
cpu_has_gpublas: %s
cpu_has_neon: %s
cpu_has_sve: %s
cpu_has_f16c: %s
cpu_has_fp16_va: %s
cpu_has_wasm_simd: %s
cpu_has_blas: %s
cpu_has_sse3: %s
cpu_has_vsx: %s
cpu_has_matmul_int8: %s
debug: false
model_desc: %s
n_vocab: %d  # output size of the final layer, 32001 for some models
optimize: true
time: %s
###############
# User Inputs #
alias: %s # default: unknown
batch_size: %d # default: 512
cfg_negative_prompt
cfg_scale: %f # default: 1.0
chunks: %d # default: -1 (unlimited)
color: %s # default: false
ctx_size: %d # default: 512
escape: %s # default: false
file: # never logged, see prompt instead. Can still be specified for input.
frequency_penalty: %f # default: 0.0 
grammar-file: # never logged, see grammar instead. Can still be specified for input.
hellaswag: %s # default: false
hellaswag_tasks: %zu # default: 400
ignore_eos: %s # default: false
in_prefix
in_prefix_bos: %s # default: false
in_suffix
interactive: %s # default: false
interactive_first: %s # default: false
keep: %d # default: 0
logdir: %s # default: unset (no logging)
logit_bias:
lora:
  %d: %f
lora_scaled:
  - %s
main_gpu: %d # default: 0
min_keep: %d # default: 0 (disabled)
mirostat: %d # default: 0 (disabled)
mirostat_ent: %f # default: 5.0
mirostat_lr: %f # default: 0.1
  - %s: %f
mlock: %s # default: false
model: %s # default: %s
model_draft: %s # default:
multiline_input: %s # default: false
n_gpu_layers: %d # default: -1
n_predict: %d # default: -1 (unlimited)
n_probs: %d # only used by server binary, default: 0
no_mmap: %s # default: false
penalize_nl: %s # default: false
ppl_output_type: %d # default: 0
ppl_stride: %d # default: 0
presence_penalty: %f # default: 0.0
prompt
prompt_cache: %s
prompt_cache_all: %s # default: false
prompt_cache_ro: %s # default: false
prompt_tokens
repeat_penalty: %f # default: 1.1
reverse_prompt:
rope_freq_base: %f # default: 10000.0
rope_freq_scale: %f # default: 1.0
seed: %u # default: -1 (random seed)
simple_io: %s # default: false
cont_batching: %s # default: false
flash_attn: %s # default: false
temp: %f # default: 0.8
tensor_split
tfs: %f # default: 1.0
threads: %d # default: %u
top_k: %d # default: 40
top_p: %f # default: 0.95
min_p: %f # default: 0.0
typical_p: %f # default: 1.0
verbose_prompt: %s # default: false
display_prompt: %s # default: true
alert
backspace
newline
vertical-tab
form-feed
carriage-return
exclamation-mark
quotation-mark
number-sign
dollar-sign
percent-sign
ampersand
apostrophe
left-parenthesis
right-parenthesis
asterisk
plus-sign
comma
hyphen
period
slash
zero
three
four
five
seven
nine
colon
semicolon
less-than-sign
equals-sign
greater-than-sign
question-mark
commercial-at
left-square-bracket
backslash
right-square-bracket
circumflex
underscore
grave-accent
left-curly-bracket
vertical-line
right-curly-bracket
tilde
alnum
alpha
blank
cntrl
digit
graph
lower
print
punct
upper
xdigit
[json.exception.
Unexpected end of regex when escaping.
Unexpected end of regex when reading control code.
Unexpected end of regex when ascii character.
vector::_M_fill_insert
parse_error
 at line 
, column 
parse error
<U+%.4X>
end of input
null literal
true literal
string literal
<uninitialized>
unknown token
number literal
false literal
'[', '{', or a literal
<parse error>
syntax error 
while parsing 
; last read: '
unexpected 
; expected 
!keep_stack.empty()
ref_stack.back()->is_array() || ref_stack.back()->is_object()
!key_keep_stack.empty()
object_element
!ref_stack.empty()
Unexpected escape character.
Unexpected end of regex when in an open parenthesis.
Invalid special open parenthesis.
Unexpected end of regex when in brace expression.
Unexpected character in brace expression.
current == 'u'
ranges.size() == 2 || ranges.size() == 4 || ranges.size() == 6
invalid string: ill-formed UTF-8 byte
current == '\"'
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: missing closing quote
invalid string: '\u' must be followed by 4 hex digits
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
invalid string: forbidden character after backslash
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after exponent sign
!token_string.empty()
endptr == token_buffer.data() + token_buffer.size()
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid comment; missing closing '*/'
invalid comment; expecting '/' or '*' after '/'
invalid literal
object key
object separator
ref_stack.back()->is_array()
attempting to parse an empty input; check that your input string or stream contains the expected JSON
!states.empty()
array
object
Unexpected end of character class.
Unexpected end of regex when in bracket expression.
Unexpected character class open bracket.
^$\.*+?()[]{}|
.[\()*+?{|^$
.[\*^$
.[\()*+?{|^$
.[\*^$
discarded
number
binary
boolean
string
iterator does not fit current value
iterator out of range
cannot use erase() with 
type_error
m_object != nullptr
cannot compare iterators of different containers
m_it.object_iterator != m_object->m_data.m_value.object->end()
m_it.array_iterator != m_object->m_data.m_value.array->end()
cannot get value
loc != nullptr
basic_string::_M_create
basic_string::_M_replace_aux
Unexpected back-reference in polynomial mode.
Back-reference index exceeds current sub-expression count.
Back-reference referred to an opened sub-expression.
Number of NFA states exceeds limit. Please use shorter regex string, or use smaller brace expression, or make _GLIBCXX_REGEX_STATE_LIMIT larger.
Invalid character class.
Nothing to repeat before a quantifier.
Unexpected token in brace expression.
Unexpected end of brace expression.
Invalid range in brace expression.
Invalid collate element.
Invalid equivalence class.
Unexpected dash in bracket expression. For POSIX syntax, a dash is not treated literally only when it is at beginning or end.
Invalid range in bracket expression.
Character is expected after a dash.
Unexpected character in bracket expression.
Parenthesis is not closed.
N8nlohmann16json_abi_v3_11_36detail9exceptionE
N8nlohmann16json_abi_v3_11_36detail11parse_errorE
N8nlohmann16json_abi_v3_11_36detail16invalid_iteratorE
N8nlohmann16json_abi_v3_11_36detail10type_errorE
N8nlohmann16json_abi_v3_11_36detail12out_of_rangeE
St12codecvt_utf8IDiLm1114111ELSt12codecvt_mode0EE
St23_Sp_counted_ptr_inplaceINSt8__detail4_NFAINSt7__cxx1112regex_traitsIcEEEESaIS5_ELN9__gnu_cxx12_Lock_policyE2EE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb0ELb0ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb0ELb0ELb1EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb0ELb1ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb0ELb1ELb1EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb1ELb0ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb1ELb0ELb1EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb1ELb1ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIcEELb1ELb1ELb1EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIcEELb0ELb0EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIcEELb0ELb1EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIcEELb1ELb0EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIcEELb1ELb1EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIcEELb0ELb0EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIcEELb0ELb1EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIcEELb1ELb0EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIcEELb1ELb1EEE
00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
.123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz+
0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz
""//\\a
map::at
Failed to initialize llama_grammar
default
	repeat_last_n = %d, repeat_penalty = %.3f, frequency_penalty = %.3f, presence_penalty = %.3f
	top_k = %d, tfs_z = %.3f, top_p = %.3f, min_p = %.3f, typical_p = %.3f, temp = %.3f
	mirostat = %d, mirostat_lr = %.3f, mirostat_ent = %.3f
top_k
tfs_z
typical_p
top_p
min_p
temperature
CFG -> Penalties 
-> mirostat 
original_logits != NULL
!original_logits.empty()
llama_sampling_init
%s: failed to parse grammar
%s: grammar does not contain a 'root' symbol
top-k
top-p
nucleus
typical-p
typical
min-p
tfs-z
kkppyymmkfypmt
expecting 
 hex chars at 
unknown escape at 
unexpected end of input
expecting name at 
expecting integer at 
%s ::= 
malformed rule, does not end with LLAMA_GRETYPE_END: 
unexpected end of rule: 
<U+%04X>
LLAMA_GRETYPE_CHAR_RNG_UPPER without preceding char: 
LLAMA_GRETYPE_CHAR_ALT without preceding char: 
expecting ')' at 
expecting preceding item to */+/?/{ at 
expecting an int at 
expecting '}' at 
expecting ',' at 
expecting ::= at 
expecting newline or end at 
Undefined rule identifier '
parse
%s: error parsing grammar: %s
print_grammar
%s: error printing grammar: %s
_Map_base::at
type must be string, but is 
JSON schema conversion failed:
WARNING: JSON schema conversion was incomplete: %s
 ::= 
| " " | "\n" [ \t]{0,20}
("true" | "false") space
[0-9]{1,16}
decimal-part
[0] | [1-9] [0-9]{0,15}
integral-part
("-"? integral-part) ("." decimal-part)? ([eE] [-+]? integral-part)? space
("-"? integral-part) space
object | array | string | number | boolean | null
"{" space ( string ":" space value ("," space string ":" space value)* )? "}" space
"[" space ( value ("," space value)* )? "]" space
"\"" [0-9a-fA-F]{8} "-" [0-9a-fA-F]{4} "-" [0-9a-fA-F]{4} "-" [0-9a-fA-F]{4} "-" [0-9a-fA-F]{12} "\"" space
[^"\\\x7F\x00-\x1F] | [\\] (["\\bfnrt] | "u" [0-9a-fA-F]{4})
"\"" char* "\"" space
"null" space
[0-9]{4} "-" ( "0" [1-9] | "1" [0-2] ) "-" ( "0" [1-9] | [1-2] [0-9] | "3" [0-1] )
date
([01] [0-9] | "2" [0-3]) ":" [0-5] [0-9] ":" [0-5] [0-9] ( "." [0-9]{3} )? ( "Z" | ( "+" | "-" ) ( [01] [0-9] | "2" [0-3] ) ":" [0-5] [0-9] )
time
date "T" time
date-time
"\"" date "\"" space
date-string
"\"" time "\"" space
time-string
"\"" date-time "\"" space
date-time-string
[^a-zA-Z0-9-]+
"\]\-\\]
[0-9]
string_view index out of range
basic_string::basic_string
"-" (
) | 
) | [0] | [1-9] 
[0] | [1-9] 
"-" [1-9] 
At least one of min_value or max_value must be set
n_chars < number_buffer.size() - 1
it != m_data.m_value.object->end()
cannot use operator[] with a string argument with 
anchor.m_object != nullptr
0123456789ABCDEF
index < utf8d.size()
\u%04x
\u%04x\u%04x
invalid UTF-8 byte at index 
: 0x
incomplete UTF-8 string; last byte: 0x
\ufffd
cannot use operator[] with a numeric argument with 
type must be array, but is 
type must be number, but is 
$ref
properties
value > 0
delta >= 0
((x.f << delta) >> delta) == x.f
x.f != 0
m_plus.e == m_minus.e
m_plus.e == v.e
e >= -1500
e <= 1500
index >= 0
static_cast<std::size_t>(index) < kCachedPowers.size()
kAlpha <= cached.e + e + 64
kGamma >= cached.e + e + 64
x.f >= y.f
p1 > 0
d <= 9
len >= 1
dist <= delta
ten_k > 0
buf[len - 1] != '0'
p2 > delta
last - first >= std::numeric_limits<FloatType>::max_digits10
len <= std::numeric_limits<FloatType>::max_digits10
last - first >= 2 + (-kMinExp - 1) + std::numeric_limits<FloatType>::max_digits10
last - first >= std::numeric_limits<FloatType>::max_digits10 + 6
k > n
e > -1000
e < 1000
i != val.m_data.m_value.object->cend()
std::next(i) == val.m_data.m_value.object->cend()
!val.m_data.m_value.array->empty()
"bytes": [
"subtype": 
{"bytes":[
],"subtype":
null}
<discarded>
https://
Unsupported ref: 
Error resolving ref 
 not in 
( "," space 
-rest
Pattern must start with '^' and end with '$'
"\"" 
[\U00000000-\U0010FFFF]
[^\x0A\x0D]
Unsupported pattern syntax
Unbalanced parentheses
Wrong number of values in curly brackets
Invalid number in curly brackets
Unbalanced square brackets
Unbalanced curly brackets
Rule 
 not known
char
["] ( 
 ["] space
format
root
oneOf
anyOf
const
 space
enum
) space
additionalProperties
required
allOf
items
prefixItems
"[" space 
 "," space 
tuple-
 "]" space
item
minItems
maxItems
"," space
pattern
^uuid[1-5]?$
uuid
-string
minLength
maxLength
integer
minimum
exclusiveMinimum
maximum
exclusiveMaximum
Unrecognized schema: 
alternative-
 space ":" space 
additional
-value
 ":" space 
"{" space 
 "," space ( 
 "}" space
N8nlohmann16json_abi_v3_11_36detail23output_adapter_protocolIcEE
ZN15SchemaConverter14_visit_patternERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES7_EUlvE0_
ZN15SchemaConverter12_not_stringsERKSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESaIS6_EEEUlRKZNS_12_not_stringsESA_E8TrieNodeE_
N8nlohmann16json_abi_v3_11_36detail21output_string_adapterIcNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE
ZN15SchemaConverter18_build_object_ruleERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEN8nlohmann16json_abi_v3_11_310basic_jsonINS9_11ordered_mapES0_S7_blmdSaNS9_14adl_serializerES0_IhSaIhEEvEEESaISG_EERKSt13unordered_setIS7_St4hashIS7_ESt8equal_toIS7_ESaIS7_EERKS7_RKSF_EUlRKS0_IS7_SQ_EbE_
ZN15SchemaConverter12resolve_refsERN8nlohmann16json_abi_v3_11_310basic_jsonINS1_11ordered_mapESt6vectorNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEblmdSaNS1_14adl_serializerES4_IhSaIhEEvEERKSA_EUlSF_E_
ZN15SchemaConverter5visitERKN8nlohmann16json_abi_v3_11_310basic_jsonINS1_11ordered_mapESt6vectorNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEblmdSaNS1_14adl_serializerES4_IhSaIhEEvEERKSA_EUlSG_bE_
St23_Sp_counted_ptr_inplaceIN8nlohmann16json_abi_v3_11_36detail21output_string_adapterIcNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEESaISA_ELN9__gnu_cxx12_Lock_policyE2EE
																
000102030405060708091011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798990001020304050607080910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989900010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
U1(\Q
mSx@
b}$l
~)p$w
11eU%
z^KD
|.()[]{}^$.[]()|^
""//\\a
*ZL18_build_min_max_intiiRNSt7__cxx1118basic_stringstreamIcSt11char_traitsIcESaIcEEEibEUlRK11string_viewS8_E1_
*ZL14format_literalRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEUlRKNS_13match_resultsIN9__gnu_cxx17__normal_iteratorIPKcS4_EESaINS_9sub_matchISC_EEEEEE_
*Z22json_schema_to_grammarRKN8nlohmann16json_abi_v3_11_310basic_jsonINS0_11ordered_mapESt6vectorNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEblmdSaNS0_14adl_serializerES3_IhSaIhEEvEEEUlRKS9_E_
aarch64-none-linux-gnu
aarch64-none-linux-gnu-gcc (GNU Toolchain for the A-profile Architecture 10.2-2020.11 (arm-10.16)) 10.2.1 20201103
27637c95
llama
falcon
grok
gpt2
gptj
gptneox
baichuan
starcoder
refact
bert
nomic-bert
jina-bert-v2
bloom
stablelm
qwen
qwen2
qwen2moe
phi2
phi3
plamo
codeshell
orion
internlm2
minicpm
minicpm3
gemma
gemma2
gemma3
starcoder2
mamba
xverse
command-r
dbrx
olmo
openelm
arctic
deepseek2
chatglm
bitnet
jais
telechat
custom
rwkv7
(unknown)
general.type
general.architecture
general.quantization_version
general.alignment
general.name
general.author
general.version
general.url
general.description
general.license
general.source.url
general.source.huggingface.repository
%s.vocab_size
%s.context_length
%s.embedding_length
%s.block_count
%s.leading_dense_block_count
%s.feed_forward_length
%s.expert_feed_forward_length
%s.expert_shared_feed_forward_length
%s.use_parallel_residual
%s.tensor_data_layout
%s.expert_count
%s.expert_used_count
%s.expert_shared_count
%s.expert_weights_scale
%s.pooling_type
%s.logit_scale
%s.decoder_start_token_id
%s.attn_logit_softcapping
%s.final_logit_softcapping
%s.attention.head_count
%s.attention.head_count_kv
%s.attention.max_alibi_bias
%s.attention.clamp_kqv
%s.attention.key_length
%s.attention.value_length
%s.attention.layer_norm_epsilon
%s.attention.layer_norm_rms_epsilon
%s.attention.causal
%s.attention.q_lora_rank
%s.attention.kv_lora_rank
%s.attention.relative_buckets_count
%s.attention.sliding_window
%s.attention.decay_lora_rank
%s.attention.iclr_lora_rank
%s.attention.value_residual_mix_lora_rank
%s.attention.gate_lora_rank
%s.wkv.head_size
%s.token_shift_count
%s.rope.dimension_count
%s.rope.freq_base
%s.rope.dimension_sections
%s.rope.scale_linear
%s.rope.scaling.type
%s.rope.scaling.factor
%s.rope.scaling.attn_factor
%s.rope.scaling.original_context_length
%s.rope.scaling.finetuned
%s.rope.scaling.yarn_log_multiplier
split.no
split.count
split.tensors.count
%s.ssm.conv_kernel
%s.ssm.inner_size
%s.ssm.state_size
%s.ssm.time_step_rank
tokenizer.ggml.model
tokenizer.ggml.pre
tokenizer.ggml.tokens
tokenizer.ggml.token_type
tokenizer.ggml.token_type_count
tokenizer.ggml.scores
tokenizer.ggml.merges
tokenizer.ggml.bos_token_id
tokenizer.ggml.eos_token_id
tokenizer.ggml.unknown_token_id
tokenizer.ggml.seperator_token_id
tokenizer.ggml.padding_token_id
tokenizer.ggml.cls_token_id
tokenizer.ggml.mask_token_id
tokenizer.ggml.add_bos_token
tokenizer.ggml.add_eos_token
tokenizer.ggml.add_space_prefix
tokenizer.ggml.remove_extra_whitespaces
tokenizer.ggml.precompiled_charsmap
tokenizer.huggingface.json
tokenizer.rwkv.world
tokenizer.ggml.prefix_token_id
tokenizer.ggml.suffix_token_id
tokenizer.ggml.middle_token_id
tokenizer.ggml.eot_token_id
tokenizer.ggml.eom_token_id
adapter.type
adapter.lora.alpha
rkllm.platform
rkllm.core_num
rkllm.m_align
rkllm.vision.spatial_merge_size
rkllm.vision.spatial_patch_size
rkllm.hidden_act_param
rkllm.act_type
rkllm.ffn_gate
rkllm.ffn_up
rkllm.ffn_down
rkllm.scale_depth
rkllm.scale_emb
rkllm.dim_model_base
rkllm.chat_template.pre
rkllm.chat_template.system
rkllm.chat_template.post
rkllm.version
rkllm.max_context
mrope
%s-%d
kqv_merged_cont
fatal error
kv.size == n_ctx
k_cache_view
v_cache_view
inp_tokens
inp_embd
%5ld
, %5ld
kq_soft_max_ext
kqv_merged
kqv_wo
kqv_out
ffn_moe_logits
ffn_moe_probs
ffn_moe_argsort
ffn_moe_topk
ffn_moe_weights
ffn_moe_weights_sum
ffn_moe_weights_norm
ffn_moe_weights_scaled
ffn_moe_up
ffn_moe_gate
ffn_moe_silu
ffn_moe_gate_par
ffn_moe_down
ffn_up
ffn_up_s
ffn_gate
ffn_gate_s
ffn_silu
ffn_act_smoothq
ffn_gelu
ffn_act
ffn_relu
ffn_fatrelu
ffn_sqr(relu)
ffn_mul
ffn_gate_par
ffn_down
ffn_up_b
ffn_gate_b
vector::_M_range_check: __n (which is %zu) >= this->size() (which is %zu)
size >= 0 && size < INT_MAX
size2 == size
blk.%d.
Failed to determine layer for tensor %s
Bad layer %d for tensor %s. Must be in [0, %d)
E rkllm: tensor %s not found
%s: tensor '%s' not found
E rkllm: tensor %s has wrong shape, expected %s, got %s
%s: tensor '%s' has wrong shape; expected %s, got %s
%s: tensor '%s' has wrong type; expected %s, got %s
 (guessed)
all F32
Q2_K - Medium
Q2_K - Small
Q3_K - Small
Q3_K - Medium
Q3_K - Large
Q4_K - Small
Q4_K - Medium
Q5_K - Small
Q5_K - Medium
IQ2_XXS - 2.0625 bpw
IQ2_XS - 2.3125 bpw
IQ2_S - 2.5 bpw
IQ2_M - 2.7 bpw
IQ3_XS - 3.3 bpw
IQ3_XXS - 3.0625 bpw
IQ1_S - 1.5625 bpw
IQ1_M - 1.75 bpw
IQ4_NL - 4.5 bpw
IQ4_XS - 4.25 bpw
IQ3_S - 3.4375 bpw
IQ3_S mix - 3.66 bpw
unknown, may not work
weight
__missing__
token_embd.weight
attn_v.weight
attn_k.weight
attn_output.weight
attn_q.weight
attn_qkv.weight
Unsupported tensor size encountered
inp != nullptr && "missing result_norm/result_embd tensor"
inp_mean
inp_cls
unknown pooling type
result_embd_pooled
unknown architecture
109M
137M
160M
220M
250M
270M
335M
410M
450M
770M
780M
0.5B
1.3B
1.4B
2.8B
6.9B
236B
314B
0.1B
0.4B
0.8B
1.5B
A2.7B
8x7B
8x22B
16x12B
10B+128x3.66B
57B.A14B
%s %s %s
p != nullptr && "Failed to alloc kv_cache_view cells"
p != nullptr && "Failed to alloc kv_cache_view cells sequences"
no logits
negative index out of range [0, %d)
out of range [0, %lu)
batch.logits[%d] != true
corrupt output buffer (j=%d, n_outputs=%d)
no embeddings
Deepseek2 does not support K-shift
kv_self.recurrent
nf == nh && "KV defrag bug: nf != nh"
%s-%05d-of-%05d.gguf
-%05d-of-%05d.gguf
I rkllm: --------------------------------------------------------------------------------------
Tokens per Second
Time per Token (ms)
Tokens
Total Time (ms)
Stage
I rkllm:  %-12s  %-15s  %-8s  %-23s  %-23s
Init
I rkllm:  %-12s  %-15.2f  %-8s  %-23s  %-23s
Prefill
I rkllm:  %-12s  %-15.2f  %-8d  %-23.2f  %-23.2f
Generate
/proc/self/status
Failed to open /proc/self/status
VmHWM:
%*s %ld
Memory Usage (GB)
I rkllm:  %-12s
I rkllm:  %-12.2f
I rkllm:  Memory Usage not found in /proc/self/status
AVX = 
AVX_VNNI = 
AVX2 = 
AVX512 = 
AVX512_VBMI = 
AVX512_VNNI = 
AVX512_BF16 = 
FMA = 
NEON = 
SVE = 
ARM_FMA = 
F16C = 
FP16_VA = 
WASM_SIMD = 
BLAS = 
SSE3 = 
SSSE3 = 
VSX = 
MATMUL_INT8 = 
LLAMAFILE = 
###########
# Timings #
mst_eval: %.2f  # ms / token during generation
mst_p_eval: %.2f  # ms / token during prompt processing
mst_sample: %.2f  # ms / token during sampling
n_eval: %d  # number of tokens generated (excluding the first one)
n_p_eval: %d  # number of tokens processed in batches at the beginning
n_sample: %d  # number of sampled tokens
t_eval_us: %ld  # total microseconds spent generating tokens
t_load_us: %ld  # total microseconds spent loading the model
t_p_eval_us: %ld  # total microseconds spent prompt processing
t_sample_us: %ld  # total microseconds spent sampling
ts_eval: %.2f  # tokens / second during generation
ts_p_eval: %.2f  # tokens / second during prompt processing
ts_sample: %.2f  # tokens / second during sampling
unknown type %d
failed to load RNG state
E rkllm: unsupported model architecture: %s
unknown model architecture: '
<|im_start|>
<|im_end|>
<|im_start|>assistant
llama2
mistral
[INST]
<<SYS>>
' ' + eos_token
bos_token + '[INST]
content.strip()
[INST] 
<s>[INST] 
<<SYS>>
<</SYS>>
 [/INST]
</s>
<|assistant|>
<|end|>
<|end|>
<|assistant|>
zephyr
<|endoftext|>
monarch
bos_token + message['role']
</s>
<s>assistant
<start_of_turn>
<end_of_turn>
<start_of_turn>model
'\n\nAssistant: ' + eos_token
Human: 
Assistant: </s>
openchat
GPT4 Correct 
<|end_of_turn|>
GPT4 Correct Assistant:
vicuna
vicuna-orca
USER: 
ASSISTANT: 
SYSTEM: 
ASSISTANT:
deepseek
### Instruction:
<|EOT|>
### Instruction:
### Response:
<|EOT|>
<|START_OF_TURN_TOKEN|>
<|USER_TOKEN|>
<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>
<|END_OF_TURN_TOKEN|>
<|START_OF_TURN_TOKEN|><|USER_TOKEN|>
<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>
llama3
<|start_header_id|>
<|end_header_id|>
<|end_header_id|>
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>
chatglm3
[gMASK]sop
[gMASK]
chatglm4
[gMASK]<sop>
<sop>
<AI>
'Assistant: ' + message['content'] + eos_token
User: 
Assistant: 
sentence
Assistant:
model != nullptr
tokenizer.chat_template
token_embd
output_norm
rope_freqs
blk.%d.attn_norm
blk.%d.attn_q
blk.%d.attn_k
blk.%d.attn_v
blk.%d.attn_output
blk.%d.attn_rot_embd
blk.%d.ffn_gate_inp
blk.%d.ffn_norm
blk.%d.ffn_gate
blk.%d.ffn_down
blk.%d.ffn_up
blk.%d.ffn_gate.%d
blk.%d.ffn_down.%d
blk.%d.ffn_up.%d
blk.%d.ffn_gate_exps
blk.%d.ffn_down_exps
blk.%d.ffn_up_exps
blk.%d.ffn_act
blk.%d.attn_norm_2
blk.%d.attn_qkv
blk.%d.layer_output_norm
blk.%d.attn_output_norm
position_embd
blk.%d.ffn.act
blk.%d.attn_q_norm
blk.%d.attn_k_norm
token_embd_norm
token_types
blk.%d.ffn_gate_inp_shexp
blk.%d.ffn_gate_shexp
blk.%d.ffn_down_shexp
blk.%d.ffn_up_shexp
rope_factors_long
rope_factors_short
blk.%d.attn_q_a_norm
blk.%d.attn_kv_a_norm
blk.%d.attn_q_a
blk.%d.attn_q_b
blk.%d.attn_kv_a_mqa
blk.%d.attn_kv_b
blk.%d.post_attention_norm
blk.%d.post_ffw_norm
blk.%d.ssm_in
blk.%d.ssm_conv1d
blk.%d.ssm_x
blk.%d.ssm_dt
blk.%d.ssm_a
blk.%d.ssm_d
blk.%d.ssm_out
blk.%d.ffn_norm_exps
blk.%d.attn_sub_norm
blk.%d.ffn_sub_norm
dec.output_norm
dec.blk.%d.attn_norm
dec.blk.%d.attn_q
dec.blk.%d.attn_k
dec.blk.%d.attn_v
dec.blk.%d.attn_o
dec.blk.%d.attn_rel_b
dec.blk.%d.cross_attn_norm
dec.blk.%d.cross_attn_q
dec.blk.%d.cross_attn_k
dec.blk.%d.cross_attn_v
dec.blk.%d.cross_attn_o
dec.blk.%d.cross_attn_rel_b
dec.blk.%d.ffn_norm
dec.blk.%d.ffn_gate
dec.blk.%d.ffn_down
dec.blk.%d.ffn_up
enc.output_norm
enc.blk.%d.attn_norm
enc.blk.%d.attn_q
enc.blk.%d.attn_k
enc.blk.%d.attn_v
enc.blk.%d.attn_o
enc.blk.%d.attn_rel_b
enc.blk.%d.ffn_norm
enc.blk.%d.ffn_gate
enc.blk.%d.ffn_down
enc.blk.%d.ffn_up
blk.%d.attn_kv
blk.%d.time_mix_w0
blk.%d.time_mix_w1
blk.%d.time_mix_w2
blk.%d.time_mix_a0
blk.%d.time_mix_a1
blk.%d.time_mix_a2
blk.%d.time_mix_v0
blk.%d.time_mix_v1
blk.%d.time_mix_v2
blk.%d.time_mix_g1
blk.%d.time_mix_g2
blk.%d.time_mix_k_k
blk.%d.time_mix_k_a
blk.%d.time_mix_r_k
blk.%d.time_mix_lerp_fused
blk.%d.time_mix_key
blk.%d.time_mix_value
blk.%d.time_mix_receptance
blk.%d.time_mix_ln
blk.%d.time_mix_output
blk.%d.channel_mix_lerp_k
blk.%d.channel_mix_key
blk.%d.channel_mix_value
(uint32_t) seq_id_src < cache.size
lctx.inp_out_ids && "every model that can must skip unused outputs"
ggml_backend_buffer_is_host(lctx.inp_out_ids->buffer)
lctx.n_outputs == n_outputs
lctx.n_outputs == 0
(hparams.causal_attn || !cparams.causal_attn) && "causal attention is not supported by this model"
ggml_backend_buffer_is_host(lctx.inp_KQ_mask->buffer)
ggml_backend_buffer_is_host(lctx.inp_KQ_mask_swa->buffer)
lctx.inp_mean
ggml_backend_buffer_is_host(lctx.inp_mean->buffer)
seq_id < n_tokens && "seq_id cannot be larger than n_tokens with pooling_type == MEAN"
lctx.inp_cls
ggml_backend_buffer_is_host(lctx.inp_cls->buffer)
seq_id < n_tokens && "seq_id cannot be larger than n_tokens with pooling_type == CLS"
seq_id < n_tokens && "seq_id cannot be larger than n_tokens with pooling_type == LAST"
ggml_backend_buffer_is_host(lctx.inp_s_mask->buffer)
ggml_backend_buffer_is_host(lctx.inp_s_seq->buffer)
0 < n_seq
ggml_backend_buffer_is_host(lctx.inp_pos_bucket->buffer)
ggml_backend_buffer_is_host(lctx.inp_KQ_mask_cross->buffer)
kv_self.head + cell_count <= kv_self.size
kv_self.cells[kv_self.head].pos == batch.pos[0]
kv_self.cells[kv_self.head + cell_count - 1].pos == batch.pos[cell_count - 1]
kv_self.cells[kv_self.head].has_seq_id(dest_seq_id)
kv_self.cells[kv_self.head + cell_count - 1].has_seq_id(dest_seq_id)
failed to restore kv cache
wrong model arch: '%s' instead of '%s'
could not reserve outputs
invalid output id, %d does not fit in batch size of %u
logits buffer too small
embeddings buffer too small
(!batch_all.token && batch_all.embd) || (batch_all.token && !batch_all.embd)
n_tokens_all <= cparams.n_batch
(cparams.causal_attn || cparams.n_ubatch >= n_tokens_all) && "non-causal attention requires n_ubatch >= n_tokens"
n_threads > 0
strcmp(embd->name, "result_embd_pooled") == 0 && "missing embeddings tensor"
strcmp(res->name, "result_norm") == 0 && "missing embeddings tensor"
strcmp(res->name, "result_output") == 0 && "missing result_output tensor"
backend_res != nullptr
lctx.logits != nullptr
n_outputs_prev + n_outputs_new <= n_outputs
(n_outputs_prev + n_outputs_new)*n_vocab <= (int64_t) lctx.logits_size
backend_embd != nullptr
lctx.embd != nullptr
(n_outputs_prev + n_outputs_new)*n_embd <= (int64_t) lctx.embd_size
(!batch.token && batch.embd) || (batch.token && !batch.embd)
cparams.n_ubatch >= n_tokens && "encoder requires n_ubatch >= n_tokens"
strcmp(embd->name, "result_norm") == 0
type %s unsupported for integer quantization: no dequantization available
cannot dequantize/convert tensor type %s
nelements % block_size == 0
ctx_outs[cur_split] && "Find uninitialized gguf_context"
cell_count == cell_count_check
n_outputs <= ctx->output_size
(uint32_t) pos < n_outputs
res == sizeof(uint32_t) * 3 + sizeof(llama_token) * n_token_count + data_ctx.get_size_written()
nread <= state_size
nread + sizeof(uint32_t) * 3 + sizeof(llama_token) * *n_token_count_out == file.tell()
E rkllm: the prompt dose not match the current model[%s]
key not found in model: %s
n > N_MAX: %u > %u for key %s
key %s has wrong type %s but expected type %s
key %s has wrong array length; expected %u, got %u
array key not found in model: %s
(std::is_same<T, float>::value)
%s is not a float32, int32 array
array length %u for key %s exceeds max %u
hparams.n_embd_head_k % ggml_blck_size(type_k) == 0
hparams.n_embd_head_v % ggml_blck_size(type_v) == 0
cache_k_l%d
cache_v_l%d
cvec.ctxs.empty()
cvec.bufs.empty()
no_vocab
cannot find tokenizer merges in model file
unicode_cpts_from_utf8(word).size() > 0
rwkv
unknown tokenizer: '%s'
llama-v3
llama-bpe
deepseek-llm
deepseek-coder
gpt-2
phi-2
jina-es
jina-de
jina-v2-es
jina-v2-de
jina-v2-code
stablelm2
smaug-bpe
poro-chat
chatglm-bpe
viking
tekken
smollm
unknown pre-tokenizer type: '%s'
cannot find tokenizer vocab in model file
vocab.id_to_token.size() == vocab.token_to_id.size()
<PRE>
<SUF>
<MID>
<EOT>
<|fim_prefix|>
<|fim_suffix|>
<|fim_middle|>
<end_of_turn>
!ids.empty() && "model vocab missing newline token"
<|im_end|>
<|endoftext|>
<|eom_id|>
<mask>
phi-3
failed to create context
model has expert layers but no expert layers are used
Grok model cannot have zero experts
DBRX model cannot have zero experts
scales
n_expert > 0
2 * n_embd == d_inner
scale
E rkllm: wrong number of tensors, expected %d, got %d
%s: wrong number of tensors; expected %d, got %d
!mappings.empty()
unable to allocate backend CPU buffer
unable to allocate backend buffer
addr == NULL && size == 0
failed to allocate buffer
failed to load lora adapter file from 
adapter
expect general.type to be 'adapter', but got: 
model arch and LoRA arch mismatch
lora
expect adapter.type to be 'lora', but got: 
.lora_a
.lora_b
LoRA tensor '
' has unexpected suffix
LoRA tensor pair for '
' is missing one component
' does not exist in base model
tensor '
' has incorrect shape
lora_a tensor is not transposed (hint: adapter from "finetune" example is no longer supported)
failed to allocate buffer for lora adapter
hparams.n_expert <= LLAMA_MAX_EXPERTS
hparams.n_expert_used <= hparams.n_expert
hparams.n_expert_used > 0
hparams.n_expert_used == 0
W rkllm: the model version is too old, please use the latest toolkit to reconvert the model
E rkllm: An unsupported rope type was detected, please try upgrading the rkllm-runtime version.
An unsupported rope type was detected, please try upgrading the rkllm-runtime version.
invalid n_rot: %u, expected %u
invalid output file type %d
(qs.n_attention_wv == 0 || qs.n_attention_wv == (int)model.hparams.n_layer || qs.n_attention_wv == 3 * (int)model.hparams.n_layer) && "n_attention_wv is unexpected"
cur->data != nullptr
w.idx < files.size()
_norm.weight
output.weight
ffn_gate_inp.weight
ssm_conv1d.weight
ssm_x.weight
ssm_dt.weight
attn_rel_b.weight
imatrix size %d is different from tensor size %d for %s
Missing importance matrix for tensor %s in a very low-bit quantization
requantizing from type %s is disabled
quantized data validation failed
E rkllm: max_context[%d] must be less than the model's max_context_limit[%d]
E rkllm: the model's target_platform does not match the real platform
E rkllm: the model architecture %s is not supported by rkllm
I rkllm: rkllm-toolkit version: %s, max_context_limit: %d, npu_core_num: %d, target_platform: %s
E rkllm: The rkllm-runtime version is lower than the rkllm-toolkit version. Please update rkllm-runtime to %s or higher.
error loading model architecture: 
error loading model hyperparameters: 
error loading model vocabulary: 
<unk>
unexpectedly reached end of buffer
norm_w
write error: %s
read error: %s
unexpectedly reached end of file
*ZL24llama_build_graph_defragR13llama_contextRKSt6vectorIjSaIjEEEUlP11ggml_tensorPKciE_
*ZL25llama_build_graph_k_shiftR13llama_contextEUlP11ggml_tensorPKciE_
*ZL24llama_build_graph_s_copyR13llama_contextEUlP11ggml_tensorPKciE_
*ZL17llama_build_graphR13llama_contextRK11llama_batchbEUlP11ggml_tensorPKciE_
*NSt6thread11_State_implINS_8_InvokerISt5tupleIJZL32llama_tensor_dequantize_internalP11ggml_tensorRSt6vectorI7no_initIfESaIS7_EERS5_IS_SaIS_EEmiEUl9ggml_typePhPfiE_SE_SF_SG_mEEEEEE
*NSt6thread11_State_implINS_8_InvokerISt5tupleIJZL30llama_tensor_quantize_internal9ggml_typePKfPvlllS5_RSt6vectorIS_SaIS_EEiEUlvE_EEEEEE
std::future_error: 
failed to open %s: %s
seek error: %s
E rkllm: 32-bit systems only support models with weights smaller than 2GB
ftell error: %s
kv_self.size == n_ctx
K_shift
K_shifted
n_embd_head == hparams.n_embd_head_k
n_embd_head == hparams.n_rot
inp_s_copy
inp_s_mask
attn_norm
ffn_inp
ffn_norm
inp_out_ids
l_out
result_norm
result_output
inp_pos
KQ_mask
Qcur
Kcur
Vcur
ffn_out
ffn_moe_out
attn_norm_2
wqkv
attn_out_norm
ffn_moe_gelu
layer_out_norm
wqkv_clamped
pos_embd
inpL
bqkv
inp_norm
result_embd
inp_scaled
attn_q_norm
attn_k_norm
attn_post_norm
hidden_scaled
ffn_post_norm
hidden_scaled_ffn
lmhead_scaling
ffn_shexp_gate_inp
ffn_shexp_gate
ffn_shexp
ffn_shexp_out
result_output_no_bias
hparams.n_swa > 0
KQ_mask_swa
tmpq
tmpk
q_nope
q_pe
kv_pe_compresseed
kv_compressed
k_pe
k_nope
v_states
q_states
k_states
Qcur_scaled
sa_out
Qcur_normed
Kcur_normed
2 * d_model == d_inner
inp_s_seq
ffn_norm_exps
attn_sub_norm
attn_o_out
ffn_sub_out
ffn_sub_norm
pos_bucket
pos_bucket_1d
pos_bias
kq_b
n_outputs_enc > 0 && "call llama_encode() first"
embd_enc
KQ_mask_cross
cross_inp
attn_norm_cross
Qcur_rope
Kcur_rope
tensor '%s' data is not within the file bounds, model is corrupted or incomplete
mmap failed: %s
size_data != 0 && "call init_mappings() first"
buf_mmap || cur->data
addr
weight->idx < files.size()
malloc failed
tensor '%s' has invalid data
found tensors with invalid data
first % page_size == 0
last % page_size == 0
LLAMA_TRACE
%s: failed to load model from %s
illegal split file: %d, model must be loaded with the first split
invalid split file: %s
%s: failed to load GGUF split from %s
corrupted model: %d tensors expected but %d found
general.file_type
%s[%s,%d]
%s...
invalid model: tensor '%s' is duplicated
NSt13__future_base13_State_baseV2E
NSt13__future_base21_Async_state_commonV2E
16llama_data_write
15llama_data_read
22llama_data_write_dummy
23llama_data_write_buffer
22llama_data_read_buffer
21llama_data_write_file
20llama_data_read_file
NSt13__future_base7_ResultISt4pairIP11ggml_tensorbEEE
NSt13__future_base17_Async_state_implINSt6thread8_InvokerISt5tupleIJZN18llama_model_loader13load_all_dataEP12ggml_contextRSt13unordered_mapIjP19ggml_backend_bufferSt4hashIjESt8equal_toIjESaISt4pairIKjS9_EEEPSt6vectorISt10unique_ptrI11llama_mlockSt14default_deleteISM_EESaISP_EEPFbfPvEST_EUlvE_EEEESE_IP11ggml_tensorbEEE
NSt13__future_base15_Deferred_stateINSt6thread8_InvokerISt5tupleIJZN18llama_model_loader13load_all_dataEP12ggml_contextRSt13unordered_mapIjP19ggml_backend_bufferSt4hashIjESt8equal_toIjESaISt4pairIKjS9_EEEPSt6vectorISt10unique_ptrI11llama_mlockSt14default_deleteISM_EESaISP_EEPFbfPvEST_EUlvE_EEEESE_IP11ggml_tensorbEEE
St23_Sp_counted_ptr_inplaceINSt13__future_base17_Async_state_implINSt6thread8_InvokerISt5tupleIJZN18llama_model_loader13load_all_dataEP12ggml_contextRSt13unordered_mapIjP19ggml_backend_bufferSt4hashIjESt8equal_toIjESaISt4pairIKjSA_EEEPSt6vectorISt10unique_ptrI11llama_mlockSt14default_deleteISN_EESaISQ_EEPFbfPvESU_EUlvE_EEEESF_IP11ggml_tensorbEEESaIS13_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceINSt13__future_base15_Deferred_stateINSt6thread8_InvokerISt5tupleIJZN18llama_model_loader13load_all_dataEP12ggml_contextRSt13unordered_mapIjP19ggml_backend_bufferSt4hashIjESt8equal_toIjESaISt4pairIKjSA_EEEPSt6vectorISt10unique_ptrI11llama_mlockSt14default_deleteISN_EESaISQ_EEPFbfPvESU_EUlvE_EEEESF_IP11ggml_tensorbEEESaIS13_ELN9__gnu_cxx12_Lock_policyE2EE
NSt13__future_base12_Task_setterISt10unique_ptrINS_7_ResultISt4pairIP11ggml_tensorbEEENS_12_Result_base8_DeleterEENSt6thread8_InvokerISt5tupleIJZN18llama_model_loader13load_all_dataEP12ggml_contextRSt13unordered_mapIjP19ggml_backend_bufferSt4hashIjESt8equal_toIjESaIS3_IKjSJ_EEEPSt6vectorIS1_I11llama_mlockSt14default_deleteISU_EESaISX_EEPFbfPvES11_EUlvE_EEEES6_EE
NSt6thread11_State_implINS_8_InvokerISt5tupleIJZNSt13__future_base17_Async_state_implINS1_IS2_IJZN18llama_model_loader13load_all_dataEP12ggml_contextRSt13unordered_mapIjP19ggml_backend_bufferSt4hashIjESt8equal_toIjESaISt4pairIKjSA_EEEPSt6vectorISt10unique_ptrI11llama_mlockSt14default_deleteISN_EESaISQ_EEPFbfPvESU_EUlvE_EEEESF_IP11ggml_tensorbEEC4EOSZ_EUlvE_EEEEEE
MbP?
%02x
_offset >= 0
offset + length <= raw_text.length()
token_left.find(' ') == std::string::npos
token_left.find('\n') == std::string::npos
token_right.find(' ') == std::string::npos
token_right.find('\n') == std::string::npos
vocab.type != LLAMA_VOCAB_TYPE_NONE
llama_vocab_get_type(vocab) != LLAMA_VOCAB_TYPE_NONE
llama_is_byte_token(vocab, id)
[UNK_BYTE_0x
avail >= 0
_length >= 1
vocab.special_bos_id != -1
vocab.special_eos_id != -1
vocab.special_cls_id != -1
vocab.special_sep_id != -1
Index out of array bounds in XCDA array!
Index out of array bounds in precompiled charsmap!
vocab.type == LLAMA_VOCAB_TYPE_BPE
(?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])|[^\r\n\p{L}\p{N}]?\p{L}+|\p{N}{1,3}| ?[^\s\p{L}\p{N}]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+
\s?[A-Za-z
\s?[!-/:-~
\p{N}+
\s?\p{L}+
\s?\p{P}+
\p{N}
[\p{P}\$\+<=>\^~\|`]+
's|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)
[0-9][0-9][0-9]
(?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])|[^\r\n\p{L}\p{N}]?\p{L}+|\p{N}| ?[^\s\p{L}\p{N}]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+
 ?[^(\s|.,!?
[^\r\n\p{L}\p{N}]?((?=[\p{L}])([^a-z]))*((?=[\p{L}])([^A-Z]))+|[^\r\n\p{L}\p{N}]?((?=[\p{L}])([^a-z]))+((?=[\p{L}])([^A-Z]))*|\p{N}| ?[^\s\p{L}\p{N}]+[\r\n/]*|\s*[\r\n]+|\s+(?!\S)|\s+
[\p{P}\$\+<=>\^~\|]+
is_positive_char || pos->type == LLAMA_GRETYPE_CHAR_NOT
!grammar->stacks.empty()
!stacks.empty()
vocab
candidates->size > 0
smpl
invalid character
failed to convert utf8 to codepoint
invalid codepoint
\p{L}
\p{P}
A-Za-z
!-#%-*,-/:-;?-@\[-\]_\{\}
(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\r\n\p{L}\p{N}]?\p{L}+|\p{N}{1,3}| ?[^\s\p{L}\p{N}]+[\r\n]*|\s*[\r\n]+|\s+(?!\S)|\s+
Regex includes both unicode categories and non-ASCII characters - not supported
Failed to process regex: '%s'
Regex error: %s
Failed to process regex
St12codecvt_utf8IwLm1114111ELSt12codecvt_mode0EE
St23_Sp_counted_ptr_inplaceINSt8__detail4_NFAINSt7__cxx1112regex_traitsIwEEEESaIS5_ELN9__gnu_cxx12_Lock_policyE2EE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb0ELb0ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb0ELb0ELb1EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb0ELb1ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb0ELb1ELb1EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb1ELb0ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb1ELb0ELb1EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb1ELb1ELb0EEE
NSt8__detail11_AnyMatcherINSt7__cxx1112regex_traitsIwEELb1ELb1ELb1EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIwEELb0ELb0EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIwEELb0ELb1EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIwEELb1ELb0EEE
NSt8__detail12_CharMatcherINSt7__cxx1112regex_traitsIwEELb1ELb1EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIwEELb0ELb0EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIwEELb0ELb1EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIwEELb1ELb0EEE
NSt8__detail15_BracketMatcherINSt7__cxx1112regex_traitsIwEELb1ELb1EEE
""//\\a
%s:%d: 
attach %d
set style enabled on
--batch
quit
detach
bt -frame-info source-and-location
lldb
%s: not enough space in the context's memory pool (needed %zu, available %zu)
((uintptr_t) (mem_buffer + obj_new->offs))%GGML_MEM_ALIGN == 0
tensor != NULL
sect_dims <= ne0
src0->type == GGML_TYPE_F16
src1->type == GGML_TYPE_F32
nb00 == sizeof(ggml_fp16_t)
nb10 == sizeof(float)
0 <= type && type < GGUF_TYPE_COUNT
ggml_are_same_shape(a, b)
ggml_is_contiguous_1(a)
invalid type
offset == info->offset
C % HEADS == 0
GGML status: unknown
GGML status: error (failed to allocate memory)
GGML status: error (operation failed)
GGML status: success
GGML status: warning (operation aborted)
%s type: %d shape: %ld %ld %ld %ld
type < GGML_TYPE_COUNT
ggml_numa_init: NUMA already initialized
/sys/devices/system/node/node%u
/sys/devices/system/cpu/cpu%u
/sys/devices/system/node/node%u/cpu%u
/proc/sys/kernel/numa_balancing
WARNING: /proc/sys/kernel/numa_balancing is enabled, this has been observed to impair performance
 - ggml_object: type = %d, offset = %zu, size = %zu, next = %p
%s: objects in context %p:
%s: --- end ---
ggml_nelements(src1) + ggml_nelements(src0) == ggml_nelements(dst)
src0->nb[0] == sizeof(float)
src1->nb[0] == sizeof(float)
src2->nb[0] == sizeof(float)
src3->nb[0] == sizeof(float)
src4->nb[0] == sizeof(float)
src5->nb[0] == sizeof(float)
src0->nb[1] == src0->ne[0]*sizeof(float)
src0->nb[2] == src0->ne[0]*src0->ne[1]*sizeof(float)
src1->nb[2] == src1->ne[0]*src1->ne[1]*sizeof(float)
0 <= sq[0] && sq[0] < n_kv
(nr*n_t) + (nc*nr*n_kv) == ggml_nelements(dst)
src3->nb[0] == sizeof(int32_t)
src2->nb[2] == src2->ne[1]*src2->ne[0]*sizeof(float)
nb0 == sizeof(float)
nb00 == sizeof(float)
/%d-
/%04d-npu_matmul-
/%04d-cpu_matmul-
/%04d-add-
/%04d-mul-
/%04d-norm-
/%04d-rmsnorm-
/%04d-d%d-
/%04d-
%s-%s
attn_%s
attn_residual%s
ffn_residual%s
src type %d do not support
Failed to open file: %s
buffersize %d read from binary file: %s
dst->type == GGML_TYPE_F32
ne02 == ne12
ne03 == ne13
ne2 == ne12
ne3 == ne13
nb00 == ggml_type_size(type)
ne0 == ne00
ne1 == ne10
ne2 == ne02
ne0 == D
ne2 == N
nbq0 == ggml_type_size(q->type)
nbk0 == ggml_type_size(k->type)
nbv0 == ggml_type_size(v->type)
nek0 == D
nev0 == D
nb0 <= nb1
nb1 <= nb2
nb2 <= nb3
P >= 0
nbq0 == sizeof(float)
nbk0 == sizeof(float)
nbv0 == sizeof(float)
nev1 == D
ned0 == D
ned1 == N
ggml_blck_size(result_type) == 1
view_src == NULL || data_size == 0 || data_size + view_offs <= ggml_nbytes(view_src)
%s: not enough space in the scratch memory pool (needed %zu, available %zu)
wtype != GGML_TYPE_COUNT
ggml_nelements(dst) == ggml_nelements(src0)
ggml_is_contiguous(dst) && ggml_is_contiguous(src0)
src0->type == dst->type
ne0 == ne01
ne1 == ne11
nb10 == ggml_type_size(src1->type)
n_past >= 0
dst->nb[0] == sizeof(float)
ggml_is_contiguous(dst)
dst->ne[0] == nc
src0->nb[0] == sizeof(ggml_fp16_t)
ggml_are_same_shape(src0, dst)
ggml_is_scalar(src1)
src1->type == GGML_TYPE_F16
dst->type == GGML_TYPE_F16
nb0 == sizeof(ggml_fp16_t)
src0->type == GGML_TYPE_BF16
src1->type == GGML_TYPE_BF16
dst->type == GGML_TYPE_BF16
nb0 == sizeof(ggml_bf16_t)
nb00 == sizeof(ggml_bf16_t)
ggml_is_quantized(src0->type)
dst->type == src0->type
offset + (ne10 == 0 ? 0 : ne10-1)*nb0 + (ne11 == 0 ? 0 : ne11-1)*nb1 + (ne12 == 0 ? 0 : ne12-1)*nb2 + (ne13 == 0 ? 0 : ne13-1)*nb3 < ggml_nbytes(dst)
offset + (ne10 == 0 ? 0 : ne10-1)*nb00 + (ne11 == 0 ? 0 : ne11-1)*nb01 + (ne12 == 0 ? 0 : ne12-1)*nb02 + (ne13 == 0 ? 0 : ne13-1)*nb03 < ggml_nbytes(src0)
ggml_are_same_shape(src0, dst) && ggml_are_same_shape(src0, src1)
offset + im0*nb0 + im1*nb1 + im2*nb2 + im3*nb3 <= ggml_nbytes(dst)
ggml_is_contiguous(src0)
ggml_is_contiguous(src1)
ggml_are_same_shape(src1, dst)
ggml_is_scalar(dst)
ggml_are_same_shape(src0, src1)
params->wsize >= sizeof(float) * (nth + nth * nc)
ggml_is_contiguous(opt0)
ggml_are_same_shape(src0, src1) && ggml_are_same_shape(src0, dst)
ggml_can_repeat(src1, src0) && ggml_are_same_shape(src0, dst)
src1->type == GGML_TYPE_F32 && "only f32 src1 supported for now"
ggml_can_repeat(dst, src0)
ggml_can_repeat(src0, dst)
insufficient memory
unknown allocation error
invalid alignment value
WARNING: Behavior may be unexpected when allocating 0 bytes for ggml_aligned_malloc!
%s: %s (attempted to allocate %6.2f MB)
ctx->mem_buffer != NULL
((uintptr_t) (ctx->mem_buffer))%GGML_MEM_ALIGN == 0
ggml_can_repeat(b, a)
tensor->nb[0] == sizeof(int8_t)
tensor->nb[0] == sizeof(int16_t)
tensor->nb[0] == sizeof(int32_t)
tensor->nb[0] == sizeof(ggml_fp16_t)
tensor->nb[0] == sizeof(ggml_bf16_t)
tensor->nb[0] == sizeof(float)
tensor->op == GGML_OP_UNARY
i != GGML_HASHSET_FULL
replacements->set.keys[i] == NULL
%s (clone)
cgraph->n_leafs < cgraph->size
leaf_%d
cgraph->n_nodes < cgraph->size
node_%d
%s (view)
ggml_nelements(b) <= ggml_nelements(a)
ggml_is_contiguous(a)
a->type == GGML_TYPE_F32
b->type == GGML_TYPE_F32
ggml_is_quantized(a->type) || a->type == GGML_TYPE_F16 || a->type == GGML_TYPE_BF16
ggml_can_repeat_rows(b, a)
ggml_is_scalar(b)
ggml_is_padded_1d(a)
ggml_is_matrix(a)
ggml_can_repeat(a, b)
dim >= 0 && dim < GGML_MAX_DIMS
a->ne[d] == b->ne[d]
ggml_is_contiguous(r)
ggml_is_contiguous(w)
ggml_is_contiguous(k)
ggml_is_contiguous(v)
ggml_is_contiguous(b)
ggml_is_contiguous(state)
w->ne[0] == S && w->ne[1] == H && w->ne[2] == n_tokens
v->ne[0] == S && v->ne[1] == H && v->ne[2] == n_tokens
a->ne[0] == S && a->ne[1] == H && a->ne[2] == n_tokens
b->ne[0] == S && b->ne[1] == H && b->ne[2] == n_tokens
ggml_nelements(state) == S * S * H * n_seqs
!ggml_is_transposed(a)
ggml_can_mul_mat(a, b)
a->op == GGML_OP_MUL_MAT
!ggml_is_transposed(as)
ids->type == GGML_TYPE_I32
as->ne[3] == 1
b->ne[3] == 1
ids->ne[2] == 1 && ids->ne[3] == 1
ids->ne[1] == b->ne[2]
as->ne[0] == b->ne[0]
ids->ne[0] % b->ne[1] == 0
ggml_can_out_prod(a, b)
ggml_nelements(a) >= ggml_nelements(b)
ggml_nelements(a) == ggml_nelements(b)
%s (copy of %s)
%s (copy)
%s (cont)
ggml_nelements(a) == (ne0*ne1*ne2*ne3)
%s (reshaped)
ggml_nelements(a) == ne0
ggml_nelements(a) == ne0*ne1
ggml_nelements(a) == ne0*ne1*ne2
ggml_nelements(a) == ne0*ne1*ne2*ne3
axis0 >= 0 && axis0 < GGML_MAX_DIMS
axis1 >= 0 && axis1 < GGML_MAX_DIMS
axis2 >= 0 && axis2 < GGML_MAX_DIMS
axis3 >= 0 && axis3 < GGML_MAX_DIMS
axis0 != axis1
axis0 != axis2
axis0 != axis3
axis1 != axis2
axis1 != axis3
axis2 != axis3
%s (permuted)
%s (transposed)
a->ne[2] == b->ne[1]
b->type == GGML_TYPE_I32
ggml_is_matrix(a) && ggml_is_vector(b) && b->type == GGML_TYPE_I32
ggml_is_matrix(c) && (a->ne[0] == c->ne[0])
a->ne[1] == 1
mask->type == GGML_TYPE_F16 || mask->type == GGML_TYPE_F32
ggml_is_contiguous(mask)
ggml_is_matrix(mask)
mask->ne[0] == a->ne[0]
mask->ne[1] >= a->ne[1]
mask
(mode & 1) == 0 && "mode & 1 == 1 is no longer supported"
ggml_is_vector(b)
a->ne[2] == b->ne[0]
a->ne[2] * 4 == b->ne[0]
c->type == GGML_TYPE_F32
c->ne[0] >= n_dims / 2
c == NULL && "freq factors not implemented yet"
(mode & 4) == 0 && "ggml_rope_back() for ChatGLM not implemented yet"
ggml_is_matrix(b)
a->ne[3] == 1
p0 == 0
d0 == 1
a->ne[2] == b->ne[2]
a->ne[1] == b->ne[1]
a->ne[3] == b->ne[2]
a->ne[0] <= ne0
a->ne[1] <= ne1
a->ne[2] <= ne2
a->ne[3] <= ne3
stop > start
a->ne[0] >= k
mask->ne[2] == 1
mask->ne[3] == 1
mask->ne[1] >= GGML_PAD(q->ne[1], GGML_KQ_MASK_PAD) && "the Flash-Attention kernel requires the mask to be padded to GGML_KQ_MASK_PAD and at least n_queries big"
ggml_can_mul_mat(k, q)
a->op == GGML_OP_FLASH_ATTN_EXT
TODO: adapt to ggml_flash_attn_ext() changes
ggml_is_3d(s)
ggml_is_matrix(x)
ggml_is_matrix(c)
ggml_is_matrix(sq)
sq->type == GGML_TYPE_I32
s->ne[0] == d_conv - 1
s->ne[1] == d_inner
x->ne[0] == d_inner
sq->ne[0] == n_kv
sq->ne[1] == n_tokens
ggml_is_contiguous(s)
ggml_is_contiguous(x)
ggml_is_contiguous(dt)
ggml_is_contiguous(A)
B->nb[0] == ggml_type_size(B->type)
C->nb[0] == ggml_type_size(C->type)
ggml_are_same_shape(x, dt)
A->ne[0] == d_state
A->ne[1] == d_inner
B->ne[0] == d_state
B->ne[1] == n_tokens
C->ne[0] == d_state
C->ne[1] == n_tokens
qh == kh
2*MAX(qh, kh) - 1 == a->ne[1]
ggml_are_same_shape(pw, ph)
ggml_is_contiguous(pw)
ggml_is_contiguous(ph)
ph->type == GGML_TYPE_F32
pw->type == GGML_TYPE_F32
pw->ne[3] == a->ne[2]
pw->ne[0]*pw->ne[0] == a->ne[0]
pw->ne[1]*pw->ne[2] == a->ne[1]
n_tasks == GGML_N_TASKS_MAX || n_tasks > 0
ggml_is_scalar(c)
tensor->grad == NULL
%s (grad)
n_dims <= ne0
n_dims % 2 == 0
sections[0] > 0 || sections[1] > 0 || sections[2] > 0
n_dims == ne0/2
src2->type == GGML_TYPE_F32
src2->ne[0] >= n_dims / 2
ne0 == 1
ne1 == ne01
ne3 == ne03
dim >= 0 && dim < 4
eps > 0.0f
ne00 == ne0
ne00 == ne1
ne01 == 1
ne02 == ne2
ne03 == ne3
k0 == s0
ggml_nelements(dst) == steps
t == 0 || t == 1
eps >= 0.0f
error: set affinity failed 
warning: pthread_setaffinity_np() failed: %s
WARNING: Behavior may be unexpected when allocating 0 bytes for ggml_malloc!
%s: failed to allocate %6.2f MB
WARNING: Behavior may be unexpected when allocating 0 bytes for ggml_calloc!
cgraph->nodes[cgraph->n_nodes - 1] == tensor
gf->n_nodes > 0
src0->type == tensor->type
tensor->grad->type == tensor->type
tensor->grad->type == src1->grad->type
ggml_is_contiguous(src0->grad)
ggml_is_contiguous(tensor->grad)
offset % n0 == 0
nb1 % n0 == 0
nb2 % n0 == 0
nb3 % n0 == 0
ggml_are_same_shape(tensor->src[i], tensor->src[i]->grad)
dst->size >= src->n_leafs
dst->size >= src->n_nodes
dst->visited_hash_set.size >= src->visited_hash_set.size
dst->grads != NULL
k != GGML_HASHSET_FULL
replacements->set.keys[k] == NULL
cgraph->grads != NULL
%s: op not implemented: 
node->src[0]->ne[3] == 1
node->src[1]->ne[2] == 1
node->src[1]->ne[3] == 1
cplan
cplan->n_threads > 0
cplan->work_size == 0 || cplan->work_data != NULL
magic
%-16s %8x
%-16s %8d
leafs
nodes
eval
%-16s %lu
NDIMS
TYPE
%-6s %-12s %8s %8s %8s %8s %8s %16s %16s %16s %16s %16s %16s
DATA
%-6s %-6s %-12s %8s %8s %8s %8s %8s %16s %16s %16s %16s %8s %16s %16s
NTASKS
%-6s %-12s %8d %ld %ld %ld %ld %16zu %16zu %16zu %16zu %16p %32s
cgraph->leafs[i]->op == GGML_OP_NONE
cgraph->leafs[i]->src[0] == NULL
cgraph->leafs[i]->src[1] == NULL
%-6s %-6s %-12s %8d %ld %ld %ld %ld %16zu %16zu %16zu %16zu %16p %32s
%s: failed to open %s: %s
%s: failed to find tensor, arg = %d, node = %d
%s: failed to create ggml context
%s: failed to read %s
E rkllm: invalid magic number, got %08x
E rkllm: invalid version number
%s: loaded leaf %u: '%16s', %9zu bytes
%s: loaded node %u: '%16s', %9zu bytes
=== GRAPH ===
n_nodes = %d
 - %3d: [ %5ld, %5ld, %5ld] %16s %s
n_leafs = %d
 - %3d: [ %5ld, %5ld] %8s %16s
========================================
dashed
solid
digraph G {
  newrank = true;
  rankdir = TB;
yellow
green
white
  "%p" [ style = filled; fillcolor = %s; shape = record; label="
%s (%s)|
(%s)|
%d [%ld, %ld] | <x>%s
%d [%ld, %ld, %ld] | <x>%s
 | <g>%s"; ]
pink
  "%p" [ style = filled; fillcolor = %s; shape = record; label="<x>
CONST %d [%ld, %ld]
 | (
%.1e
src %d
  "%p":%s -> "%p":%s [ arrowhead = %s; style = %s; label = "%s"; ]
%s: dot -Tpng %s -o %s.png && open %s.png
  "%p":%s -> "%p":%s [ label = "%s"; ]
lightblue
ggml_is_scalar(f)
np < GGML_MAX_PARAMS
opt-forward.dot
opt-backward.dot
imatrix != NULL
start % type_traits[type].blck_size == 0
start % n_per_row == 0
result == nrows * row_size
%s: invalid string length (%lu)
key_id >= 0 && key_id < gguf_get_n_kv(ctx)
ctx->kv[key_id].type == GGUF_TYPE_ARRAY
ctx->kv[key_id].type == GGUF_TYPE_UINT8
ctx->kv[key_id].type == GGUF_TYPE_INT8
ctx->kv[key_id].type == GGUF_TYPE_UINT16
ctx->kv[key_id].type == GGUF_TYPE_INT16
ctx->kv[key_id].type == GGUF_TYPE_UINT32
I rkllm: loading rkllm model from %s
E rkllm: failed to open '%s': '%s'
E rkllm: invalid rkllm model!
%s: GGUFv1 is no longer supported. please use a more up-to-date version
%s: array size is too large (%lu)
info->n_dims <= GGML_MAX_DIMS
0 <= info->type && info->type < GGML_TYPE_COUNT
info->ne[i] > 0
INT64_MAX/info->ne[1] > info->ne[0]
INT64_MAX/info->ne[2] > info->ne[0]*info->ne[1]
INT64_MAX/info->ne[3] > info->ne[0]*info->ne[1]*info->ne[2]
E rkllm: duplicated tensor name %s
E rkllm: failed to read tensor info
%s: tensor '%s' of type %d (%s) number of elements (%ld) is not a multiple of block size (%ld)
E rkllm: failed to initialize context
E rkllm: failed to read the tensor data
E rkllm: failed to read tensor data
E rkllm: failed to read key-value pairs
E rkllm: failed to read header
ctx->kv[key_id].type == GGUF_TYPE_INT32
ctx->kv[key_id].type == GGUF_TYPE_FLOAT32
ctx->kv[key_id].type == GGUF_TYPE_UINT64
ctx->kv[key_id].type == GGUF_TYPE_INT64
ctx->kv[key_id].type == GGUF_TYPE_FLOAT64
ctx->kv[key_id].type == GGUF_TYPE_BOOL
ctx->kv[key_id].type == GGUF_TYPE_STRING
ctx->kv[key_id].type != GGUF_TYPE_ARRAY
ctx->kv[key_id].type != GGUF_TYPE_STRING
nested arrays not supported
duplicated tensor name
tensor not found
failed to open file for writing
bool
STEP
Tanh
ReLU
Sigmoid
GELU
GELU_QUICK
SiLU
Hardswish
HardSigmoid
view(x,nb,offset)+=y->x
log(x)
argmax(x)
repeat(x)
repeat_back(x)
concat(x, y)
silu_back(x)
norm(x)
rms_norm(x)
rms_norm_back(x)
group_norm(x)
X[i]*Y
y-\>view(x)
x-\>y
cont(x)
reshape(x)
view(x)
permute(x)
transpose(x)
get_rows(x)
get_rows_back(x)
diag(x)
diag_mask_inf(x)
diag_mask_zero(x)
soft_max(x)
soft_max_back(x)
rope(x)
rope_back(x)
clamp(x)
conv_transpose_1d(x)
im2col(x)
conv_transpose_2d(x)
pool_1d(x)
pool_2d(x)
upscale(x)
pad(x)
arange(start, stop, step)
timestep_embedding(timesteps, dim, max_period)
argsort(x)
leaky_relu(x)
flash_attn_ext(x)
flash_attn_back(x)
ssm_conv(x)
ssm_scan(x)
win_part(x)
win_unpart(x)
get_rel_pos(x)
add_rel_pos(x)
unary(x)
f(x)
f(x,y)
custom_f32(x)
custom_f32(x,y)
custom_f32(x,y,z)
custom(x)
custom(x,y)
custom(x,y,z)
cross_entropy_loss(x,y)
cross_entropy_loss_back(x,y)
Add1
Sqrt
SUM_Rows
Mean
Argmax
Repeat
Repeat_BACK
Concat
SiLU_BACK
Norm
RMSNorm
RMS_NORM_BACK
GroupNorm
MatMul
MatMul_ID
Out_Prod
Scale
Copy
Cont
Reshape
View
Permute
Transpose
GetRows
GET_ROWS_BACK
Diag
DIAG_MASK_INF
DIAG_MASK_ZERO
Softmax
SOFT_MAX_BACK
Rope
ROPE_BACK
Clamp
Conv_Transpose_1D
IM2COL
Conv_Transpose_2D
Pool_1D
Pool_2D
Upscale
Arange
TIMESTEP_EMBEDDING
Argsort
Leaky_ReLU
Flash_Attn_EXT
Flash_Attn_BACK
SSM_CONV
SSM_SCAN
WIN_PART
WIN_UNPART
GET_REL_POS
ADD_REL_POS
UNARY
MAP_UNARY
MAP_BINARY
MAP_CUSTOM1_F32
MAP_CUSTOM2_F32
MAP_CUSTOM3_F32
MAP_CUSTOM1
MAP_CUSTOM2
MAP_CUSTOM3
CROSS_ENTROPY_LOSS
CROSS_ENTROPY_LOSS_BACK
DEPRECATED
q8_1
q2_K
q3_K
q4_K
q5_K
q6_K
q8_K
iq2_xxs
iq2_xs
iq3_xxs
iq1_s
iq3_s
iq2_s
iq4_xs
iq1_m
bf16
q4_0_4x4
q4_0_4x8
q4_0_8x8
W8A8_C_0_0
W8A8_C_0_1
W8A8_C_1_0
W8A8_C_1_1
W4A16_C_0_0
W4A16_C_1_0
W4A16_G64_0_0
W4A16_G128_0_0
W8A8_G128_0_0
W8A8_G256_0_0
W8A8_G512_0_0
W4A16_G32_0_0
W4A8_G32_0_0
,*(&
	{	u	
ggml_new_object
ggml_print_objects
ggml_new_tensor_impl
ggml_aligned_malloc
ggml_malloc
ggml_calloc
ggml_get_n_tasks
ggml_graph_export
ggml_graph_import
ggml_graph_dump_dot
gguf_fread_str
ofbwKi
8'+c
gguf_init_from_file
@C_p
?alloc->n_free_blocks < MAX_FREE_BLOCKS && "out of free blocks"
%s: not enough space in the buffer to allocate %zu bytes, largest block available %zu bytes
not enough space in the buffer
%s: not enough space in the buffer to allocate %s (needed %zu, available %zu)
galloc != NULL
galloc->bufts != NULL
galloc->buffers != NULL
galloc->buf_tallocs != NULL
galloc->hash_set.keys != NULL
galloc->hash_values != NULL
galloc->node_allocs != NULL
galloc->leaf_allocs != NULL
%s: failed to allocate %s buffer of size %zu
buffer_id >= 0 && buffer_id < galloc->n_buffers
ggml_get_no_alloc(ctx) == true
%s: tensor %s is too large to fit in a %s buffer (tensor size: %zu, max buffer size: %zu)
ggml_dyn_tallocr_alloc
ggml_tallocr_alloc
ggml_gallocr_reserve_n
ggml_backend_alloc_ctx_tensors_from_buft
src != NULL
src->data && "graph must be allocated"
%s: failed to allocate buffer of size %zu
base != NULL && "backend buffer base cannot be NULL"
buf != NULL && "tensor buffer not set"
tensor->data != NULL && "tensor not allocated"
offset + size <= ggml_nbytes(tensor) && "tensor write out of bounds"
offset + size <= ggml_nbytes(tensor) && "tensor read out of bounds"
backend->iface.graph_plan_create != NULL
backend->iface.graph_plan_free != NULL
backend->iface.graph_plan_compute != NULL
ggml_are_same_layout(src, dst) && "cannot copy tensors with different layouts"
event->backend->iface.event_record != NULL
event->backend->iface.event_synchronize != NULL
backend->iface.event_wait != NULL
ggml_backend_registry_count < GGML_REG_MAX_BACKENDS
i < ggml_backend_registry_count
%.*s
%s: backend %s not found
ggml_backend_is_cpu(backend_cpu)
(uintptr_t)ptr % TENSOR_ALIGNMENT == 0 && "buffer pointer must be aligned"
ctx->buffers != NULL
ggml_backend_buffer_is_multi_buffer(buffer)
n_backends > 0
n_backends <= GGML_SCHED_MAX_BACKENDS
ggml_backend_is_cpu(backends[n_backends - 1])
GGML_SCHED_DEBUG
ggml_backend_supports_buft(backends[b], sched->bufts[b])
i >= 0 && i < sched->n_backends
backend_index >= 0 && backend_index < sched->n_backends
sched->splits != NULL
i_split < GGML_SCHED_MAX_SPLITS
%s#%s#%d
n_graph_inputs < GGML_SCHED_MAX_SPLIT_INPUTS
n_inputs < GGML_SCHED_MAX_SPLIT_INPUTS
## SPLIT #%d: %s # %d inputs: 
%zuM
[%s (%5.5s)] 
%zuK
node #%3d (%10.10s): %20.20s (%5.5s) [%5.5s %8.8s]:
 %20.20s (%5.5s) [%5.5s %8.8s]
sched->graph.nodes != NULL
sched->graph.leafs != NULL
(int)sched->hash_set.size >= graph->n_nodes + graph->n_leafs
%s: failed to initialize context
%s: failed to allocate graph
(int)sched->hash_set.size >= measure_graph->n_nodes + measure_graph->n_leafs
tensor->buffer == NULL
tensor->view_src != NULL
tensor->view_src->buffer != NULL
tensor->view_src->data != NULL
tensor->data == NULL
tensor->view_src == NULL
addr >= ggml_backend_buffer_get_base(buffer)
(char *)addr + ggml_backend_buffer_get_alloc_size(buffer, tensor) <= (char *)ggml_backend_buffer_get_base(buffer) + ggml_backend_buffer_get_size(buffer)
failed to allocate context for graph copy
failed to allocate buffer for graph copy
ggml_backend_cpu_buffer_type_alloc_buffer
ggml_backend_reg_init_backend_from_str
ggml_backend_sched_split_graph
ggml_backend_sched_alloc_splits
num_neighbors > 0
grid_index >= 0
quant_weights && "missing quantization weights"
kmap_q2xs && "forgot to call ggml_quantize_init()?"
kgrid_q2xs && "forgot to call ggml_quantize_init()?"
kneighbors_q2xs && "forgot to call ggml_quantize_init()?"
n%QK_K == 0
Oops: found point %u not on grid:
scale >= 0
type == GGML_TYPE_IQ2_XXS || type == GGML_TYPE_IQ2_XS || type == GGML_TYPE_IQ1_S || type == GGML_TYPE_IQ1_M || type == GGML_TYPE_IQ2_S
grid_size == 256 || grid_size == 512
n_per_row%QK_K == 0
Oops, did not find grid point
Have %d neighbours
    neighbour %d: sumqx = %g sumq2 = %g
kgrid_q3xs && "forgot to call ggml_quantize_init()?"
kmap_q3xs && "forgot to call ggml_quantize_init()?"
kneighbors_q3xs && "forgot to call ggml_quantize_init()?"
quant_weights
besti1 >= 0 && besti2 >= 0 && best_shift != 0
besti1 >= 0 && besti2 >= 0 && best_k >= 0
n_per_row%QK4_NL == 0
k%QK4_NL == 0
%s: invalid type %d
%s: invalid size %zu for type %s (type size = %zu)
%s: found %d NaNs in row of %zu BF16 values
%s: found %d infinities in row of %zu BF16 values
ggml_validate_row_data: found inf value at block %zu
ggml_validate_row_data: found nan value at block %zu
&5EYq
,$$$4$$,
>,$,
,4,$
$>,$
4$$$4,
 D a 
 )!H!
$@$V$
%A%d%
@!@$@@@H@V@`@
A AaA
BHBVBhB
H@HEH
IXIaI
XdX@Y
`@`h`
   A D P 
!@!H!e!
$)$@$
%A%R%
( (U(
@!@$@@@B@E@H@J@Q@T@`@e@
A AAADAPA
B)B@B
D DADDDPD
E$E@E
FDFPF
H@HEHTHbH
IDIPIiI
P P(PAPDPPP
Q@QBQ
T!T@T`T
U!VhV
XAXPX
Y@YBY
`@`T`b`
a$bJb
e@eEe
hjh%i
jTjbj
	!	@	E	H	Q	T	`	
   % * A D P R U d 
!!!@!B!E!Q!T!`!
"""("*"D"P"
$!$$$@$B$E$H$Q$T$`$
% %A%D%P%f%
&@&Y&
(A(D(P(
*"*d*
@!@$@&@@@B@E@H@J@Q@T@V@Y@`@b@e@
A A"A%AAADAFAIAPARAUAXAaAdA
B$B@BEBHBQBTB`B
D D"D%D(DADDDFDIDPDRDUDXDaDdD
E!E$E@EBEEEHEQETE`EjE
F FAFDFPF
H!H$H@HBHEHHHQHTH`H
I IAIDIPI
P P"P%P(PAPDPFPIPPPRPUPXPaPdP
Q!Q$Q@QBQEQHQQQTQ`Q
R RARDRPRiR
T!T$T@TBTETHTQTTT`T
U UAUDUPU
V&V@V
X XAXDXPXZX
`!`$`@`E`H`Q`T```
a aAaDaPa
b@bVb
d dAdDdPd
e@eJehe
i*iBj
	)	4	U	c	x	
	 	9	E	G	Q	r	
ggml_validate_row_data
	$	%	A	P	Q	U	a	d	i	
   " % ( * E Q Y a e 
!%!B!D!I!U!X!Z!a!d!e!f!
" """("*"E"Q"V"Y"e"
$%$D$E$F$I$R$U$X$Z$f$
%!%)%@%E%H%Q%T%U%Y%b%e%h%
&%&A&I&U&`&a&i&
( ("(((*(E(Q(T(e(
)%)F)I)R)U)a)d)f)i)
* *"*(***E*Q*V*Y*e*
@%@I@R@U@X@Z@a@d@f@
A!A&A)AEAHAJAQATAUAVAYAZAeAhAjA
B%BABRBUBZBdBiB
D)DEDHDJDQDTDUDVDaDbDeDhDjD
E E%E*EAEDEEEFEIEPEQETEUEVEXEYEaEdEeEfEiE
F!F$F)F@FBFEFHFPFQFRFUFVFYFbFeFhF
H%HBHIHPHUHXHaHdHfHiH
I!I$I&I@IEIJIQIRITIUIVIYI`IbIeIfIjI
JDJFJIJUJXJZJdJiJ
P!P$P)P@PEPHPQPTPUPVPYPePhP
Q Q%Q&Q(Q*QAQDQEQFQIQPQQQRQTQUQVQXQYQZQaQdQeQfQiQ
R!R$RBRERJRQRTRURVRYRbReR
T!T%T(T*TATDTETFTITJTPTQTTTUTVTXTYTZTaTbTdTeTfTiT
U!U$U%U&U)U@UAUBUDUEUFUHUIUPUQURUTUUUVUXUYUZU`UaUdUeUfUhUiUjU
V V!V"V$V%V&V(V)VAVEVFVHVIVJVPVQVRVTVUVVVXVYVZVaVdVeViV
X!X*XEXHXJXQXTXUXVXXXYX`XbXdXeX
Y%YAYDYEYFYIYPYQYRYTYUYVYXYYYZYaYdYeYfYiY
Z Z%Z&Z)ZEZHZIZQZUZVZXZYZbZeZhZjZ
`%`D`P`U`V`X`Z`a`d`f`i`
a!a"a&a)aEaIaQaUaVaYaeafaja
b@bAbFbUbVbXb`b
d!d&d)d@dBdEdHdJdQdTdUdVdYdZd`dbded
eDeEeFeIePeQeTeUeVeYeaedeeefeie
f f&f(f)f@fEfHfJfQfTfUfVfXfZf`fefhf
h%hAhRhUhZhahih
i!i$i&i)i@iAiEiFiHiQiTiUiViYi`ieiji
jAjDjIjPjUjXjZjdjejij
++++
++++
+++++
++++
++++
++++
++++
++++
+++++
+++++
++++
++++
+++++
++++++
++++
+++++
++++
++++
++++
++++
++++
++++++
++++
+++++
++++
++++
+++++++++++++
++++
++++
+++++
++++
++++
++++
++++
+++++
++++
+++++
++++
++++
+++++
++++
+++++
+++++
++++
++++
++++
+++++++
++++
+++++++++++++w
@K8z
(ggml_cpu_has_sve() || ggml_cpu_has_matmul_int8()) && "__ARM_FEATURE_SVE and __ARM_FEATURE_MATMUL_INT8 not defined, use the Q4_0_4_4 quantization format for optimal " "performance"
MAX_NPU_CORE >= used_npu_core && used_npu_core > 0
kq_soft_max
matmul_qkv_rkllm_spilt_%d
matmul_qkv
matmul_qk_rkllm_spilt_%d
matmul_qk
E rkllm: 2features matmul run failed
E rkllm: overflow detected at input
%s_rkllm_spilt_%d
E rkllm: rkllm_query_shape failed
E rkllm: matmul(fp16) run failed
E rkllm: set quant params failed(w8a8)
E rkllm: matmul(w8a8) run failed
E rkllm: matmul(w4a16) run failed
E rkllm: set quant params failed[w4a8]
E rkllm: matmul run failed[w4a8]
E rkllm: rkllm_init failed
Enabled cpus: [
I rkllm: %s
I rkllm: Enabled cpus num: %d
base_domain_id must >= 0, but current base_domain_id is %d
rknn llm lib version: 2.3.3b0 (c54da5763@2025-04-18T15:37:10)
RKNN LLM Runtime Information, %s
persist.vendor.rknn.log.level
RKNN_LOG_LEVEL
load model file error!
model init error!
_feature_B
Failed to get mem by name %s
scale set for op %s failed, only support matmul type INT8_MM_INT8_TO_FLOAT32 or INT8_MM_INT4_TO_FLOAT16, but current type is %s
_Bias
_C_secondary
Failed to find type by op name %s
UNDEFINED
FLOAT16_MM_FLOAT16_TO_FLOAT32
INT8_MM_INT8_TO_INT32
INT8_MM_INT8_TO_INT8
FLOAT16_MM_FLOAT16_TO_FLOAT16
FLOAT16_MM_INT8_TO_FLOAT32
FLOAT16_MM_INT8_TO_FLOAT16
FLOAT16_MM_INT4_TO_FLOAT32
FLOAT16_MM_INT4_TO_FLOAT16
INT8_MM_INT8_TO_FLOAT32
INT4_MM_INT4_TO_INT16
INT8_MM_INT4_TO_INT32
FLOAT16_MM_INT4_TO_BFLOAT16
INT8_MM_INT4_TO_FLOAT16
E RKNN: %s%s
W RKNN: %s%s
I RKNN: %s%s
D RKNN: %s%s
T RKNN: %s%s
E RKNN: Unsupported log level: %d
failed to open rknn device!
meet unsupported matmul dtype : %s
domain id not found for tensor: %s
meet unkown op, op name: %s
op name: %s get shape failed
failed to update weight tensor addr, tensor name: %s
failed to update sacle tensor addr, tensor name: %s
failed to update internal tensor addr, tensor name: %s
Not support core mask: %x, fallback to single core auto mode
Failed to set core mask: %x
meet unkown shape, op name: %s, shape: %d, %d, %d
failed to malloc npu memory, size: %zu, flags: %#x
Job can not submit multi core tasks
invalid tensor malloc size, tensor name: %s, target: %s, size: %zu
failed to malloc cpu memory, size: %zu
N4rknn10RKNNTensorE
St23_Sp_counted_ptr_inplaceIN4rknn10RKNNTensorESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN5rkllm10RKLLMModelESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
RKLLM model version is 
, but current librkllmrt.so is support model version <= 
, please update
Number of operators in rkllm should be greater than 0.
model fd is NULL
invalid model fd, model_offset(%d) > total_file_size(%zu)
failed to read model title
invalid rknn llm model magic
failed to read model data
regtask
regcmd
failed to read regtask: must read size(%zu), real read size(%zu)
failed to read regcmd: must read size(%zu), real read size(%zu)
failed to read weight tensor: must read size(%zu), real read size(%zu)
failed to read scale tensor: must read size(%zu), real read size(%zu)
Invalid argument: properties is null
Device is not available
%d.%d.%d
UNKNOW
RKNN_FLOAT16_MM_FLOAT16_TO_FLOAT16
RKNN_INT8_MM_INT8_TO_INT32
RKNN_FLOAT16_MM_INT4_TO_FLOAT32
RKNN_FLOAT16_MM_FLOAT16_TO_FLOAT32
RKNN_FLOAT16_MM_INT8_TO_FLOAT32
RKNN_FLOAT16_MM_INT8_TO_FLOAT16
RKNN_INT4_MM_INT4_TO_INT16
RKNN_INT8_MM_INT8_TO_FLOAT32
RKNN_FLOAT16_MM_INT4_TO_FLOAT16
RKNN_FLOAT16_MM_INT4_TO_BFLOAT16
RKNN_INT8_MM_INT8_TO_INT8
RKNN_INT8_MM_INT4_TO_INT32
feature_B
shapes is null!
matmul_type is null!
unsupported matmul type: %s
shapes format error,should be M1,K1,N1#M2,K2,N2#...!
dynamic_shapes K and N must be same!
rknn_matmul_create_dynamic_shape, unsupported matmul dtype : %s in this platform
rknn_matmul_create, K(%d) > limit: %d
rknn_matmul_create_dynamic_shape, matmul K must be align with %d!
rknn_matmul_create_dynamic_shape, matmul N:%d must be align with %d!
weight_expand
channel
rknn_matmul_create_dynamic_shape, need kernel tile for M = %d, K = %d, N = %d, matmul type = %d, but not support kernel tile currently!
C_secondary
Bias
rknn_matmul_create_dynamic_shape, max K = %d, but limit to %d!
temp_reset_cmd_rubik_in
temp_reset_cmd_rubik_out
failed to find tensor: %#x for address informations!
subgraph%d regcmdbuffer size: %zu, taskbuffer size: %zu
total regcmd buffer size: %zu, task buffer size: %zu
total plan size: %zu
regcmd buffer size: %zu, task buffer size: %zu
weight size: %zu, internal size: %zu, misc size: %zu
Unsupport type bits %d
Unsupport group conv type %d
N4rknn7RKNNJobE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNSubGraphESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn9RKNNModelESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
 ...
RKNPU Lite
RKNPU v2
RKNPU t3
RKNPU T4
RKNPU F2
RKNPU F3
RKNPU W2
RKNPU W1
Illegal argb input channel %d
Illegal argb input type_bits %d, not support now
get data entries error: invalid surface number!
Meet unsupported dtype: %d
Not support prec type: %d
ConvTranspose do swap: h <--> w
unsupported conv weight in type: %d
RKNNConfig: getBanksForFullWeights type_bytes is 0, use 4 bits
min_weight_banks > 3 && m_Target == RKNNTarget::RKNPU_F2, do conv with ChannelTile
min_weight_banks > 7 && m_Target == RKNNTarget::RKNPU_F3, do conv with ChannelTile
min_weight_banks > 8 && m_Target == RKNNTarget::RKNPU_W2, do conv with ChannelTile
min_weight_banks > 7 && m_Target == RKNNTarget::RKNPU_W1, do conv with ChannelTile
Unsupport type bits %d for depthwise
unsupported conv data in type: %d
Current driver version: %d.%d.%d, recommend to upgrade the driver to the new version: >= %d.%d.%d
invalid device fd!
import memory, fd: %d, refcount: %d
failed to convert fd(%d) to handle, ret: %d, errno: %d, errstr: %s
failed to allocate handle, ret: %d, errno: %d, errstr: %s
import memory, virt addr: %p, dma addr: 0x%lx, obj addr: 0x%lx, size: %zu, real size: %zu, fd: %d, handle: %d, refcount: %d
unimport memory, fd: %d, refcount: %d
unimport memory, virt addr: %p, dma addr: 0x%lx, obj addr: 0x%lx, real size: %zu, fd: %d, handle: %d, refcount: %d
failed to destroy handle, ret: %d, errno: %d, errstr: %s
can not find memory for freeing
free memory, name: %s, virt addr: %p, dma addr: 0x%lx, obj addr: 0x%lx, size: %zu, aligned size: %zu, fd: %d, handle: %d, flags: %#x, gem name: %d, iommu domain id: %d
failed to unmap memory, errno: %s
free memory, name: %s, virt addr: %p, dma addr: 0x%lx, obj addr: 0x%lx, size: %zu, aligned size: %zu, fd: %d
This shared library is not supported on the current platform, hw_version = %d
Meet unknown rknpu target: %#x
RKNN Driver Information, version: %d.%d.%d
librknnrt version: 2.3.3b0 (c54da5763@2025-04-18T15:37:10)
Mismatch driver version, %s requires driver version >= %d.%d.%d, but you have driver version: %d.%d.%d which is incompatible!
failed to sync partial buffer that import from outside, fd: %d, offset: %zd, size: %zd, flags: %#lx, ret: %d
failed to sync memory, ret: %d, errno: %d, errstr: %s
failed to convert handle(%d) to fd, ret: %d, errno: %d, errstr: %s
failed to get map offset, ret: %d, errno: %d, errstr: %s
failed to map memory, errno: %s
ptr already exist in mem map, you would better unimport it before
allocated memory, name: %s, virt addr: %p, dma addr: 0x%lx, obj addr: 0x%lx, size: %zu, aligned size: %zu, fd: %d, handle: %d, flags: %#x, gem name: %d, iommu domain id: %d
DMA Heap allocation failed
failed to allocate fd, ret: %d, errno: %d, errstr: %s
failed to map memory, errno = %s
allocated memory, name: %s, virt addr: %p, dma addr: 0x%lx, obj addr: 0x%lx, size: %zu, aligned size: %zu, fd: %d
/dev/rknpu
rknpu
failed to open %s module, need to insmod rknpu dirver!
/dev/dma_heap
system dma heap handle: %d
Failed to open DMA heap: %s
Conv
InputOperator, OutputOperator, exPassThrough, exSwooshR, exSwooshL, exAfterProc, AfterProc, exProposal, exDataConvert, exReorg, exRoiAlign, exLRN, exActivation, exSoftmax13, exLogSoftmax13, exLSTM, exGRU, exHardSwish, exLayerNorm, exNorm, exSwish, exMish, exRfftn, exIRfftn, exGelu, exConvTransposePad, exRMSNorm, exSoftmaxMask, exGlu, exMeanVarianceNormalization, exSDPAttention, exMatMul, exNorm, exWindow, exConvStreaming, Abs, Acos, Acosh, Add, And, ArgMax, ArgMin, Asin, Asinh, Atan, Atanh, AveragePool, BatchNormalization, Bernoulli, BitShift, BitwiseAnd, BitwiseNot, BitwiseOr, BitwiseXor, BlackmanWindow, Cast, CastLike, Ceil, Celu, CenterCropPad, Clip, Col2Im, Compress, Concat, ConcatFromSequence, Constant, ConstantOfShape, Conv, ConvInteger, ConvTranspose, Cos, Cosh, CumSum, DFT, DepthToSpace, DequantizeLinear, Det, Div, Dropout, DynamicQuantizeLinear, Einsum, Elu, Equal, Erf, Exp, Expand, EyeLike, Flatten, Floor, GRU, Gather, GatherElements, GatherND, Gemm, GlobalAveragePool, GlobalLpPool, GlobalMaxPool, Greater, GreaterOrEqual, GridSample, GroupNormalization, HammingWindow, HannWindow, HardSigmoid, HardSwish, Hardmax, Identity, InstanceNormalization, IsInf, IsNaN, LRN, LSTM, LayerNormalization, LeakyRelu, Less, LessOrEqual, Log, LogSoftmax, LpNormalization, LpPool, MatMul, MatMulInteger, Max, MaxPool, MaxRoiPool, MaxUnpool, Mean, MeanVarianceNormalization, MelWeightMatrix, Min, Mish, Mod, Mul, Multinomial, Neg, NegativeLogLikelihoodLoss, NonMaxSuppression, NonZero, Not, OneHot, Optional, OptionalGetElement, OptionalHasElement, Or, PRelu, Pad, Pow, QLinearConv, QLinearMatMul, QuantizeLinear, RNN, RandomNormal, RandomNormalLike, RandomUniform, RandomUniformLike, Range, Reciprocal, ReduceL1, ReduceL2, ReduceLogSum, ReduceLogSumExp, ReduceMax, ReduceMean, ReduceMin, ReduceProd, ReduceSum, ReduceSumSquare, Relu, Reshape, Resize, ReverseSequence, RoiAlign, Round, STFT, Scatter, ScatterElements, ScatterND, Selu, SequenceAt, SequenceConstruct, SequenceEmpty, SequenceErase, SequenceInsert, SequenceLength, SequenceMap, Shape, Shrink, Sigmoid, Sign, Sin, Sinh, Size, Slice, Softmax, SoftmaxCrossEntropyLoss, Softplus, Softsign, SpaceToDepth, Split, SplitToSequence, Sqrt, Squeeze, StringNormalizer, Sub, Sum, Tan, Tanh, TfIdfVectorizer, ThresholdedRelu, Tile, TopK, Transpose, Trilu, Unique, Unsqueeze, Upsample, Where, Xor, Adagrad, Adam, Gradient, Momentum
CustomOperator
Meet invalid dst tensor for unpack!
Meet invalid dst tensor layout for pack, dst tensor layout: %s, dimension size: %d!
Meet invalid dst tensor shape for pack, orign dimension size: %d!
Folder doesn't Exist!
CHWN
NHWC
NC1HWC2
HWIO
OIHW
NCHW
O1I1HWI2O2
Meet invalid src tensor layout for convert NC1HWC2, src tensor layout: %s, dimension size: %d!
Meet invalid src tensor shape for ConvertNC1HWC2, orign dimension size: %d!
type is unsuport!
Meet invalid src type: %s for ConvertNC1HWC2!
Meet invalid src tensor shape size for nchw to nhwc, src shape size = %d
Meet unsupported dst dtype: %s for convert
Meet invalid src tensor layout for unpack, src tensor layout: %s, dimension size: %d!
Meet invalid src tensor shape for unpack, orign dimension size: %d!
Meet invalid src tensor layout for UnpackWeight, src tensor layout: %s, dimension size: %d!
Meet unsupported unpack dst dtype: %s
Meet invalid src tensor layout for unpack NHWC, src tensor layout: %s, dimension size: %d!
Meet invalid src tensor shape for unpack NHWC, orign dimension size: %d!
Meet invalid src tensor shape size for nhwc to nchw, src shape size = %d
Unsupported unpack nhwc quant!
N4rknn7float16E
exConvStreaming
OutputOperator
AfterProc
InputOperator
_afterproc
failed to update tensor addr, tensor name: %s
DynamicCMD_StackBuf
allocated SRAM tensor memory, name: %s, total size(Byte): %zu (including SRAM size(Byte): %zu)
failed to update out cvt offset!
failed to update out cvt shift!
failed to update cna cvt bypass!
unknown cache type: %s
invalid means and stds size!
invalid multipliers, shifts and offsets size!
normalize target: NPU
Meet unsupported target on normalize: %d
update cvt sign: %d
failed to update normalize parameters
Meet unsupported rknn target type: %#x
_unpack
_cast
regcfg
tf32 not Support Argb Mode, Fallback to CPU Normalize
failed to update argb in!
failed to update rgb bytelength!
failed to update line stride!
failed to update feature data addr!
failed to update surf stride!
failed to update data entries!
failed to update line stride!
failed to update feature data addr!
Unknown target type
enable argb mode, dtype: %s, channel: %d
Meet invalid src tensor layout for unpack RT: src tensor layout = %d, dimension size = %d!
Meet invalid src tensor shape for unpack RT: src tensor origin dimention size = %d !
Only Allocate buffer if set RKNN_FLAG_COLLECT_MODEL_INFO_ONLY flag!
_Cache_Slice_0_Load_to_Nbuf
_Cache_Slice_1_Load_to_Nbuf
_Feature_Load_to_Cache
Reset cmd value addr is error!
dynamic cmd type: %d is knowed
task_unroll
DRAM
SRAM
NBUF
NBUF_WRB
FLOAT
UINT8
UINT16
INT64
STRING
BOOL
DOUBLE
UINT32
UINT64
COMPLEX64
COMPLEX128
INT4
TF32
persist.vendor.rknn.min.timeout.ms
RKNN_MIN_TIMEOUT_MS
config size_e: %d, NPU not support!
If using rknn, update to the latest toolkit2 and runtime from: https://console.zbox.filez.com/l/I00fc3 (PWD: rknn). If using rknn-llm, update from: https://github.com/airockchip/rknn-llm
failed to submit, invalid task start: %d, %s
failed to update data and weight reuse!
failed to submit, invalid run task counter: %d >= %d, %s
failed to submit, invalid task index: %d, %s
Unknown
failed to submit, op id: %d, op name: %s, flags: %#x, task start: %d, task number: %d, run task counter: %d, int status: %#x, %s
failed to sync wait, errno: %s
St23_Sp_counted_ptr_inplaceIN4rknn9RKNNJobV2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn7RKNNJobESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
Unkown core mode: %d
m_RegcmdPtr is empty
Illegal core_mask %d
Illegal core num, rknn model version illegal
op work load meet unkown idx: %d, idx must < 9
failed to submit!, invalid task start: %d/%d/%d of %d, %s
Unsupport weight data type!
failed to submit!, invalid run task counter: %d >= %d, %s
failed to submit!, invalid task index: %d, %s
failed to submit!, op id: %d, op name: %s, flags: %#x, task start: %d, task number: %d, run task counter: %d, int status: %#x, %s
N4rknn9RKNNJobV2E
REGTASK: The bit width of field value exceeds the limit, target: %s, offset: %#x, shift = %d, limit: %#x, value: %#x
Interrupt Status: %#x
  CNA feature group0: %d
  CNA feature group1: %d
  CNA weight  group0: %d
  CNA weight  group1: %d
  CNA csc     group0: %d
  CNA csc     group1: %d
  ACCU        group0: %d
  ACCU        group1: %d
  DPU         group0: %d
  DPU         group1: %d
  PPU         group0: %d
  PPU         group1: %d
  DMA read     error: %d
  DMA write    error: %d
Meet unsupported target: %s
Unknown platform
N4rknn16RKNNRegisterTaskE
St23_Sp_counted_ptr_inplaceIN4rknn21RKNNRegisterTask_liteESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_v2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_t3ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_t4ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_f2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_w2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_w1ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn19RKNNRegisterTask_f3ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
N4rknn19RKNNRegisterTask_f2E
N4rknn19RKNNRegisterTask_f3E
N4rknn21RKNNRegisterTask_liteE
N4rknn19RKNNRegisterTask_t3E
N4rknn19RKNNRegisterTask_t4E
N4rknn19RKNNRegisterTask_v2E
N4rknn19RKNNRegisterTask_w1E
N4rknn19RKNNRegisterTask_w2E
Meet unknown rknpu target string: %s
failed to check rknpu hardware version: %#x
UNKNOWN
RKNPU V2
RKNPU T3
Meet unknown rknpu target type: %#x
RK3566/RK3568
RV1103/RV1106
RK2118
RV1103b
RV1126b
RKNNJob not initialized: size = %d
Meet unsupported target type: %#x
N4rknn10RKNNTargetE
N4rknn14RKNNTargetLiteE
N4rknn12RKNNTargetT3E
N4rknn12RKNNTargetT4E
N4rknn12RKNNTargetF2E
N4rknn12RKNNTargetV2E
N4rknn12RKNNTargetW2E
N4rknn12RKNNTargetW1E
N4rknn12RKNNTargetF3E
St23_Sp_counted_ptr_inplaceIN4rknn14RKNNTargetLiteESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetT3ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetT4ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetF2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetV2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetW2ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetW1ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNTargetF3ESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
vector<bool>::_M_insert_range
getNewLineIndex 
getNewLineIndex 
emitABC_T_BAC_regtask tensor must be 4D
C must be aligned to subc
emitABC_T_BAC_regtask notch_addr overflow
emitKC_T_C1K1C2K2C3 limit_w overflow
emitKC_T_C1K1C2K2C3 notch_limit overflow
Meet unsupported target
_prectrans
banks num invalid, input_bank_num: %d, weight_bank_num: %d
Not implement 3576 int8 perchannel matmul
input expand u8->i16 
Error
Invalid reuse strategy!
MAC proc_precision not support when generate group_kernel_size
int4
buffer overflow!!!
Feature is too large
aligned_kernels inefficient
Illegal type_bits %d
grade 2 group failed for core_num %d
Matmul
Conv min_weight_banks > 3, OutputName : %s
failed to tile argb mode layer!
MC K Tile Failed, min kernel step %d, but get %d
deconv illegal grade2group core num %d
Get matmul k limit error, meet unsupport bits %d
Cannot find uniform split solution for size %d with limit %d and macC %d
ZpOffset
ReduceSumWeight
C_secondary_2
nbuf
emit transpose failed, skip this op
emitTranspose: unsupported tile_count
emitTranspose: unsupported perm
N4rknn7runtime12RKNPUEmitterE
N4rknn7runtime2f212DeconvTilingE
N4rknn7runtime14RKNPUEmitterF2E
N4rknn7runtime16RKNPUEmitterLiteE
N4rknn7runtime14RKNPUEmitterT4E
N4rknn7runtime14RKNPUEmitterV2E
St23_Sp_counted_ptr_inplaceIN4rknn22RKNNOperatorTilingInfoESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn7runtime16RKNPUEmitterLiteESaIS2_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn7runtime14RKNPUEmitterV2ESaIS2_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn7runtime14RKNPUEmitterT4ESaIS2_ELN9__gnu_cxx12_Lock_policyE2EE
St23_Sp_counted_ptr_inplaceIN4rknn7runtime14RKNPUEmitterF2ESaIS2_ELN9__gnu_cxx12_Lock_policyE2EE
uint8
int16
int32
float16
float32
unknown tensor type: %d
undefined
St23_Sp_counted_ptr_inplaceIN4rknn12RKNNOperatorESaIS1_ELN9__gnu_cxx12_Lock_policyE2EE
The library handle can't be null!
clGetPlatformIDs
Cannot find the 
 in libOpenCL.so!
clGetPlatformInfo
clBuildProgram
clEnqueueNDRangeKernel
clSetKernelArg
clRetainMemObject
clReleaseMemObject
clEnqueueUnmapMemObject
clRetainCommandQueue
clCreateContext
clCreateContextFromType
clReleaseContext
clWaitForEvents
clReleaseEvent
clEnqueueWriteBuffer
clEnqueueReadBuffer
clEnqueueCopyImageToBuffer
clEnqueueCopyBufferToImage
clEnqueueReadImage
clGetProgramBuildInfo
clRetainProgram
clEnqueueMapBuffer
clEnqueueMapImage
clCreateCommandQueue
clGetCommandQueueInfo
clReleaseCommandQueue
clCreateProgramWithBinary
clRetainContext
clGetContextInfo
clReleaseProgram
clFlush
clFinish
clGetProgramInfo
clCreateKernel
clRetainKernel
clCreateBuffer
clCreateImage2D
clCreateUserEvent
clCreateProgramWithSource
clReleaseKernel
clGetDeviceInfo
clGetDeviceIDs
clRetainEvent
clGetKernelWorkGroupInfo
clGetEventInfo
clGetEventProfilingInfo
clGetImageInfo
clGetMemObjectInfo
clEnqueueCopyBuffer
clEnqueueWriteImage
clEnqueueCopyImage
clImportMemoryARM
clEnqueueWriteBufferRect
clCreateSubBuffer
libOpenCL.so
/usr/lib/aarch64-linux-gnu/libOpenCL.so
/usr/lib/arm-linux-gnueabihf/libOpenCL.so
/opt/intel/opencl/linux/compiler/lib/intel64_lin/libOpenCL.so
dlopen error: Unknown error occurred.
Load the OpenCL library from 
Failed to find and initialize Opencl library
Cannot load clImportMemoryARM!
Cannot load clEnqueueCopyImage!
Cannot load clEnqueueWriteImage!
Cannot load clEnqueueCopyBuffer!
Cannot load clGetMemObjectInfo!
Cannot load clGetImageInfo!
Cannot load clGetEventProfilingInfo!
Cannot load clGetEventInfo!
Cannot load clGetKernelWorkGroupInfo!
Cannot load clRetainEvent!
Cannot load clGetDeviceIDs!
Cannot load clGetDeviceInfo!
Cannot load clReleaseKernel!
Cannot load clCreateProgramWithSource!
Cannot load clCreateUserEvent!
Cannot load clCreateImage2D!
Cannot load clCreateBuffer!
Cannot load clRetainKernel!
Cannot load clCreateKernel!
Cannot load clGetProgramInfo!
Cannot load clFinish!
Cannot load clFlush!
Cannot load clReleaseProgram!
Cannot load clGetContextInfo!
Cannot load clRetainContext!
Cannot load clCreateProgramWithBinary!
Cannot load clReleaseCommandQueue!
Cannot load clGetCommandQueueInfo!
Cannot load clCreateCommandQueue!
Cannot load clEnqueueMapImage!
Cannot load clEnqueueMapBuffer!
Cannot load clRetainProgram!
Cannot load clGetProgramBuildInfo!
Cannot load clEnqueueReadImage!
Cannot load clEnqueueCopyBufferToImage!
Cannot load clEnqueueCopyImageToBuffer!
Cannot load clEnqueueReadBuffer!
Cannot loadcl clEnqueueWriteBuffer!
Cannot load clReleaseEvent!
Cannot load clWaitForEvents!
Cannot load clReleaseContext!
Cannot load clCreateContextFromType!
Cannot load clCreateContext!
Cannot load clRetainCommandQueue!
Cannot load clEnqueueUnmapMemObject!
Cannot load clReleaseMemObject!
Cannot load clRetainMemObject!
Cannot load clSetKernelArg!
Cannot load clEnqueueNDRangeKernel!
Cannot load clBuildProgram!
Cannot load clGetPlatformInfo!
Cannot load clGetPlatformIDs!
Cannot load clEnqueueWriteBufferRect!
Cannot load clCreateSubBuffer!
Cannot load clEnqueueFillBuffer!
/sys/class/drm/%s/device/config
card
renderD
/sys/dev/char/%d:%d/device/drm
/dev/dri/%s
controlD
/sys/dev/char/%d:%d/device/uevent
PCI_SLOT_NAME=
PCI_SLOT_NAME=%04x:%02x:%02x.%1u
/sys/dev/char/%d:%d/device/subsystem
/pci
LIBGL_DEBUG
verbose
Failed to change owner or group for file %s! %d: %s
%s/controlD%d
%s/renderD%d
%s/card%d
/dev/dri
drmOpenDevice: node name is %s
drmOpenDevice: open result is %d, (%s)
drmOpenDevice: Open failed
DRM_IOCTL_VERSION: %s
/proc/dri/0
clock_gettime failed: %s
%s: no device
%s: no access
%s: not root
%s: invalid args
%s: error %d (%s)
Lock
%-20.20s
%8.8s
Opens
%5.5s
Closes
Ioctls
Ioc/s
Locks
Lck/s
Unlocks
Unl/s
IRQs
IRQ/s
Primary Bytes
PB/s
Secondary Bytes
SB/s
DMA/s
Special DMA
dma/s
Miss
Ms/s
Value
Count
Cnt/s
drmOpenByBusid: Searching for BusID %s
drmOpenByBusid: drmOpenMinor returns %d
drmOpenByBusid: Interface 1.4 failed, trying 1.1
drmOpenByBusid: drmGetBusid reports %s
pci:%04x:%02x:%02x.%u
PCI:%u:%u:%u
/proc/dri/%d/name
drmGetBusid returned '%s'
[drm] failed to load kernel module "%s"
The subsystem type is not supported yet
Unknow dtype to get bits: %d
Unknow dtype to get bytes: %d
Unknown split Method -> %d
|xstart  |ystart  |kstart  | data reuse | weight reuse | mc_treat_by_y_tile | mc_treat_by_k_tile | mc_treat_by_1c_y_tile | mc_treat_by_1c_k_tile |
|%8d|%8d|%8d|%12d|%14d|%20d|%20d|%23d|%23d|
matmul
Failed to config layer: '%s', illegal tiling method %d
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
 dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
Failed to config layer: '%s' using %dCore fallback to single core mode,
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
Please help report this bug!
X tile buffer overflow! Failed to config layer: '%s', Fatal Error input W too large
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
Failed to config layer: '%s', core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
 dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
Generate Y config crash! Failed to config layer: '%s',
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
 dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
RK3588 library do not support generate RK3566/RK3568 rknn model, exit now
Failed to config layer: '%s', Fatal Error
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
 dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
Illegal mc Y type, Failed to config layer: '%s',
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
 dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
Illegal mc K type, Failed to config layer: '%s',
core_num %d ori_Ih %d ori_Iw %d ori_Ic %d ori_Ib %d 
ori_Kh %d ori_Kw %d ori_Kk %d ori_Kc %d ori_Ksx %d ori_Ksy %d 
ori_Oh %d oriOw %d oriOc %d pad_t %d pad_b %d pad_l %d pad_r %d,
 dilation_h %d dilation_w %d is_deconv %d,
Please help report this bug!
vector<bool>::_M_fill_insert
zPLR
GCC: (GNU Toolchain for the A-profile Architecture 10.2-2020.11 (arm-10.16)) 10.2.1 20201103
.shstrtab
.gnu.hash
.dynsym
.dynstr
.gnu.version
.gnu.version_r
.rela.dyn
.rela.plt
.init
.text
.fini
.rodata
.eh_frame_hdr
.eh_frame
.gcc_except_table
.init_array
.fini_array
.data.rel.ro
.dynamic
.got
.got.plt
.data
.bss
.comment
